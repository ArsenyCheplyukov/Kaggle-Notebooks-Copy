{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-19T16:51:21.352485Z","iopub.execute_input":"2021-07-19T16:51:21.352921Z","iopub.status.idle":"2021-07-19T16:51:22.617673Z","shell.execute_reply.started":"2021-07-19T16:51:21.352838Z","shell.execute_reply":"2021-07-19T16:51:22.616674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:23.753631Z","iopub.execute_input":"2021-07-19T16:51:23.753952Z","iopub.status.idle":"2021-07-19T16:51:26.555388Z","shell.execute_reply.started":"2021-07-19T16:51:23.753918Z","shell.execute_reply":"2021-07-19T16:51:26.554292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch import optim\nfrom tqdm import tqdm\nimport os\nfrom PIL import Image\nfrom torchvision.utils import save_image\nimport os\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision.models import vgg19","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:40.290675Z","iopub.execute_input":"2021-07-19T16:51:40.291064Z","iopub.status.idle":"2021-07-19T16:51:43.282044Z","shell.execute_reply.started":"2021-07-19T16:51:40.291028Z","shell.execute_reply":"2021-07-19T16:51:43.281142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_GEN = \"gen.pth.tar\"\nCHECKPOINT_DISC = \"disc.pth.tar\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 10\nBATCH_SIZE = 16\nNUM_WORKERS = 4\nHIGH_RES = 96\nLOW_RES = HIGH_RES // 4\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:53:41.937729Z","iopub.execute_input":"2021-07-19T16:53:41.93808Z","iopub.status.idle":"2021-07-19T16:53:41.943454Z","shell.execute_reply.started":"2021-07-19T16:53:41.938046Z","shell.execute_reply":"2021-07-19T16:53:41.94252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highres_transform = A.Compose(\n    [\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n        ToTensorV2(),\n    ]\n)\n\nlowres_transform = A.Compose(\n    [\n        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n        ToTensorV2(),\n    ]\n)\n\nboth_transforms = A.Compose(\n    [\n        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n        A.HorizontalFlip(p=0.5),\n        A.RandomRotate90(p=0.5),\n    ]\n)\n\ntest_transform = A.Compose(\n    [\n        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n        ToTensorV2(),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.335303Z","iopub.execute_input":"2021-07-19T16:51:43.336132Z","iopub.status.idle":"2021-07-19T16:51:43.346196Z","shell.execute_reply.started":"2021-07-19T16:51:43.336078Z","shell.execute_reply":"2021-07-19T16:51:43.345236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGGLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg = vgg19(pretrained=True).features[:36].eval().to(DEVICE)\n        self.loss = nn.MSELoss()\n\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n\n    def forward(self, input, target):\n        vgg_input_features = self.vgg(input)\n        vgg_target_features = self.vgg(target)\n        return self.loss(vgg_input_features, vgg_target_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.348202Z","iopub.execute_input":"2021-07-19T16:51:43.348766Z","iopub.status.idle":"2021-07-19T16:51:43.357575Z","shell.execute_reply.started":"2021-07-19T16:51:43.348695Z","shell.execute_reply":"2021-07-19T16:51:43.35645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, device):\n    BATCH_SIZE, C, H, W = real.shape\n    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n    interpolated_images.requires_grad_(True)\n\n    # Calculate critic scores\n    mixed_scores = critic(interpolated_images)\n\n    # Take the gradient of the scores with respect to the images\n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.359215Z","iopub.execute_input":"2021-07-19T16:51:43.359738Z","iopub.status.idle":"2021-07-19T16:51:43.368706Z","shell.execute_reply.started":"2021-07-19T16:51:43.359695Z","shell.execute_reply":"2021-07-19T16:51:43.367857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.369981Z","iopub.execute_input":"2021-07-19T16:51:43.370555Z","iopub.status.idle":"2021-07-19T16:51:43.38005Z","shell.execute_reply.started":"2021-07-19T16:51:43.370501Z","shell.execute_reply":"2021-07-19T16:51:43.379275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.382921Z","iopub.execute_input":"2021-07-19T16:51:43.383313Z","iopub.status.idle":"2021-07-19T16:51:43.390411Z","shell.execute_reply.started":"2021-07-19T16:51:43.383281Z","shell.execute_reply":"2021-07-19T16:51:43.389426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_examples(low_res_folder, gen):\n    files = os.listdir(low_res_folder)\n\n    gen.eval()\n    for file in files:\n        image = Image.open(low_res_folder + file)\n        with torch.no_grad():\n            upscaled_img = gen(\n                test_transform(image=np.asarray(image))[\"image\"]\n                .unsqueeze(0)\n                .to(DEVICE)\n            )\n        save_image(upscaled_img * 0.5 + 0.5, f\"./saved/{file}\")\n    gen.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T17:25:39.677398Z","iopub.execute_input":"2021-07-19T17:25:39.677763Z","iopub.status.idle":"2021-07-19T17:25:39.683248Z","shell.execute_reply.started":"2021-07-19T17:25:39.677724Z","shell.execute_reply":"2021-07-19T17:25:39.682357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyImageFolder(Dataset):\n    def __init__(self, root_dir):\n        super(MyImageFolder, self).__init__()\n        self.data = []\n        self.root_dir = root_dir\n        self.class_names = os.listdir(root_dir)\n\n        for index, name in enumerate(self.class_names):\n            files = os.listdir(os.path.join(root_dir, name))\n            self.data += list(zip(files, [index] * len(files)))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_file, label = self.data[index]\n        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n\n        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n        image = both_transforms(image=image)[\"image\"]\n        high_res = highres_transform(image=image)[\"image\"]\n        low_res = lowres_transform(image=image)[\"image\"]\n        return low_res, high_res","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.404432Z","iopub.execute_input":"2021-07-19T16:51:43.404754Z","iopub.status.idle":"2021-07-19T16:51:43.413711Z","shell.execute_reply.started":"2021-07-19T16:51:43.404721Z","shell.execute_reply":"2021-07-19T16:51:43.412633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        discriminator=False,\n        use_act=True,\n        use_bn=True,\n        **kwargs,\n    ):\n        super().__init__()\n        self.use_act = use_act\n        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n        self.act = (\n            nn.LeakyReLU(0.2, inplace=True)\n            if discriminator\n            else nn.PReLU(num_parameters=out_channels)\n        )\n\n    def forward(self, x):\n        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.415185Z","iopub.execute_input":"2021-07-19T16:51:43.41567Z","iopub.status.idle":"2021-07-19T16:51:43.424405Z","shell.execute_reply.started":"2021-07-19T16:51:43.415635Z","shell.execute_reply":"2021-07-19T16:51:43.423486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpsampleBlock(nn.Module):\n    def __init__(self, in_c, scale_factor):\n        super().__init__()\n        self.conv = nn.Conv2d(in_c, in_c * scale_factor ** 2, 3, 1, 1)\n        self.ps = nn.PixelShuffle(scale_factor)  # in_c * 4, H, W --> in_c, H*2, W*2\n        self.act = nn.PReLU(num_parameters=in_c)\n\n    def forward(self, x):\n        return self.act(self.ps(self.conv(x)))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.425922Z","iopub.execute_input":"2021-07-19T16:51:43.426305Z","iopub.status.idle":"2021-07-19T16:51:43.436709Z","shell.execute_reply.started":"2021-07-19T16:51:43.426271Z","shell.execute_reply":"2021-07-19T16:51:43.435816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.block1 = ConvBlock(\n            in_channels,\n            in_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1\n        )\n        self.block2 = ConvBlock(\n            in_channels,\n            in_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            use_act=False,\n        )\n\n    def forward(self, x):\n        out = self.block1(x)\n        out = self.block2(out)\n        return out + x","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.438345Z","iopub.execute_input":"2021-07-19T16:51:43.438813Z","iopub.status.idle":"2021-07-19T16:51:43.447695Z","shell.execute_reply.started":"2021-07-19T16:51:43.438772Z","shell.execute_reply":"2021-07-19T16:51:43.446575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n        super().__init__()\n        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)])\n        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n        self.upsamples = nn.Sequential(UpsampleBlock(num_channels, 2), UpsampleBlock(num_channels, 2))\n        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n\n    def forward(self, x):\n        initial = self.initial(x)\n        x = self.residuals(initial)\n        x = self.convblock(x) + initial\n        x = self.upsamples(x)\n        return torch.tanh(self.final(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.449121Z","iopub.execute_input":"2021-07-19T16:51:43.44968Z","iopub.status.idle":"2021-07-19T16:51:43.46196Z","shell.execute_reply.started":"2021-07-19T16:51:43.449637Z","shell.execute_reply":"2021-07-19T16:51:43.460919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n        super().__init__()\n        blocks = []\n        for idx, feature in enumerate(features):\n            blocks.append(\n                ConvBlock(\n                    in_channels,\n                    feature,\n                    kernel_size=3,\n                    stride=1 + idx % 2,\n                    padding=1,\n                    discriminator=True,\n                    use_act=True,\n                    use_bn=False if idx == 0 else True,\n                )\n            )\n            in_channels = feature\n\n        self.blocks = nn.Sequential(*blocks)\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d((6, 6)),\n            nn.Flatten(),\n            nn.Linear(512*6*6, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, 1),\n        )\n\n    def forward(self, x):\n        x = self.blocks(x)\n        return self.classifier(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.463558Z","iopub.execute_input":"2021-07-19T16:51:43.463977Z","iopub.status.idle":"2021-07-19T16:51:43.473747Z","shell.execute_reply.started":"2021-07-19T16:51:43.463934Z","shell.execute_reply":"2021-07-19T16:51:43.472871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    dataset = MyImageFolder(root_dir=\"../input/animal-faces/afhq/train/\")\n    loader = DataLoader(\n        dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        pin_memory=True,\n        num_workers=NUM_WORKERS,\n    )\n    gen = Generator(in_channels=3).to(DEVICE)\n    disc = Discriminator(in_channels=3).to(DEVICE)\n    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n    mse = nn.MSELoss()\n    bce = nn.BCEWithLogitsLoss()\n    vgg_loss = VGGLoss()\n\n    if LOAD_MODEL:\n        load_checkpoint(\n            CHECKPOINT_GEN,\n            gen,\n            opt_gen,\n            LEARNING_RATE,\n        )\n        load_checkpoint(\n           CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n        )\n\n    for epoch in range(NUM_EPOCHS):\n        train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)\n\n        if SAVE_MODEL:\n            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T17:23:30.136942Z","iopub.execute_input":"2021-07-19T17:23:30.137272Z","iopub.status.idle":"2021-07-19T17:23:30.145469Z","shell.execute_reply.started":"2021-07-19T17:23:30.137241Z","shell.execute_reply":"2021-07-19T17:23:30.144613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n    loop = tqdm(loader, leave=True)\n\n    for idx, (low_res, high_res) in enumerate(loop):\n        high_res = high_res.to(DEVICE)\n        low_res = low_res.to(DEVICE)\n        \n        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n        fake = gen(low_res)\n        disc_real = disc(high_res)\n        disc_fake = disc(fake.detach())\n        disc_loss_real = bce(\n            disc_real, torch.ones_like(disc_real) - 0.1 * torch.rand_like(disc_real)\n        )\n        disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n        loss_disc = disc_loss_fake + disc_loss_real\n\n        opt_disc.zero_grad()\n        loss_disc.backward()\n        opt_disc.step()\n\n        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n        disc_fake = disc(fake)\n        #l2_loss = mse(fake, high_res)\n        adversarial_loss = 1e-3 * bce(disc_fake, torch.ones_like(disc_fake))\n        loss_for_vgg = 0.006 * vgg_loss(fake, high_res)\n        gen_loss = loss_for_vgg + adversarial_loss\n\n        opt_gen.zero_grad()\n        gen_loss.backward()\n        opt_gen.step()\n\n        if idx % 200 == 0:\n            plot_examples(\"../input/animal-faces/afhq/val/dog/\", gen)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T17:26:57.047825Z","iopub.execute_input":"2021-07-19T17:26:57.048232Z","iopub.status.idle":"2021-07-19T17:26:57.058726Z","shell.execute_reply.started":"2021-07-19T17:26:57.04819Z","shell.execute_reply":"2021-07-19T17:26:57.057592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:51:43.501636Z","iopub.execute_input":"2021-07-19T16:51:43.501982Z","iopub.status.idle":"2021-07-19T16:51:43.509843Z","shell.execute_reply.started":"2021-07-19T16:51:43.501946Z","shell.execute_reply":"2021-07-19T16:51:43.509042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!md ./\n!mkdir test_images\n!mkdir saved","metadata":{"execution":{"iopub.status.busy":"2021-07-19T17:27:38.375221Z","iopub.execute_input":"2021-07-19T17:27:38.375576Z","iopub.status.idle":"2021-07-19T17:27:40.508229Z","shell.execute_reply.started":"2021-07-19T17:27:38.37552Z","shell.execute_reply":"2021-07-19T17:27:40.507033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T17:27:42.670864Z","iopub.execute_input":"2021-07-19T17:27:42.671202Z","iopub.status.idle":"2021-07-19T18:16:08.210014Z","shell.execute_reply.started":"2021-07-19T17:27:42.671165Z","shell.execute_reply":"2021-07-19T18:16:08.20786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip ./saved","metadata":{"execution":{"iopub.status.busy":"2021-07-19T18:16:54.082011Z","iopub.execute_input":"2021-07-19T18:16:54.082343Z","iopub.status.idle":"2021-07-19T18:17:06.766622Z","shell.execute_reply.started":"2021-07-19T18:16:54.082306Z","shell.execute_reply":"2021-07-19T18:17:06.76576Z"},"trusted":true},"execution_count":null,"outputs":[]}]}