{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-19T15:47:59.559468Z","iopub.execute_input":"2021-07-19T15:47:59.559953Z","iopub.status.idle":"2021-07-19T15:48:01.052955Z","shell.execute_reply.started":"2021-07-19T15:47:59.559863Z","shell.execute_reply":"2021-07-19T15:48:01.051687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:48:06.528271Z","iopub.execute_input":"2021-07-19T15:48:06.528662Z","iopub.status.idle":"2021-07-19T15:48:08.52399Z","shell.execute_reply.started":"2021-07-19T15:48:06.528625Z","shell.execute_reply":"2021-07-19T15:48:08.522749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision.utils import save_image\nfrom torchvision.models import vgg19\nfrom tqdm import tqdm\nimport os\nimport numpy as np\nfrom PIL import Image\nimport time\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:48:43.631563Z","iopub.execute_input":"2021-07-19T15:48:43.631997Z","iopub.status.idle":"2021-07-19T15:48:47.119521Z","shell.execute_reply.started":"2021-07-19T15:48:43.631959Z","shell.execute_reply":"2021-07-19T15:48:47.118435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_GEN = \"gen.pth\"\nCHECKPOINT_DISC = \"disc.pth\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 10\nBATCH_SIZE = 16\nLAMBDA_GP = 10\nNUM_WORKERS = 4\nHIGH_RES = 128\nLOW_RES = HIGH_RES // 4\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:48:54.062521Z","iopub.execute_input":"2021-07-19T15:48:54.062959Z","iopub.status.idle":"2021-07-19T15:48:54.115626Z","shell.execute_reply.started":"2021-07-19T15:48:54.062923Z","shell.execute_reply":"2021-07-19T15:48:54.114148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"highres_transform = A.Compose(\n    [\n        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n        ToTensorV2(),\n    ]\n)\n\nlowres_transform = A.Compose(\n    [\n        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n        ToTensorV2(),\n    ]\n)\n\nboth_transforms = A.Compose(\n    [\n        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n        A.HorizontalFlip(p=0.5),\n        A.RandomRotate90(p=0.5),\n    ]\n)\n\ntest_transform = A.Compose(\n    [\n        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n        ToTensorV2(),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:48:57.633225Z","iopub.execute_input":"2021-07-19T15:48:57.633625Z","iopub.status.idle":"2021-07-19T15:48:57.643022Z","shell.execute_reply.started":"2021-07-19T15:48:57.633567Z","shell.execute_reply":"2021-07-19T15:48:57.641669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VGGLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg = vgg19(pretrained=True).features[:35].eval().to(DEVICE)\n\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n\n        self.loss = nn.MSELoss()\n\n    def forward(self, input, target):\n        vgg_input_features = self.vgg(input)\n        vgg_target_features = self.vgg(target)\n        return self.loss(vgg_input_features, vgg_target_features)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:01.284955Z","iopub.execute_input":"2021-07-19T15:49:01.285321Z","iopub.status.idle":"2021-07-19T15:49:01.292705Z","shell.execute_reply.started":"2021-07-19T15:49:01.285289Z","shell.execute_reply":"2021-07-19T15:49:01.291563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyImageFolder(Dataset):\n    def __init__(self, root_dir):\n        super(MyImageFolder, self).__init__()\n        self.data = []\n        self.root_dir = root_dir\n        self.class_names = os.listdir(root_dir)\n\n        for index, name in enumerate(self.class_names):\n            files = os.listdir(os.path.join(root_dir, name))\n            self.data += list(zip(files, [index] * len(files)))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_file, label = self.data[index]\n        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n\n        image = cv2.imread(os.path.join(root_and_dir, img_file))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        both_transform = both_transforms(image=image)[\"image\"]\n        low_res = lowres_transform(image=both_transform)[\"image\"]\n        high_res = highres_transform(image=both_transform)[\"image\"]\n        return low_res, high_res\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:04.552109Z","iopub.execute_input":"2021-07-19T15:49:04.552489Z","iopub.status.idle":"2021-07-19T15:49:04.562293Z","shell.execute_reply.started":"2021-07-19T15:49:04.552453Z","shell.execute_reply":"2021-07-19T15:49:04.561228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, device):\n    BATCH_SIZE, C, H, W = real.shape\n    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n    interpolated_images.requires_grad_(True)\n\n    # Calculate critic scores\n    mixed_scores = critic(interpolated_images)\n\n    # Take the gradient of the scores with respect to the images\n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:07.436247Z","iopub.execute_input":"2021-07-19T15:49:07.436633Z","iopub.status.idle":"2021-07-19T15:49:07.44542Z","shell.execute_reply.started":"2021-07-19T15:49:07.43659Z","shell.execute_reply":"2021-07-19T15:49:07.443816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:10.117377Z","iopub.execute_input":"2021-07-19T15:49:10.11778Z","iopub.status.idle":"2021-07-19T15:49:10.124261Z","shell.execute_reply.started":"2021-07-19T15:49:10.117744Z","shell.execute_reply":"2021-07-19T15:49:10.122588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    # model.load_state_dict(checkpoint)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:14.051011Z","iopub.execute_input":"2021-07-19T15:49:14.05139Z","iopub.status.idle":"2021-07-19T15:49:14.058372Z","shell.execute_reply.started":"2021-07-19T15:49:14.051358Z","shell.execute_reply":"2021-07-19T15:49:14.057008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_examples(low_res_folder, gen):\n    files = os.listdir(low_res_folder)\n\n    gen.eval()\n    for file in files:\n        image = Image.open(\"../input/animal-faces/afhq/val/\" + file)\n        with torch.no_grad():\n            upscaled_img = gen(\n                test_transform(image=np.asarray(image))[\"image\"]\n                .unsqueeze(0)\n                .to(DEVICE)\n            )\n        save_image(upscaled_img, f\"saved/{file}\")\n    gen.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:01:33.889738Z","iopub.execute_input":"2021-07-19T16:01:33.89013Z","iopub.status.idle":"2021-07-19T16:01:33.898648Z","shell.execute_reply.started":"2021-07-19T16:01:33.890101Z","shell.execute_reply":"2021-07-19T16:01:33.895672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, use_act, **kwargs):\n        super().__init__()\n        self.cnn = nn.Conv2d(\n            in_channels,\n            out_channels,\n            **kwargs,\n            bias=True,\n        )\n        self.act = nn.LeakyReLU(0.2, inplace=True) if use_act else nn.Identity()\n\n    def forward(self, x):\n        return self.act(self.cnn(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:19.590141Z","iopub.execute_input":"2021-07-19T15:49:19.590512Z","iopub.status.idle":"2021-07-19T15:49:19.597797Z","shell.execute_reply.started":"2021-07-19T15:49:19.59048Z","shell.execute_reply":"2021-07-19T15:49:19.596252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpsampleBlock(nn.Module):\n    def __init__(self, in_c, scale_factor=2):\n        super().__init__()\n        self.upsample = nn.Upsample(scale_factor=scale_factor, mode=\"nearest\")\n        self.conv = nn.Conv2d(in_c, in_c, 3, 1, 1, bias=True)\n        self.act = nn.LeakyReLU(0.2, inplace=True)\n\n    def forward(self, x):\n        return self.act(self.conv(self.upsample(x)))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:23.113134Z","iopub.execute_input":"2021-07-19T15:49:23.113503Z","iopub.status.idle":"2021-07-19T15:49:23.12341Z","shell.execute_reply.started":"2021-07-19T15:49:23.11347Z","shell.execute_reply":"2021-07-19T15:49:23.122221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseResidualBlock(nn.Module):\n    def __init__(self, in_channels, channels=32, residual_beta=0.2):\n        super().__init__()\n        self.residual_beta = residual_beta\n        self.blocks = nn.ModuleList()\n\n        for i in range(5):\n            self.blocks.append(\n                ConvBlock(\n                    in_channels + channels * i,\n                    channels if i <= 3 else in_channels,\n                    kernel_size=3,\n                    stride=1,\n                    padding=1,\n                    use_act=True if i <= 3 else False,\n                )\n            )\n\n    def forward(self, x):\n        new_inputs = x\n        for block in self.blocks:\n            out = block(new_inputs)\n            new_inputs = torch.cat([new_inputs, out], dim=1)\n        return self.residual_beta * out + x","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:25.947439Z","iopub.execute_input":"2021-07-19T15:49:25.947852Z","iopub.status.idle":"2021-07-19T15:49:25.957145Z","shell.execute_reply.started":"2021-07-19T15:49:25.947818Z","shell.execute_reply":"2021-07-19T15:49:25.955605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RRDB(nn.Module):\n    def __init__(self, in_channels, residual_beta=0.2):\n        super().__init__()\n        self.residual_beta = residual_beta\n        self.rrdb = nn.Sequential(*[DenseResidualBlock(in_channels) for _ in range(3)])\n\n    def forward(self, x):\n        return self.rrdb(x) * self.residual_beta + x","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:29.574613Z","iopub.execute_input":"2021-07-19T15:49:29.574982Z","iopub.status.idle":"2021-07-19T15:49:29.581548Z","shell.execute_reply.started":"2021-07-19T15:49:29.57495Z","shell.execute_reply":"2021-07-19T15:49:29.580082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, in_channels=3, num_channels=64, num_blocks=23):\n        super().__init__()\n        self.initial = nn.Conv2d(\n            in_channels,\n            num_channels,\n            kernel_size=3,\n            stride=1,\n            padding=1,\n            bias=True,\n        )\n        self.residuals = nn.Sequential(*[RRDB(num_channels) for _ in range(num_blocks)])\n        self.conv = nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1)\n        self.upsamples = nn.Sequential(\n            UpsampleBlock(num_channels), UpsampleBlock(num_channels),\n        )\n        self.final = nn.Sequential(\n            nn.Conv2d(num_channels, num_channels, 3, 1, 1, bias=True),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(num_channels, in_channels, 3, 1, 1, bias=True),\n        )\n\n    def forward(self, x):\n        initial = self.initial(x)\n        x = self.conv(self.residuals(initial)) + initial\n        x = self.upsamples(x)\n        return self.final(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:31.822258Z","iopub.execute_input":"2021-07-19T15:49:31.822639Z","iopub.status.idle":"2021-07-19T15:49:31.834991Z","shell.execute_reply.started":"2021-07-19T15:49:31.822601Z","shell.execute_reply":"2021-07-19T15:49:31.833386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n        super().__init__()\n        blocks = []\n        for idx, feature in enumerate(features):\n            blocks.append(\n                ConvBlock(\n                    in_channels,\n                    feature,\n                    kernel_size=3,\n                    stride=1 + idx % 2,\n                    padding=1,\n                    use_act=True,\n                ),\n            )\n            in_channels = feature\n\n        self.blocks = nn.Sequential(*blocks)\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d((6, 6)),\n            nn.Flatten(),\n            nn.Linear(512 * 6 * 6, 1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(1024, 1),\n        )\n\n    def forward(self, x):\n        x = self.blocks(x)\n        return self.classifier(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:34.855864Z","iopub.execute_input":"2021-07-19T15:49:34.856232Z","iopub.status.idle":"2021-07-19T15:49:34.865124Z","shell.execute_reply.started":"2021-07-19T15:49:34.8562Z","shell.execute_reply":"2021-07-19T15:49:34.864076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_weights(model, scale=0.1):\n    for m in model.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.kaiming_normal_(m.weight.data)\n            m.weight.data *= scale\n\n        elif isinstance(m, nn.Linear):\n            nn.init.kaiming_normal_(m.weight.data)\n            m.weight.data *= scale","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:39.031931Z","iopub.execute_input":"2021-07-19T15:49:39.032332Z","iopub.status.idle":"2021-07-19T15:49:39.039844Z","shell.execute_reply.started":"2021-07-19T15:49:39.032287Z","shell.execute_reply":"2021-07-19T15:49:39.038341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:49:41.792231Z","iopub.execute_input":"2021-07-19T15:49:41.792618Z","iopub.status.idle":"2021-07-19T15:49:41.797046Z","shell.execute_reply.started":"2021-07-19T15:49:41.792558Z","shell.execute_reply":"2021-07-19T15:49:41.795869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!md ./\n!mkdir test_images","metadata":{"execution":{"iopub.status.busy":"2021-07-19T15:50:49.21725Z","iopub.execute_input":"2021-07-19T15:50:49.217797Z","iopub.status.idle":"2021-07-19T15:50:50.891844Z","shell.execute_reply.started":"2021-07-19T15:50:49.217745Z","shell.execute_reply":"2021-07-19T15:50:50.890498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(\n    loader,\n    disc,\n    gen,\n    opt_gen,\n    opt_disc,\n    l1,\n    vgg_loss,\n    g_scaler,\n    d_scaler,\n    writer,\n    tb_step,\n):\n    loop = tqdm(loader, leave=True)\n\n    for idx, (low_res, high_res) in enumerate(loop):\n        high_res = high_res.to(DEVICE)\n        low_res = low_res.to(DEVICE)\n\n        with torch.cuda.amp.autocast():\n            fake = gen(low_res)\n            critic_real = disc(high_res)\n            critic_fake = disc(fake.detach())\n            gp = gradient_penalty(disc, high_res, fake, device=DEVICE)\n            loss_critic = (\n                -(torch.mean(critic_real) - torch.mean(critic_fake))\n                + LAMBDA_GP * gp\n            )\n\n        opt_disc.zero_grad()\n        d_scaler.scale(loss_critic).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n\n        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n        with torch.cuda.amp.autocast():\n            l1_loss = 1e-2 * l1(fake, high_res)\n            adversarial_loss = 5e-3 * -torch.mean(disc(fake))\n            loss_for_vgg = vgg_loss(fake, high_res)\n            gen_loss = l1_loss + loss_for_vgg + adversarial_loss\n\n        opt_gen.zero_grad()\n        g_scaler.scale(gen_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n\n        writer.add_scalar(\"Critic loss\", loss_critic.item(), global_step=tb_step)\n        tb_step += 1\n\n        if idx % 100 == 0 and idx > 0:\n            plot_examples(\"./test_images/\", gen)\n\n        loop.set_postfix(\n            gp=gp.item(),\n            critic=loss_critic.item(),\n            l1=l1_loss.item(),\n            vgg=loss_for_vgg.item(),\n            adversarial=adversarial_loss.item(),\n        )\n\n    return tb_step","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:01:51.642392Z","iopub.execute_input":"2021-07-19T16:01:51.642788Z","iopub.status.idle":"2021-07-19T16:01:51.656183Z","shell.execute_reply.started":"2021-07-19T16:01:51.642755Z","shell.execute_reply":"2021-07-19T16:01:51.655134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    dataset = MyImageFolder(root_dir=\"../input/animal-faces/afhq/train/\")\n    loader = DataLoader(\n        dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        pin_memory=True,\n        num_workers=NUM_WORKERS,\n    )\n    gen = Generator(in_channels=3).to(DEVICE)\n    disc = Discriminator(in_channels=3).to(DEVICE)\n    initialize_weights(gen)\n    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n    writer = SummaryWriter(\"logs\")\n    tb_step = 0\n    l1 = nn.L1Loss()\n    gen.train()\n    disc.train()\n    vgg_loss = VGGLoss()\n\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n\n    if LOAD_MODEL:\n        load_checkpoint(\n            CHECKPOINT_GEN,\n            gen,\n            opt_gen,\n            LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_DISC,\n            disc,\n            opt_disc,\n            LEARNING_RATE,\n        )\n\n\n    for epoch in range(NUM_EPOCHS):\n        tb_step = train_fn(\n            loader,\n            disc,\n            gen,\n            opt_gen,\n            opt_disc,\n            l1,\n            vgg_loss,\n            g_scaler,\n            d_scaler,\n            writer,\n            tb_step,\n        )\n\n        if SAVE_MODEL:\n            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:01:57.033805Z","iopub.execute_input":"2021-07-19T16:01:57.034163Z","iopub.status.idle":"2021-07-19T16:01:57.045171Z","shell.execute_reply.started":"2021-07-19T16:01:57.034132Z","shell.execute_reply":"2021-07-19T16:01:57.043801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try_model = False\n\nif try_model:\n    # Will just use pretrained weights and run on images\n    # in test_images/ and save the ones to SR in saved/\n    gen = Generator(in_channels=3).to(DEVICE)\n    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n    load_checkpoint(\n        CHECKPOINT_GEN,\n        gen,\n        opt_gen,\n        LEARNING_RATE,\n    )\n    plot_examples(\"./test_images/\", gen)\nelse:\n    # This will train from scratch\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T16:02:01.404304Z","iopub.execute_input":"2021-07-19T16:02:01.404646Z","iopub.status.idle":"2021-07-19T16:21:24.823802Z","shell.execute_reply.started":"2021-07-19T16:02:01.404614Z","shell.execute_reply":"2021-07-19T16:21:24.81848Z"},"trusted":true},"execution_count":null,"outputs":[]}]}