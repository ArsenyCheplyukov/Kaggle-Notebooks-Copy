{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:1]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T06:24:12.508547Z","iopub.execute_input":"2023-05-06T06:24:12.508960Z","iopub.status.idle":"2023-05-06T06:24:23.240633Z","shell.execute_reply.started":"2023-05-06T06:24:12.508934Z","shell.execute_reply":"2023-05-06T06:24:23.239682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class GANModel(GAN):\n#     def __init__(self, input_channels, input_width, pretrained_model_path=None, **kwargs):\n#         super().__init__(input_channels=input_channels, input_width=input_width, **kwargs)\n#         self.input_width = input_width\n#         self.save_hyperparameters()\n#         self.pretrained_model_path = pretrained_model_path\n\n#     def forward(self, z, target=None):\n#         if target is not None:\n#             Z = torch.sigmoid(z)\n#             target = torch.sigmoid(target)\n#             return F.binary_cross_entropy_with_logits(Z, target, weight=self.weight, reduction=self.reduction)\n#         else:\n#             return self.generator(z)\n\n#     def configure_optimizers(self, lr = 0.0002, betas = (0.5, 0.999)):\n#         generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n#         discriminator_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=betas)\n#         return [generator_optimizer, discriminator_optimizer], []\n\n#     def training_step(self, batch, batch_idx, optimizer_idx):\n#         return super().training_step((batch, 0), batch_idx, optimizer_idx)\n\n#     def validation_step(self, batch, batch_idx):\n#         return super().validation_step((batch, 0), batch_idx)\n\n#     def test_step(self, batch, batch_idx):\n#         return super().test_step((batch, 0), batch_idx)\n\n#     def prepare_data(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             transforms.Resize((self.input_width, self.input_width)),\n#         ])\n#         self.train_dataset = CustomDataset(\n#             root_dir='/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/',\n#             transform=transform,\n#         )\n#         self.val_dataset = CustomDataset(\n#             root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/',\n#             transform=transform,\n#         )\n#         self.test_dataset = CustomDataset(\n#             root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/',\n#             transform=transform,\n#         )\n\n#     def train_dataloader(self):\n#         return DataLoader(self.train_dataset, batch_size=self.hparams['batch_size'])\n\n#     def val_dataloader(self):\n#         return DataLoader(self.val_dataset, batch_size=self.hparams['batch_size'])\n\n#     def test_dataloader(self):\n#         return DataLoader(self.test_dataset, batch_size=self.hparams['batch_size'])\n\n#     def on_train_start(self):\n#         if self.pretrained_model_path:\n#             self.load_state_dict(torch.load(self.pretrained_model_path))\n\n#     def generate_images(self, num_images):\n#         z = torch.randn(num_images, self.latent_dim, device=self.device)\n#         with torch.no_grad():\n#             generated_images = self(z)\n#         generated_images = generated_images.permute(0, 2, 3, 1).cpu().numpy()\n#         generated_images = (generated_images * 255).astype(np.uint8)\n#         return generated_images\n\n#     def forward(self, input, target):\n#         input = torch.sigmoid(input)\n#         target = torch.sigmoid(target)\n#         return F.binary_cross_entropy_with_logits(input, target, weight=self.weight, reduction=self.reduction)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:24:23.244673Z","iopub.execute_input":"2023-05-06T06:24:23.248445Z","iopub.status.idle":"2023-05-06T06:24:23.258649Z","shell.execute_reply.started":"2023-05-06T06:24:23.248328Z","shell.execute_reply":"2023-05-06T06:24:23.257647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !conda create --name env_name python=3.7","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:24:23.260819Z","iopub.execute_input":"2023-05-06T06:24:23.261350Z","iopub.status.idle":"2023-05-06T06:24:23.299172Z","shell.execute_reply.started":"2023-05-06T06:24:23.261320Z","shell.execute_reply":"2023-05-06T06:24:23.298281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torch==1.8.1\n!pip install -q Pillow\n!pip install -q lightning-lite==1.8.0\n# !pip install -q pytorch-lightning==1.8.0\n!pip install -q pytorch-lightning --upgrade\n!pip install -q git+https://github.com/PytorchLightning/lightning-bolts.git@master --upgrade\n!pip install -q lightning-utilities==0.3.0","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:24:23.303195Z","iopub.execute_input":"2023-05-06T06:24:23.303526Z","iopub.status.idle":"2023-05-06T06:25:27.191414Z","shell.execute_reply.started":"2023-05-06T06:24:23.303492Z","shell.execute_reply":"2023-05-06T06:25:27.190288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -q torch==1.8.1\n# !pip install -q Pillow\n# !pip install -q lightning-lite==1.8.1\n# !pip install -q pytorch-lightning==1.8.1\n# !pip install -q lightning-bolts==0.6.0.post1\n# !pip install -q lightning-utilities==0.3.0","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:27.193785Z","iopub.execute_input":"2023-05-06T06:25:27.194507Z","iopub.status.idle":"2023-05-06T06:25:27.199263Z","shell.execute_reply.started":"2023-05-06T06:25:27.194465Z","shell.execute_reply":"2023-05-06T06:25:27.198028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pytorch_lightning as pl\nfrom matplotlib import pyplot as plt\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, utils\nfrom PIL import Image\nfrom pl_bolts.models.gans import DCGAN, GAN, SRGAN, Pix2Pix\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.utilities import rank_zero_only\nimport torch.nn.functional as F\n\nfrom typing import Optional, Callable, Union, Any\nfrom pytorch_lightning import LightningDataModule\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:27.200814Z","iopub.execute_input":"2023-05-06T06:25:27.201938Z","iopub.status.idle":"2023-05-06T06:25:39.614022Z","shell.execute_reply.started":"2023-05-06T06:25:27.201906Z","shell.execute_reply":"2023-05-06T06:25:39.611862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_list = os.listdir(root_dir)\n\n    def __len__(self):\n        return len(self.image_list)\n\n    def __getitem__(self, index):\n        # get one sample from dataset\n        image_name = os.path.join(self.root_dir, self.image_list[index])\n        image = np.array(Image.open(image_name).convert('RGB'))  # convert to grayscale\n        image = image.astype(np.float32)\n        if self.transform:\n            image = self.transform(image)\n        return image, 0  # return the image as target","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:39.615523Z","iopub.execute_input":"2023-05-06T06:25:39.616072Z","iopub.status.idle":"2023-05-06T06:25:39.623180Z","shell.execute_reply.started":"2023-05-06T06:25:39.615882Z","shell.execute_reply":"2023-05-06T06:25:39.621956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataModule(pl.LightningDataModule):\n    def __init__(self, transform, batch_size=16):\n        super().__init__()\n        self.batch_size = batch_size\n        self.train_dataset = CustomDataset(\n            root_dir='/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/',\n            transform=transform,\n        )\n        self.val_dataset = CustomDataset(\n            root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/',\n            transform=transform,\n        )\n        self.test_dataset = CustomDataset(\n            root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/',\n            transform=transform,\n        )\n\n    def train_dataloader(self):\n        # return your training dataloader\n        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n\n    def val_dataloader(self):\n        # return your validation dataloader\n        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n\n    def test_dataloader(self):\n        # return your test dataloader\n        return DataLoader(self.test_dataset, batch_size=self.batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:39.624605Z","iopub.execute_input":"2023-05-06T06:25:39.625188Z","iopub.status.idle":"2023-05-06T06:25:39.636898Z","shell.execute_reply.started":"2023-05-06T06:25:39.625156Z","shell.execute_reply":"2023-05-06T06:25:39.635893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class SRGAN(SRGAN):\n#     def validation_step(self, batch, batch_idx):\n#         x, y = batch\n#         y_hat = self(x)\n#         val_loss = F.mse_loss(y_hat, y)\n#         return val_loss\n    \n#     def validation_step(self, batch, batch_idx):\n#         x, y = batch\n#         if y is None:  # skip if y is None\n#             return\n#         y_hat = x\n#         val_loss = F.mse_loss(y_hat, y)\n#         return val_loss\n    \n#     def forward(self, x):\n#         print('Input shape:', x.shape)\n#         x = self.input_block(x)\n\n# class DCGAN(DCGAN):\n#     def configure_optimizers(self):\n#         if self.trainer.sanity_checking:\n#             return torch.optim.Adam(self.parameters(), lr=1e-3)\n#         elif self.trainer.current_epoch < 5:\n#             return torch.optim.Adam(self.parameters(), lr=1e-3)\n#         else:\n#             return [torch.optim.SGD(self.parameters(), lr=1e-3, momentum=0.9),\n#                     torch.optim.Adam(self.parameters(), lr=1e-4)]\n    \n#     def training_step(self, batch, batch_idx, optimizer_idx):\n#         real_images, _ = batch\n#         batch_size = real_images.size(0)\n\n#         # Generate images from the noise\n#         noise = torch.randn(batch_size, 100, 1, 1, device=self.device)\n#         fake_images = self.generator(noise)\n\n#         # Train the discriminator on the real images\n#         if optimizer_idx == 0:\n#             # Reset discriminator gradients\n#             self.discriminator.zero_grad()\n\n#             # Compute discriminator loss on real images\n#             real_labels = torch.ones(batch_size, 1, device=self.device)\n#             real_scores = self.discriminator(real_images)\n#             d_real_loss = F.binary_cross_entropy_with_logits(real_scores, real_labels)\n\n#             # Compute discriminator loss on fake images\n#             fake_labels = torch.zeros(batch_size, 1, device=self.device)\n#             fake_scores = self.discriminator(fake_images.detach())\n#             d_fake_loss = F.binary_cross_entropy_with_logits(fake_scores, fake_labels)\n\n#             # Compute total discriminator loss and update discriminator weights\n#             d_loss = d_real_loss + d_fake_loss\n#             self.manual_backward(d_loss)\n#             self.discriminator_opt.step()\n\n#             # Log discriminator loss\n#             self.log(\"d_loss\", d_loss, on_step=True, on_epoch=True, prog_bar=True)\n\n#         # Train the generator\n#         if optimizer_idx == 1:\n#             # Reset generator gradients\n#             self.generator.zero_grad()\n\n#             # Generate fake images and compute generator loss\n#             labels = torch.ones(batch_size, 1, device=self.device)\n#             scores = self.discriminator(fake_images)\n#             g_loss = F.binary_cross_entropy_with_logits(scores, labels)\n\n#             # Update generator weights\n#             self.manual_backward(g_loss)\n#             self.generator_opt.step()\n\n#             # Log generator loss\n#             self.log(\"g_loss\", g_loss, on_step=True, on_epoch=True, prog_bar=True)\n\n#         return {'loss': d_loss + g_loss} # Return total loss for logging purposes","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:39.638525Z","iopub.execute_input":"2023-05-06T06:25:39.639112Z","iopub.status.idle":"2023-05-06T06:25:39.651767Z","shell.execute_reply.started":"2023-05-06T06:25:39.639078Z","shell.execute_reply":"2023-05-06T06:25:39.650772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     checkpoint_callback = ModelCheckpoint(\n#         dirpath='./models',\n#         filename='vae-{epoch:02d}-{step:02d}-{val_loss:.2f}',\n#         save_top_k=3,\n#         verbose=True,\n#         monitor='val_loss',\n#         mode='min',\n#         every_n_epochs=25  # set n to the desired number of iterations\n#     )\n\n#     # Run learning rate finder\n#     lr_finder = trainer.tuner.lr_find(model, datamodule=data_module)\n\n#     # Results can be found in\n#     lr_finder.results\n\n#     # Plot with\n#     fig = lr_finder.plot(suggest=True)\n#     fig.show()\n\n#     # Pick point based on plot, or get suggestion\n#     new_lr = lr_finder.suggestion()\n\n#     # update hparams of the model\n#     model.hparams.lr = new_lr","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:25:39.655139Z","iopub.execute_input":"2023-05-06T06:25:39.656050Z","iopub.status.idle":"2023-05-06T06:25:39.664250Z","shell.execute_reply.started":"2023-05-06T06:25:39.656024Z","shell.execute_reply":"2023-05-06T06:25:39.663315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.optim import Adam\n\nclass DCGAN(DCGAN):\n    # example with learning rate schedulers\n    def configure_optimizers(self):\n        lr = self.hparams.learning_rate\n        betas = (self.hparams.beta1, 0.999)\n        opt_disc = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=betas)\n        opt_gen = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=betas)\n        disc_sch = ReduceLROnPlateau(opt_disc, mode='min', factor=0.1, patience=10, verbose=True)\n        gen_sch = ReduceLROnPlateau(opt_gen, mode='min', factor=0.1, patience=10, verbose=True)\n        return (\n            {\n                \"optimizer\": opt_disc,\n                \"lr_scheduler\": {\n                    \"scheduler\": disc_sch,\n                    \"monitor\": \"loss/disc\",\n                },\n            }, {\n                \"optimizer\": opt_gen, \n                \"lr_scheduler\": {\n                    \"scheduler\": gen_sch,\n                    \"monitor\": \"loss/gen\",\n                },\n            },\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:52:24.029504Z","iopub.execute_input":"2023-05-06T06:52:24.030360Z","iopub.status.idle":"2023-05-06T06:52:24.038163Z","shell.execute_reply.started":"2023-05-06T06:52:24.030328Z","shell.execute_reply":"2023-05-06T06:52:24.037124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    pretrained_model_path = None\n    batch_size = 4096\n\n    gan_params = {\n        'image_channels': 3, # input_channels\n        'input_height': 64,\n        'input_width': 64,\n        'latent_dim': 512,\n        'learning_rate': 0.000001,\n        'feature_maps_gen': 64,\n        'feature_maps_disc': 64,\n    }\n\n    # Initialize a trainer instance and train the model\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Resize((gan_params['input_width'], gan_params['input_height']), antialias=True),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    model = DCGAN(**gan_params)\n\n    checkpoint_path = 'checkpoint.pth'\n    if os.path.exists(checkpoint_path):\n        print(f\"Loading from existing checkpoint: {checkpoint_path}\")\n        model.load_state_dict(torch.load(checkpoint_path))\n\n    data_module = MyDataModule(transform, batch_size=batch_size)\n\n#     trainer = pl.Trainer(\n#         auto_lr_find=True,\n#     )\n\n#     trainer.tune(model, data_module)\n#     # Find optimal learning rate\n#     lr_finder = trainer.tune.lr_find(model, datamodule=data_module)\n#     fig = lr_finder.plot(suggest=True)\n#     plt.show()\n    \n#     # Set suggested learning rate\n#     gan_params['learning_rate'] = lr_finder.suggestion()\n    \n#     # Learning rate logger\n#     lr_logger = LearningRateLogger()\n    \n#     # Reduce learning rate on plateau\n#     lr_scheduler = ReduceLROnPlateau(\n#         monitor='val_loss', # the metric to monitor\n#         factor=0.1,         # the factor to reduce the learning rate by\n#         patience=10,        # the number of epochs with no improvement after which learning rate will be reduced\n#         verbose=True,       # print a message when the learning rate is reduced\n#         mode='min'          # the direction of the metric (minimizing val_loss)\n#     )\n    \n    trainer = pl.Trainer(\n#         callbacks=[lr_logger], # lr_scheduler\n        accelerator='gpu',\n        devices=1,\n        sync_batchnorm=True,\n        max_epochs=25,\n        precision=32,\n        auto_lr_find=True,\n        val_check_interval=1.0,\n        accumulate_grad_batches=1,\n        gradient_clip_val=0.5,\n        gradient_clip_algorithm=\"value\",\n        limit_train_batches=1.0,\n        limit_val_batches=1.0,\n        # log_every_n_steps=10,\n        num_sanity_val_steps=1,\n        # auto_scale_batch_size='power',  #auto_scale_batch_size='binsearch',\n        # auto_select_gpus=True,\n        overfit_batches=0.0,\n        # plugins=None,\n        # profiler=None,\n        replace_sampler_ddp=True,\n        # tpu_cores=None,\n        track_grad_norm=-1,\n        benchmark=True,\n    )\n    \n    trainer.fit(\n        model,\n        datamodule=data_module\n    )\n\n    torch.save(model.state_dict(), checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:52:28.175998Z","iopub.execute_input":"2023-05-06T06:52:28.176349Z","iopub.status.idle":"2023-05-06T06:55:34.265950Z","shell.execute_reply.started":"2023-05-06T06:52:28.176320Z","shell.execute_reply":"2023-05-06T06:55:34.264684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate and view images\nmodel.eval()\nwith torch.no_grad():\n    z = torch.randn(batch_size, model.hparams.latent_dim)\n    generated_imgs = model(z)\n    generated_imgs = generated_imgs.view(-1, 3, model.hparams.input_height, model.hparams.input_width)  # Reshape to (batch_size, channels, height, width)\n    if batch_size >= 16:\n        # Display up to 16 images in a 4x4 grid\n        num_images = min(batch_size, 16)\n        grid = utils.make_grid(generated_imgs[:num_images], nrow=4)\n        plt.imshow(grid.permute(1, 2, 0))\n        plt.show()\n    else:\n        # Display images in a single row\n        fig, axs = plt.subplots(1, batch_size, figsize=(batch_size * 2, 2))\n        for i in range(batch_size):\n            axs[i].imshow(generated_imgs[i].permute(1, 2, 0))\n            axs[i].axis('off')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T06:56:19.007755Z","iopub.execute_input":"2023-05-06T06:56:19.008158Z","iopub.status.idle":"2023-05-06T06:56:41.921229Z","shell.execute_reply.started":"2023-05-06T06:56:19.008131Z","shell.execute_reply":"2023-05-06T06:56:41.920423Z"},"trusted":true},"execution_count":null,"outputs":[]}]}