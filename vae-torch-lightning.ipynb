{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:2]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-22T07:34:28.273728Z","iopub.execute_input":"2023-04-22T07:34:28.274035Z","iopub.status.idle":"2023-04-22T07:34:46.052318Z","shell.execute_reply.started":"2023-04-22T07:34:28.274006Z","shell.execute_reply":"2023-04-22T07:34:46.051243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/14986.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/3138.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/street/1269.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/street/6241.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/buildings/2193.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/buildings/11378.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/sea/19812.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/sea/16916.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/forest/7981.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/forest/3863.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/glacier/12666.jpg\n/kaggle/input/intel-image-classification/seg_train/seg_train/glacier/13288.jpg\n/kaggle/input/intel-image-classification/seg_pred/seg_pred/6234.jpg\n/kaggle/input/intel-image-classification/seg_pred/seg_pred/22288.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/22608.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/23274.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/street/20088.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/street/21494.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/buildings/22735.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/buildings/22706.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/sea/20513.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/sea/24201.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/forest/23407.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/forest/20938.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/glacier/23149.jpg\n/kaggle/input/intel-image-classification/seg_test/seg_test/glacier/21575.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#!pip uninstall -y protobuf\n#!pip install protobuf==3.20.2","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:34:46.054368Z","iopub.execute_input":"2023-04-22T07:34:46.054747Z","iopub.status.idle":"2023-04-22T07:34:46.059124Z","shell.execute_reply.started":"2023-04-22T07:34:46.054702Z","shell.execute_reply":"2023-04-22T07:34:46.058030Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#!pip install -q dask==2021.11.2\n#!pip install -q lightning-bolts[\"extra\"]\n#!pip install git+https://github.com/PytorchLightning/lightning-bolts.git@master --upgrade\n!pip install -q lightning-bolts==0.6.0.post1\n!pip install -q lightning-lite==1.8.0\n!pip install -q lightning-utilities==0.3.0\n!pip install -q pytorch-lightning<1.9.0","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:34:46.060621Z","iopub.execute_input":"2023-04-22T07:34:46.061250Z","iopub.status.idle":"2023-04-22T07:35:20.820579Z","shell.execute_reply.started":"2023-04-22T07:34:46.061211Z","shell.execute_reply":"2023-04-22T07:35:20.819362Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 1.9.4 requires lightning-utilities>=0.6.0.post0, but you have lightning-utilities 0.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/bin/bash: 1.9.0: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"#from pytorch_lightning.loggers import TensorBoardLogger\n#from pytorch_lightning.callbacks import EarlyStopping\n#from pytorch_lightning.loggers.base import LightningLoggerBase","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:20.824124Z","iopub.execute_input":"2023-04-22T07:35:20.824923Z","iopub.status.idle":"2023-04-22T07:35:20.831542Z","shell.execute_reply.started":"2023-04-22T07:35:20.824888Z","shell.execute_reply":"2023-04-22T07:35:20.828815Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\nfrom pl_bolts.models.autoencoders import VAE\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom PIL import Image\n\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.utilities import rank_zero_only","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:20.833268Z","iopub.execute_input":"2023-04-22T07:35:20.833684Z","iopub.status.idle":"2023-04-22T07:35:23.762956Z","shell.execute_reply.started":"2023-04-22T07:35:20.833627Z","shell.execute_reply":"2023-04-22T07:35:23.760209Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/2588879157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pytorch_lightning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallback\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningModule\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFabric\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed_everything\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/fabric.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecision\u001b[0m  \u001b[0;31m# avoid circular imports: # isort: split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_Connector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PLUGIN_INPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PRECISION_INPUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/plugins/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# See the License for the specific language governing permissions and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCheckpointIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchCheckpointIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/plugins/environments/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslurm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSLURMEnvironment\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchelastic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchElasticEnvironment\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXLAEnvironment\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/plugins/environments/xla.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_XLA_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTPUAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/accelerators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPSAccelerator\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_AcceleratorRegistry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_register_accelerators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUAccelerator\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_ACCELERATORS_BASE_MODULE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lightning_fabric.accelerators\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightning_fabric/accelerators/tpu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_utilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModuleAvailableCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccelerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'ModuleAvailableCache' from 'lightning_utilities.core.imports' (/opt/conda/lib/python3.7/site-packages/lightning_utilities/core/imports.py)"],"ename":"ImportError","evalue":"cannot import name 'ModuleAvailableCache' from 'lightning_utilities.core.imports' (/opt/conda/lib/python3.7/site-packages/lightning_utilities/core/imports.py)","output_type":"error"}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_list = os.listdir(root_dir)\n\n    def __len__(self):\n        return len(self.image_list)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir, self.image_list[idx])\n        image = Image.open(img_name)\n\n        if self.transform:\n            image = self.transform(image)\n\n        # Get class label from image directory name\n        label = os.path.basename(self.root_dir)\n\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:23.764100Z","iopub.status.idle":"2023-04-22T07:35:23.766733Z","shell.execute_reply.started":"2023-04-22T07:35:23.766534Z","shell.execute_reply":"2023-04-22T07:35:23.766557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAEModel(VAE):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.save_hyperparameters()\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams['lr'])\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams['max_epochs'])\n        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n    def training_step(self, batch, batch_idx):\n        loss = super().training_step((batch, 0), batch_idx)\n        #self.log('train_loss', loss, on_epoch=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        loss = super().validation_step((batch, 0), batch_idx)\n        #self.log('val_loss', loss, on_epoch=True)\n    \n    def test_step(self, batch, batch_idx):\n        loss = super().test_step((batch, 0), batch_idx)\n        #self.log('test_loss', loss, on_epoch=True)\n\n    def train_dataloader(self):\n        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((self.input_height, self.input_height)),])\n        train_dataset = CustomDataset(root_dir='/kaggle/input/intel-image-classification/seg_train/seg_train/mountain/', transform=transform)\n        return DataLoader(train_dataset, batch_size=self.hparams['batch_size'])\n\n    def val_dataloader(self):\n        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((self.input_height, self.input_height)),])\n        val_dataset = CustomDataset(root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/', transform=transform)\n        return DataLoader(val_dataset, batch_size=self.hparams['batch_size'])\n\n    def test_dataloader(self):\n        transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((self.input_height, self.input_height)),])\n        test_dataset = CustomDataset(root_dir='/kaggle/input/intel-image-classification/seg_test/seg_test/mountain/', transform=transform)\n        return DataLoader(test_dataset, batch_size=self.hparams['batch_size'])\n\n    def on_train_start(self):\n        if self.hparams['pretrained_model_path']:\n            self.load_state_dict(torch.load(self.hparams['pretrained_model_path']))\n\n    def generate_images(self, num_images):\n        z = torch.randn(num_images, self.latent_dim, device=self.device)\n        with torch.no_grad():\n            generated_images = self.decoder(z)\n        generated_images = generated_images.permute(0, 2, 3, 1).cpu().numpy()\n        generated_images = (generated_images * 255).astype(np.uint8)\n        return generated_images","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:23.769631Z","iopub.status.idle":"2023-04-22T07:35:23.769987Z","shell.execute_reply.started":"2023-04-22T07:35:23.769814Z","shell.execute_reply":"2023-04-22T07:35:23.769832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    hparams = {\n        'input_height': 64,\n        'latent_dim': 768,\n        'max_epochs': 250,\n        'batch_size': 128,\n        'pretrained_model_path': None\n    }\n    checkpoint_callback = ModelCheckpoint(\n        dirpath='./models',\n        filename='vae-{epoch:02d}-{step:02d}-{val_loss:.2f}',\n        save_top_k=3,\n        verbose=True,\n        monitor='val_loss',\n        mode='min',\n        every_n_epochs=25  # set n to the desired number of iterations\n    )\n    #logger = TensorBoardLogger(save_dir=\"logs/\")\n    # Initialize a trainer instance and train the model\n    trainer = pl.Trainer(\n        max_epochs=250,\n        accelerator='gpu',\n        devices=1,\n        precision=16,\n        #limit_train_batches=0.1,\n        #limit_val_batches=0.1,\n        auto_lr_find=True,\n        callbacks=[checkpoint_callback],\n        sync_batchnorm=True,\n    )\n    model = VAEModel(**hparams)\n    trainer.fit(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:23.771235Z","iopub.status.idle":"2023-04-22T07:35:23.772504Z","shell.execute_reply.started":"2023-04-22T07:35:23.772213Z","shell.execute_reply":"2023-04-22T07:35:23.772241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Generate some images\ngenerated_images = model.generate_images(num_images=4)\n\nprint(generated_images[0].shape)\n\n# Plot the generated images\nfig, axs = plt.subplots(1, 4)\nfor i in range(4):\n    axs[i].imshow(generated_images[i])\n    axs[i].axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:23.774066Z","iopub.status.idle":"2023-04-22T07:35:23.774940Z","shell.execute_reply.started":"2023-04-22T07:35:23.774676Z","shell.execute_reply":"2023-04-22T07:35:23.774703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(hparams['latent_dim'])","metadata":{"execution":{"iopub.status.busy":"2023-04-22T07:35:23.776396Z","iopub.status.idle":"2023-04-22T07:35:23.777275Z","shell.execute_reply.started":"2023-04-22T07:35:23.777012Z","shell.execute_reply":"2023-04-22T07:35:23.777038Z"},"trusted":true},"execution_count":null,"outputs":[]}]}