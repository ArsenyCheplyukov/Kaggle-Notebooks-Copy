{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:03:08.73064Z","iopub.execute_input":"2021-07-17T19:03:08.730956Z","iopub.status.idle":"2021-07-17T19:03:10.093183Z","shell.execute_reply.started":"2021-07-17T19:03:08.730888Z","shell.execute_reply":"2021-07-17T19:03:10.092006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:03:26.299896Z","iopub.execute_input":"2021-07-17T19:03:26.300301Z","iopub.status.idle":"2021-07-17T19:03:26.316603Z","shell.execute_reply.started":"2021-07-17T19:03:26.300246Z","shell.execute_reply":"2021-07-17T19:03:26.315528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters etc\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 5e-5\nBATCH_SIZE = 32\nIMAGE_SIZE = 64\nCHANNELS_IMG = 1\nZ_DIM = 128\nNUM_EPOCHS = 10\nFEATURES_CRITIC = 64\nFEATURES_GEN = 64\nCRITIC_ITERATIONS = 5\nWEIGHT_CLIP = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:03:50.088481Z","iopub.execute_input":"2021-07-17T19:03:50.088824Z","iopub.status.idle":"2021-07-17T19:03:50.132567Z","shell.execute_reply.started":"2021-07-17T19:03:50.088783Z","shell.execute_reply":"2021-07-17T19:03:50.131725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        tuple([0.5 for _ in range(CHANNELS_IMG)]), tuple([0.5 for _ in range(CHANNELS_IMG)])\n    ),\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:03:54.011978Z","iopub.execute_input":"2021-07-17T19:03:54.012289Z","iopub.status.idle":"2021-07-17T19:03:54.018313Z","shell.execute_reply.started":"2021-07-17T19:03:54.012261Z","shell.execute_reply":"2021-07-17T19:03:54.017396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n#comment mnist and uncomment below if you want to train on CelebA dataset\n#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\nloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:04:00.230075Z","iopub.execute_input":"2021-07-17T19:04:00.23039Z","iopub.status.idle":"2021-07-17T19:06:04.580585Z","shell.execute_reply.started":"2021-07-17T19:04:00.230361Z","shell.execute_reply":"2021-07-17T19:06:04.579734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # input: N x channels_img x 64 x 64\n            nn.Conv2d(\n                channels_img, features_d, kernel_size=4, stride=2, padding=1\n            ),\n            nn.LeakyReLU(0.2),\n            # _block(in_channels, out_channels, kernel_size, stride, padding)\n            self._block(features_d, features_d * 2, 4, 2, 1),\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:07.527058Z","iopub.execute_input":"2021-07-17T19:06:07.52737Z","iopub.status.idle":"2021-07-17T19:06:07.536128Z","shell.execute_reply.started":"2021-07-17T19:06:07.52734Z","shell.execute_reply":"2021-07-17T19:06:07.535068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, channels_noise, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            # Input: N x channels_noise x 1 x 1\n            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            nn.ConvTranspose2d(\n                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n            ),\n            # Output: N x channels_img x 64 x 64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:10.542844Z","iopub.execute_input":"2021-07-17T19:06:10.543166Z","iopub.status.idle":"2021-07-17T19:06:10.5513Z","shell.execute_reply.started":"2021-07-17T19:06:10.543137Z","shell.execute_reply":"2021-07-17T19:06:10.550484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize gen and disc/critic\ngen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\ncritic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:13.181116Z","iopub.execute_input":"2021-07-17T19:06:13.181432Z","iopub.status.idle":"2021-07-17T19:06:17.433792Z","shell.execute_reply.started":"2021-07-17T19:06:13.181402Z","shell.execute_reply":"2021-07-17T19:06:17.432951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initializate optimizer\nopt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\nopt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:18.931108Z","iopub.execute_input":"2021-07-17T19:06:18.931412Z","iopub.status.idle":"2021-07-17T19:06:18.936104Z","shell.execute_reply.started":"2021-07-17T19:06:18.931385Z","shell.execute_reply":"2021-07-17T19:06:18.935044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for tensorboard plotting\nfixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0\n\ngen.train()\ncritic.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:20.612245Z","iopub.execute_input":"2021-07-17T19:06:20.61256Z","iopub.status.idle":"2021-07-17T19:06:22.288468Z","shell.execute_reply.started":"2021-07-17T19:06:20.612529Z","shell.execute_reply":"2021-07-17T19:06:22.287577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    # Target labels not needed! <3 unsupervised\n    for batch_idx, (data, _) in enumerate(loader):\n        data = data.to(device)\n        cur_batch_size = data.shape[0]\n\n        # Train Critic: max E[critic(real)] - E[critic(fake)]\n        for _ in range(CRITIC_ITERATIONS):\n            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n            fake = gen(noise)\n            critic_real = critic(data).reshape(-1)\n            critic_fake = critic(fake).reshape(-1)\n            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n            critic.zero_grad()\n            loss_critic.backward(retain_graph=True)\n            opt_critic.step()\n\n            # clip critic weights between -0.01, 0.01\n            for p in critic.parameters():\n                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n\n        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n        gen_fake = critic(fake).reshape(-1)\n        loss_gen = -torch.mean(gen_fake)\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n\n        # Print losses occasionally and print to tensorboard\n        if batch_idx % BATCH_SIZE == 0 and batch_idx > 0:\n            gen.eval()\n            critic.eval()\n            print(\n                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n            )\n\n            with torch.no_grad():\n                fake = gen(noise)\n                # take out (up to) 32 examples\n                img_grid_real = torchvision.utils.make_grid(\n                    data[:32], normalize=True\n                )\n                img_grid_fake = torchvision.utils.make_grid(\n                    fake[:32], normalize=True\n                )\n\n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n\n            step += 1\n            gen.train()\n            critic.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T19:06:26.879938Z","iopub.execute_input":"2021-07-17T19:06:26.880278Z","iopub.status.idle":"2021-07-17T21:50:02.169874Z","shell.execute_reply.started":"2021-07-17T19:06:26.880252Z","shell.execute_reply":"2021-07-17T21:50:02.168816Z"},"trusted":true},"execution_count":null,"outputs":[]}]}