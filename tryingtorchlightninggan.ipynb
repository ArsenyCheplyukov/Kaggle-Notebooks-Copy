{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-08T17:27:30.512026Z","iopub.execute_input":"2023-05-08T17:27:30.512415Z","iopub.status.idle":"2023-05-08T17:27:30.536773Z","shell.execute_reply.started":"2023-05-08T17:27:30.512360Z","shell.execute_reply":"2023-05-08T17:27:30.535918Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets import ImageFolder\nimport pytorch_lightning as pl\n\nclass MyDataModule(pl.LightningDataModule):\n    def __init__(self, root_dir, batch_size, image_size):\n        super().__init__()\n        self.root_dir = root_dir\n        self.batch_size = batch_size\n        self.image_size = image_size\n\n    def setup(self, stage=None):\n        # transforms for images\n        transform=pl.transforms.Compose([\n            pl.transforms.Resize(self.image_size),\n            pl.transforms.CenterCrop(self.image_size),\n            pl.transforms.ToTensor(),\n            pl.transforms.Normalize((0,0,0), (1,1,1))\n        ])\n\n        # load the dataset\n        self.dataset = ImageFolder(root=self.root_dir, transform=transform)\n\n    def train_dataloader(self):\n        return pl.DataLoader(self.dataset, batch_size=self.batch_size,\n                              shuffle=True, num_workers=2)\n\n    def val_dataloader(self):\n        return pl.DataLoader(self.dataset, batch_size=self.batch_size,\n                              shuffle=False, num_workers=2)\n\n    def test_dataloader(self):\n        return pl.DataLoader(self.dataset, batch_size=self.batch_size,\n                              shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T17:27:30.538720Z","iopub.execute_input":"2023-05-08T17:27:30.539215Z","iopub.status.idle":"2023-05-08T17:27:47.799891Z","shell.execute_reply.started":"2023-05-08T17:27:30.539183Z","shell.execute_reply":"2023-05-08T17:27:47.797957Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score \u001b[38;5;28;01mas\u001b[39;00m accuracy\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning.metrics'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pytorch_lightning.metrics'","output_type":"error"}]},{"cell_type":"code","source":"dm = MyDataModule(root_dir='/kaggle/input/intel-image-classification/seg_train/seg_train/',\n                  batch_size=batch_size, image_size=image_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T17:27:47.800676Z","iopub.status.idle":"2023-05-08T17:27:47.801103Z","shell.execute_reply.started":"2023-05-08T17:27:47.800866Z","shell.execute_reply":"2023-05-08T17:27:47.800911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, nz, ngf, nc):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\nclass Discriminator(nn.Module):\n    def __init__(self, ndf, nc):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n    def forward(self, input):\n        return self.main(input)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T17:27:47.802337Z","iopub.status.idle":"2023-05-08T17:27:47.802701Z","shell.execute_reply.started":"2023-05-08T17:27:47.802532Z","shell.execute_reply":"2023-05-08T17:27:47.802548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN(pl.LightningModule):\n    def __init__(self, hparams):\n        super().__init__()\n        self.hparams = hparams\n        self.generator = Generator(self.hparams.nz, self.hparams.ngf, self.hparams.nc)\n        self.discriminator = Discriminator(self.hparams.ndf, self.hparams.nc)\n        self.example_input_array = torch.zeros(2, self.hparams.nz, 1, 1)\n        self.criterion = nn.BCELoss()\n\n    def forward(self, z):\n        return self.generator(z)\n\n    def adversarial_loss(self, y_hat, y):\n        return self.criterion(y_hat, y)\n\n    def training_step(self, batch, batch_idx, optimizer_idx):\n        real, _ = batch\n        real = real.to(self.device)\n        batch_size = real.size(0)\n        valid = torch.ones(batch_size, 1, device=self.device)\n        fake = torch.zeros(batch_size, 1, device=self.device)\n\n        if optimizer_idx == 0:\n            z = torch.randn(batch_size, self.hparams.nz, 1, 1, device=self.device)\n            generated_imgs = self(z)\n            g_loss = self.adversarial_loss(self.discriminator(generated_imgs), valid)\n            self.log('g_loss', g_loss)\n            return g_loss\n\n        if optimizer_idx == 1:\n            z = torch.randn(batch_size, self.hparams.nz, 1, 1, device=self.device)\n            generated_imgs = self(z)\n            real_loss = self.adversarial_loss(self.discriminator(real), valid)\n            fake_loss = self.adversarial_loss(self.discriminator(generated_imgs.detach()), fake)\n            d_loss = (real_loss + fake_loss) / 2\n            self.log('d_loss', d_loss)\n            return d_loss\n\n    def configure_optimizers(self):\n        opt_g = optim.Adam(self.generator.parameters(), lr=self.hparams.lr, betas=(0.5, 0.999))\n        opt_d = optim.Adam(self.discriminator.parameters(), lr=self.hparams.lr, betas=(0.5, 0.999))\n        return [opt_g, opt_d], []\n\n    def on_epoch_end(self):\n        z = torch.randn(1, self.hparams.nz, 1, 1, device=self.device)\n        sample_image = self(z)\n        self.logger.experiment.add_image('generated_image', sample_image[0], self.current_epoch)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T17:27:47.804517Z","iopub.status.idle":"2023-05-08T17:27:47.805076Z","shell.execute_reply.started":"2023-05-08T17:27:47.804785Z","shell.execute_reply":"2023-05-08T17:27:47.804811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Set the hyperparameters\nhparams = argparse.Namespace()\nhparams.root_dir = 'cifar10'\nhparams.batch_size = 64\nhparams.image_size = 64\nhparams.nz = 100\nhparams.ngf = 64\nhparams.ndf = 64\nhparams.nc = 3\nhparams.lr = 0.0002\nhparams.beta1 = 0.5\nhparams.beta2 = 0.999\nhparams.n_epochs = 10\n\n# Instantiate the data module\ndm = MyDataModule(hparams.root_dir, hparams.batch_size, hparams.image_size)\n\n# Instantiate the model\nmodel = GAN(hparams)\n\n# Instantiate a checkpoint callback to save the best model\ncheckpoint_callback = ModelCheckpoint(monitor='d_loss', mode='min')\n\n# Train the model\ntrainer = pl.Trainer(gpus=1, max_epochs=hparams.n_epochs, checkpoint_callback=checkpoint_callback)\ntrainer.fit(model, dm)\n\n# Generate some sample images\nnoise = torch.randn(64, hparams.nz, 1, 1)\nfake_images = model.generator(noise).detach().cpu()\ngrid = vutils.make_grid(fake_images, nrow=8, padding=2, normalize=True)\n\n# Save the generated images to a file\nvutils.save_image(grid, 'generated_images.png')\n\n# Load the generated image\nimg = Image.open('generated_images.png')\n\n# Display the image using matplotlib\nplt.imshow(img)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T17:27:47.808671Z","iopub.status.idle":"2023-05-08T17:27:47.809601Z","shell.execute_reply.started":"2023-05-08T17:27:47.809317Z","shell.execute_reply":"2023-05-08T17:27:47.809344Z"},"trusted":true},"execution_count":null,"outputs":[]}]}