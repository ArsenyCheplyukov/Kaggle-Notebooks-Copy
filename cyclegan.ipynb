{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport sys\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom PIL import Image\nimport os\nimport numpy as np \nimport random\nimport copy\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision.utils import save_image","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:28.078612Z","iopub.execute_input":"2021-07-18T21:25:28.078896Z","iopub.status.idle":"2021-07-18T21:25:31.645064Z","shell.execute_reply.started":"2021-07-18T21:25:28.078864Z","shell.execute_reply":"2021-07-18T21:25:31.644072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!md ./\n!mkdir genh\n!mkdir genz\n!mkdir critich\n!mkdir criticz","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:31.649747Z","iopub.execute_input":"2021-07-18T21:25:31.650059Z","iopub.status.idle":"2021-07-18T21:25:35.186397Z","shell.execute_reply.started":"2021-07-18T21:25:31.650031Z","shell.execute_reply":"2021-07-18T21:25:35.185294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTRAIN_DIR = f\"../input/paired-landscape-and-monetstylised-image/monet_style_dataset/monet_style_dataset_A/\"\nVAL_DIR = f\"../input/paired-landscape-and-monetstylised-image/monet_style_dataset/monet_style_dataset_B/\"\nBATCH_SIZE = 4\nLEARNING_RATE = 1e-5\nLAMBDA_IDENTITY = 0.0\nLAMBDA_CYCLE = 10\nNUM_WORKERS = 4\nNUM_EPOCHS = 5\nLOAD_MODEL = False\nSAVE_MODEL = True\nCHECKPOINT_GEN_H = \"./genh.pth.tar\"\nCHECKPOINT_GEN_Z = \"./genz.pth.tar\"\nCHECKPOINT_CRITIC_H = \"./critich.pth.tar\"\nCHECKPOINT_CRITIC_Z = \"./criticz.pth.tar\"\n\ntransforms = A.Compose([\n    A.Resize(width=256, height=256),\n    A.HorizontalFlip(p=0.5),\n    A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n    ToTensorV2(),\n ])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.189937Z","iopub.execute_input":"2021-07-18T21:25:35.190216Z","iopub.status.idle":"2021-07-18T21:25:35.250024Z","shell.execute_reply.started":"2021-07-18T21:25:35.190182Z","shell.execute_reply":"2021-07-18T21:25:35.249073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity()\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channels, channels, kernel_size=3, padding=1),\n            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass Generator(nn.Module):\n    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n            nn.InstanceNorm2d(num_features),\n            nn.ReLU(inplace=True),\n        )\n        self.down_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n            ]\n        )\n        self.res_blocks = nn.Sequential(\n            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n        )\n        self.up_blocks = nn.ModuleList(\n            [\n                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n                ConvBlock(num_features*2, num_features*1, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n            ]\n        )\n\n        self.last = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n\n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_blocks:\n            x = layer(x)\n        x = self.res_blocks(x)\n        for layer in self.up_blocks:\n            x = layer(x)\n        return torch.tanh(self.last(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.251341Z","iopub.execute_input":"2021-07-18T21:25:35.251713Z","iopub.status.idle":"2021-07-18T21:25:35.269012Z","shell.execute_reply.started":"2021-07-18T21:25:35.251676Z","shell.execute_reply":"2021-07-18T21:25:35.268001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, stride, 1, bias=True, padding_mode=\"reflect\"),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                features[0],\n                kernel_size=4,\n                stride=2,\n                padding=1,\n                padding_mode=\"reflect\",\n            ),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(Block(in_channels, feature, stride=1 if feature==features[-1] else 2))\n            in_channels = feature\n        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.initial(x)\n        return torch.sigmoid(self.model(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.270424Z","iopub.execute_input":"2021-07-18T21:25:35.270978Z","iopub.status.idle":"2021-07-18T21:25:35.284299Z","shell.execute_reply.started":"2021-07-18T21:25:35.27094Z","shell.execute_reply":"2021-07-18T21:25:35.28338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HorseZebraDataset(Dataset):\n    def __init__(self, root_zebra, root_horse, transform=None):\n        self.root_zebra = root_zebra\n        self.root_horse = root_horse\n        self.transform = transform\n\n        self.zebra_images = os.listdir(root_zebra)\n        self.horse_images = os.listdir(root_horse)\n        self.length_dataset = max(len(self.zebra_images), len(self.horse_images)) # 1000, 1500\n        self.zebra_len = len(self.zebra_images)\n        self.horse_len = len(self.horse_images)\n\n    def __len__(self):\n        return self.length_dataset\n\n    def __getitem__(self, index):\n        zebra_img = self.zebra_images[index % self.zebra_len]\n        horse_img = self.horse_images[index % self.horse_len]\n\n        zebra_path = os.path.join(self.root_zebra, zebra_img)\n        horse_path = os.path.join(self.root_horse, horse_img)\n\n        zebra_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n        horse_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n\n        if self.transform:\n            augmentations = self.transform(image=zebra_img, image0=horse_img)\n            zebra_img = augmentations[\"image\"]\n            horse_img = augmentations[\"image\"]\n\n        return zebra_img, horse_img","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.286925Z","iopub.execute_input":"2021-07-18T21:25:35.287289Z","iopub.status.idle":"2021-07-18T21:25:35.300118Z","shell.execute_reply.started":"2021-07-18T21:25:35.287253Z","shell.execute_reply":"2021-07-18T21:25:35.29938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n    H_reals = 0\n    H_fakes = 0\n    loop = tqdm(loader, leave=True)\n\n    for idx, (zebra, horse) in enumerate(loop):\n        zebra = zebra.to(DEVICE)\n        horse = horse.to(DEVICE)\n\n        # Train Discriminators H and Z\n        with torch.cuda.amp.autocast():\n            fake_horse = gen_H(zebra)\n            D_H_real = disc_H(horse)\n            D_H_fake = disc_H(fake_horse.detach())\n            H_reals += D_H_real.mean().item()\n            H_fakes += D_H_fake.mean().item()\n            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n            D_H_loss = D_H_real_loss + D_H_fake_loss\n\n            fake_zebra = gen_Z(horse)\n            D_Z_real = disc_Z(zebra)\n            D_Z_fake = disc_Z(fake_zebra.detach())\n            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n\n            # put it togethor\n            D_loss = (D_H_loss + D_Z_loss)/2\n\n        opt_disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n\n        # Train Generators H and Z\n        with torch.cuda.amp.autocast():\n            # adversarial loss for both generators\n            D_H_fake = disc_H(fake_horse)\n            D_Z_fake = disc_Z(fake_zebra)\n            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n\n            # cycle loss\n            cycle_zebra = gen_Z(fake_horse)\n            cycle_horse = gen_H(fake_zebra)\n            cycle_zebra_loss = l1(zebra, cycle_zebra)\n            cycle_horse_loss = l1(horse, cycle_horse)\n\n            # identity loss (remove these for efficiency if you set lambda_identity=0)\n            identity_zebra = gen_Z(zebra)\n            identity_horse = gen_H(horse)\n            identity_zebra_loss = l1(zebra, identity_zebra)\n            identity_horse_loss = l1(horse, identity_horse)\n\n            # add all togethor\n            G_loss = (\n                loss_G_Z\n                + loss_G_H\n                + cycle_zebra_loss * LAMBDA_CYCLE\n                + cycle_horse_loss * LAMBDA_CYCLE\n                + identity_horse_loss * LAMBDA_IDENTITY\n                + identity_zebra_loss * LAMBDA_IDENTITY\n            )\n\n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n\n        if idx % 200 == 0:\n            save_image(fake_horse*0.5+0.5, f\"saved_images/horse_{idx}.png\")\n            save_image(fake_zebra*0.5+0.5, f\"saved_images/zebra_{idx}.png\")\n\n        loop.set_postfix(H_real=H_reals/(idx+1), H_fake=H_fakes/(idx+1))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.301833Z","iopub.execute_input":"2021-07-18T21:25:35.302233Z","iopub.status.idle":"2021-07-18T21:25:35.318686Z","shell.execute_reply.started":"2021-07-18T21:25:35.302195Z","shell.execute_reply":"2021-07-18T21:25:35.317717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n\n\ndef seed_everything(seed=42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.320126Z","iopub.execute_input":"2021-07-18T21:25:35.320491Z","iopub.status.idle":"2021-07-18T21:25:35.335253Z","shell.execute_reply.started":"2021-07-18T21:25:35.320457Z","shell.execute_reply":"2021-07-18T21:25:35.334185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    disc_H = Discriminator(in_channels=3).to(DEVICE)\n    disc_Z = Discriminator(in_channels=3).to(DEVICE)\n    gen_Z = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n    gen_H = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n    opt_disc = optim.Adam(\n        list(disc_H.parameters()) + list(disc_Z.parameters()),\n        lr=LEARNING_RATE,\n        betas=(0.5, 0.999),\n    )\n\n    opt_gen = optim.Adam(\n        list(gen_Z.parameters()) + list(gen_H.parameters()),\n        lr=LEARNING_RATE,\n        betas=(0.5, 0.999),\n    )\n\n    L1 = nn.L1Loss()\n    mse = nn.MSELoss()\n\n    if LOAD_MODEL:\n        load_checkpoint(\n            CHECKPOINT_GEN_H, gen_H, opt_gen, LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_GEN_Z, gen_Z, opt_gen, LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_CRITIC_H, disc_H, opt_disc, LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_CRITIC_Z, disc_Z, opt_disc, LEARNING_RATE,\n        )\n\n    dataset = HorseZebraDataset(\n        root_horse=TRAIN_DIR+\"original_A\", root_zebra=TRAIN_DIR+\"stylized_A\", transform=transforms\n    )\n    val_dataset = HorseZebraDataset(\n       root_horse=VAL_DIR+\"original_B\", root_zebra=VAL_DIR+\"stylized_B\", transform=transforms\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=1,\n        shuffle=False,\n        pin_memory=True,\n    )\n    loader = DataLoader(\n        dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n\n    for epoch in range(NUM_EPOCHS):\n        train_fn(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)\n\n        if SAVE_MODEL:\n            save_checkpoint(gen_H, opt_gen, filename=CHECKPOINT_GEN_H)\n            save_checkpoint(gen_Z, opt_gen, filename=CHECKPOINT_GEN_Z)\n            save_checkpoint(disc_H, opt_disc, filename=CHECKPOINT_CRITIC_H)\n            save_checkpoint(disc_Z, opt_disc, filename=CHECKPOINT_CRITIC_Z)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.336545Z","iopub.execute_input":"2021-07-18T21:25:35.336993Z","iopub.status.idle":"2021-07-18T21:25:35.351198Z","shell.execute_reply.started":"2021-07-18T21:25:35.336957Z","shell.execute_reply":"2021-07-18T21:25:35.350052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!md ./\n!mkdir saved_images","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:35.352439Z","iopub.execute_input":"2021-07-18T21:25:35.352889Z","iopub.status.idle":"2021-07-18T21:25:36.631828Z","shell.execute_reply.started":"2021-07-18T21:25:35.352853Z","shell.execute_reply":"2021-07-18T21:25:36.630754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T21:25:36.633487Z","iopub.execute_input":"2021-07-18T21:25:36.633937Z","iopub.status.idle":"2021-07-18T22:41:45.527765Z","shell.execute_reply.started":"2021-07-18T21:25:36.633895Z","shell.execute_reply":"2021-07-18T22:41:45.52409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r my_arch.zip ./saved_images","metadata":{"execution":{"iopub.status.busy":"2021-07-18T22:43:21.704771Z","iopub.execute_input":"2021-07-18T22:43:21.705154Z","iopub.status.idle":"2021-07-18T22:43:22.397031Z","shell.execute_reply.started":"2021-07-18T22:43:21.70512Z","shell.execute_reply":"2021-07-18T22:43:22.396066Z"},"trusted":true},"execution_count":null,"outputs":[]}]}