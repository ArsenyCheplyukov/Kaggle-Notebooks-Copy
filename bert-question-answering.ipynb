{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **BERT для вопросно-ответных систем**","metadata":{}},{"cell_type":"markdown","source":"##### ^^Скачайте датасет (SQuAD) отсюда. Для выполенения семинара Вам понадобятся файлы train-v2.0.json и dev-v2.0.json.**\n\n##### **Склонируйте репозиторий https://github.com/huggingface/transformers (воспользуйтесь скриптом clone_pytorch_transformers.sh) и положите путь до папки examples в переменную PATH_TO_EXAMPLES.**","metadata":{}},{"cell_type":"code","source":"! git clone https://github.com/huggingface/transformers.git","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:33:55.199889Z","iopub.execute_input":"2021-07-26T18:33:55.200211Z","iopub.status.idle":"2021-07-26T18:34:04.963285Z","shell.execute_reply.started":"2021-07-26T18:33:55.200136Z","shell.execute_reply":"2021-07-26T18:34:04.962341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\nimport sys; sys.path.append('./stepik-dl-nlp')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T18:34:10.628292Z","iopub.execute_input":"2021-07-26T18:34:10.628683Z","iopub.status.idle":"2021-07-26T18:36:00.387378Z","shell.execute_reply.started":"2021-07-26T18:34:10.628647Z","shell.execute_reply":"2021-07-26T18:36:00.386424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_TO_TRANSFORMERS_REPO = 'https://github.com/huggingface/transformers.git'","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:08:56.878629Z","iopub.execute_input":"2021-07-26T19:08:56.878969Z","iopub.status.idle":"2021-07-26T19:08:56.883081Z","shell.execute_reply.started":"2021-07-26T19:08:56.878937Z","shell.execute_reply":"2021-07-26T19:08:56.882094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1-DR30q7MF-gZ51TDx596dAOhgh-uOAPj","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:55:15.637653Z","iopub.execute_input":"2021-07-26T18:55:15.637995Z","iopub.status.idle":"2021-07-26T18:55:17.656199Z","shell.execute_reply.started":"2021-07-26T18:55:15.637959Z","shell.execute_reply":"2021-07-26T18:55:17.655215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['PATH_TO_TRANSFORMER_REPO'] = PATH_TO_TRANSFORMERS_REPO","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:00.398494Z","iopub.execute_input":"2021-07-26T18:36:00.398863Z","iopub.status.idle":"2021-07-26T18:36:00.40543Z","shell.execute_reply.started":"2021-07-26T18:36:00.398806Z","shell.execute_reply":"2021-07-26T18:36:00.404553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pytorch-transformers","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:00.408535Z","iopub.execute_input":"2021-07-26T18:36:00.408873Z","iopub.status.idle":"2021-07-26T18:36:07.365214Z","shell.execute_reply.started":"2021-07-26T18:36:00.408846Z","shell.execute_reply":"2021-07-26T18:36:07.364229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget 'https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad.py'\n!wget 'https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/utils_squad_evaluate.py'\n!wget 'https://raw.githubusercontent.com/nlpyang/pytorch-transformers/master/examples/run_squad.py'","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:07.366834Z","iopub.execute_input":"2021-07-26T18:36:07.367192Z","iopub.status.idle":"2021-07-26T18:36:10.038961Z","shell.execute_reply.started":"2021-07-26T18:36:07.36715Z","shell.execute_reply":"2021-07-26T18:36:10.037912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone $PATH_TO_TRANSFORMERS_REPO","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:09:03.950161Z","iopub.execute_input":"2021-07-26T19:09:03.950517Z","iopub.status.idle":"2021-07-26T19:09:04.790718Z","shell.execute_reply.started":"2021-07-26T19:09:03.950484Z","shell.execute_reply":"2021-07-26T19:09:04.789592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nPATH_TO_EXAMPLES = os.path.join(PATH_TO_TRANSFORMERS_REPO, 'examples')\nsys.path.append(PATH_TO_EXAMPLES)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:10.714058Z","iopub.execute_input":"2021-07-26T18:36:10.714365Z","iopub.status.idle":"2021-07-26T18:36:10.719187Z","shell.execute_reply.started":"2021-07-26T18:36:10.714325Z","shell.execute_reply":"2021-07-26T18:36:10.717911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport tqdm\nimport json\n\nfrom utils_squad import (read_squad_examples, convert_examples_to_features,\n                         RawResult, write_predictions,\n                         RawResultExtended, write_predictions_extended)\n\nfrom run_squad import train, load_and_cache_examples\n\nfrom torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n\nfrom transformers import (WEIGHTS_NAME, BertConfig, XLNetConfig, XLMConfig,\n                          BertForQuestionAnswering, BertTokenizer)\n\nfrom utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:10.720682Z","iopub.execute_input":"2021-07-26T18:36:10.721392Z","iopub.status.idle":"2021-07-26T18:36:16.684437Z","shell.execute_reply.started":"2021-07-26T18:36:10.721324Z","shell.execute_reply":"2021-07-26T18:36:16.683559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, do_basic_tokenize=True)\nmodel = BertForQuestionAnswering.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:16.688469Z","iopub.execute_input":"2021-07-26T18:36:16.688737Z","iopub.status.idle":"2021-07-26T18:36:35.175105Z","shell.execute_reply.started":"2021-07-26T18:36:16.688709Z","shell.execute_reply":"2021-07-26T18:36:35.174242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://drive.google.com/drive/folders/1-DR30q7MF-gZ51TDx596dAOhgh-uOAPj?usp=sharing","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:36:35.177257Z","iopub.execute_input":"2021-07-26T18:36:35.177631Z","iopub.status.idle":"2021-07-26T18:36:39.042647Z","shell.execute_reply.started":"2021-07-26T18:36:35.177594Z","shell.execute_reply":"2021-07-26T18:36:39.041701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    model.cuda()\n    model.load_state_dict(torch.load('../input/bert-squad-5-epochs/bert_squad_5epochs.pt')) # если у вас есть GPU\nelse:\n    model.load_state_dict(torch.load('../input/bert-squad-5-epochs/bert_squad_5epochs.pt', map_location=device)) # если GPU нет","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:10:40.255962Z","iopub.execute_input":"2021-07-26T19:10:40.256469Z","iopub.status.idle":"2021-07-26T19:10:40.607629Z","shell.execute_reply.started":"2021-07-26T19:10:40.256421Z","shell.execute_reply":"2021-07-26T19:10:40.603878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Дообучение**","metadata":{}},{"cell_type":"code","source":"!pip install dataclasses","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:40:37.089949Z","iopub.execute_input":"2021-07-26T18:40:37.090282Z","iopub.status.idle":"2021-07-26T18:40:43.086124Z","shell.execute_reply.started":"2021-07-26T18:40:37.090249Z","shell.execute_reply":"2021-07-26T18:40:43.085182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass TRAIN_OPTS:\n    train_file : str = '../input/squad-20/train-v2.0.json'    # SQuAD json-файл для обучения\n    predict_file : str = '../input/squad-20/dev-v2.0.json'    # SQuAD json-файл для тестирования\n    model_type : str = 'bert'               # тип модели (может быть  'bert', 'xlnet', 'xlm', 'distilbert')\n    model_name_or_path : str = 'bert-base-uncased' # путь до предобученной модели или название модели из ALL_MODELS\n    output_dir : str = '/tmp' # путь до директории, где будут храниться чекпоинты и предсказания модели\n    device : str = 'cuda' # cuda или cpu\n    n_gpu : int = 1 # количество gpu для обучения\n    cache_dir : str = '' # где хранить предобученные модели, загруженные с s3\n        \n    # Если true, то в датасет будут включены вопросы, на которые нет ответов.\n    version_2_with_negative : bool = True\n    # Если (null_score - best_non_null) больше, чем порог, предсказывать null.\n    null_score_diff_threshold : float = 0.0\n    # Максимальная длина входной последовательности после WordPiece токенизации. Sequences \n    # Последовательности длиннее будут укорочены, для более коротких последовательностей будет использован паддинг\n    max_seq_length : int = 384\n    # Сколько stride использовать при делении длинного документа на чанки\n    doc_stride : int = 128\n    # Максимальное количество токенов в вопросе. Более длинные вопросы будут укорочены до этой длины\n    max_query_length : int = 128 #\n        \n    do_train : bool = True\n    do_eval : bool = True\n        \n    # Запускать ли evaluation на каждом logging_step\n    evaluate_during_training : bool = True\n    # Должно быть True, если Вы используете uncased модели\n    do_lower_case : bool = True #\n    \n    per_gpu_train_batch_size : int = 8 # размер батча для обучения\n    per_gpu_eval_batch_size : int = 8 # размер батча для eval\n    learning_rate : float = 5e-5 # learning rate\n    gradient_accumulation_steps : int = 1 # количество шагов, которые нужно сделать перед backward/update pass\n    weight_decay : float = 0.0 # weight decay\n    adam_epsilon : float = 1e-8 # эпсилон для Adam\n    max_grad_norm : float = 1.0 # максимальная норма градиента\n    num_train_epochs : float = 5.0 # количество эпох на обучение\n    max_steps : int = -1 # общее количество шагов на обучение (override num_train_epochs)\n    warmup_steps : int = 0 # warmup \n    n_best_size : int = 5 # количество ответов, которые надо сгенерировать для записи в nbest_predictions.json\n    max_answer_length : int = 30 # максимально возможная длина ответа\n    verbose_logging : bool = True # печатать или нет warnings, относящиеся к обработке данных\n    logging_steps : int = 5000 # логировать каждые X шагов\n    save_steps : int = 5000 # сохранять чекпоинт каждые X шагов\n        \n    # Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\n    eval_all_checkpoints : bool = True\n    no_cuda : bool = False # не использовать CUDA\n    overwrite_output_dir : bool = True # переписывать ли содержимое директории с выходными файлами\n    overwrite_cache : bool = True # переписывать ли закешированные данные для обучения и evaluation\n    seed : int = 42 # random seed\n    local_rank : int = -1 # local rank для распределенного обучения на GPU\n    fp16 : bool = False # использовать ли 16-bit (mixed) precision (через NVIDIA apex) вместо 32-bit\"\n    # Apex AMP optimization level: ['O0', 'O1', 'O2', and 'O3'].\n    # Подробнее тут: https://nvidia.github.io/apex/amp.html\n    fp16_opt_level : str = '01'","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:04:48.238866Z","iopub.execute_input":"2021-07-26T19:04:48.239417Z","iopub.status.idle":"2021-07-26T19:04:48.264348Z","shell.execute_reply.started":"2021-07-26T19:04:48.239339Z","shell.execute_reply":"2021-07-26T19:04:48.262805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir(BertConfig)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:04:52.319099Z","iopub.execute_input":"2021-07-26T19:04:52.319443Z","iopub.status.idle":"2021-07-26T19:04:52.326312Z","shell.execute_reply.started":"2021-07-26T19:04:52.31941Z","shell.execute_reply":"2021-07-26T19:04:52.325367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig, XLNetConfig, XLMConfig)), ())\nALL_MODELS","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:05:08.670217Z","iopub.execute_input":"2021-07-26T19:05:08.67056Z","iopub.status.idle":"2021-07-26T19:05:08.705878Z","shell.execute_reply.started":"2021-07-26T19:05:08.670529Z","shell.execute_reply":"2021-07-26T19:05:08.704633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TRAIN_OPTS()\ntrain_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:39:56.911722Z","iopub.status.idle":"2021-07-26T18:39:56.91215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(args, train_dataset, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:39:56.913315Z","iopub.status.idle":"2021-07-26T18:39:56.913949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Сохраняем веса дообученной модели на диск, чтобы в следующий раз не обучать модель заново.**","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), './stepik-dl-nlp/models/bert_squad_final_5epoch.pt')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:39:56.915016Z","iopub.status.idle":"2021-07-26T18:39:56.915666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Подгрузить веса модели можно так:**","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/bert-squad-5-epochs/bert_squad_5epochs.pt'))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:03:31.923257Z","iopub.execute_input":"2021-07-26T19:03:31.92362Z","iopub.status.idle":"2021-07-26T19:03:32.169689Z","shell.execute_reply.started":"2021-07-26T19:03:31.923587Z","shell.execute_reply":"2021-07-26T19:03:32.167915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Оценка качества работы модели**","metadata":{}},{"cell_type":"code","source":"PATH_TO_DEV_SQUAD = '../input/squad-20/dev-v2.0.json'\nPATH_TO_SMALL_DEV_SQUAD = '../input/squad-20/train-v2.0.json'\n\nwith open(PATH_TO_DEV_SQUAD, 'r') as iofile:\n    full_sample = json.load(iofile)\n    \nsmall_sample = {\n    'version': full_sample['version'],\n    'data': full_sample['data'][:1]\n}\n\nwith open(PATH_TO_SMALL_DEV_SQUAD, 'w') as iofile:\n    json.dump(small_sample, iofile)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:11:44.602286Z","iopub.execute_input":"2021-07-26T19:11:44.602631Z","iopub.status.idle":"2021-07-26T19:11:44.703135Z","shell.execute_reply.started":"2021-07-26T19:11:44.602601Z","shell.execute_reply":"2021-07-26T19:11:44.70127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 384\noutside_pos = max_seq_length + 10\ndoc_stride = 128\nmax_query_length = 64\nmax_answer_length = 30","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:11:46.920678Z","iopub.execute_input":"2021-07-26T19:11:46.921176Z","iopub.status.idle":"2021-07-26T19:11:46.92995Z","shell.execute_reply.started":"2021-07-26T19:11:46.921132Z","shell.execute_reply":"2021-07-26T19:11:46.929011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"examples = read_squad_examples(\n    input_file=PATH_TO_SMALL_DEV_SQUAD,\n    is_training=False,\n    version_2_with_negative=True)\n\nfeatures = convert_examples_to_features(\n    examples=examples,\n    tokenizer=tokenizer,\n    max_seq_length=max_seq_length,\n    doc_stride=doc_stride,\n    max_query_length=max_query_length,\n    is_training=False,\n    cls_token_segment_id=0,\n    pad_token_segment_id=0,\n    cls_token_at_end=False\n)\n\ninput_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\ninput_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\nsegment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\ncls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)\np_mask = torch.tensor([f.p_mask for f in features], dtype=torch.float)\n\nexample_index = torch.arange(input_ids.size(0), dtype=torch.long)\ndataset = TensorDataset(input_ids, input_mask, segment_ids, example_index, cls_index, p_mask)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:16.911469Z","iopub.execute_input":"2021-07-26T19:14:16.911813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_sampler = SequentialSampler(dataset)\neval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_list(tensor):\n    return tensor.detach().cpu().tolist()\n\nall_results = []\nfor idx, batch in enumerate(tqdm.tqdm_notebook(eval_dataloader, desc=\"Evaluating\")):\n    model.eval()\n    batch = tuple(t.to(device) for t in batch)\n    with torch.no_grad():\n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1]\n                  }\n        inputs['token_type_ids'] = batch[2]\n        example_indices = batch[3]\n        outputs = model(**inputs)\n\n    for i, example_index in enumerate(example_indices):\n        eval_feature = features[example_index.item()]\n        unique_id = int(eval_feature.unique_id)\n        result = RawResult(unique_id    = unique_id,\n                           start_logits = to_list(outputs[0][i]),\n                           end_logits   = to_list(outputs[1][i]))\n        all_results.append(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_results[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_best_size = 5\ndo_lower_case = True\noutput_prediction_file = 'output_1best_file'\noutput_nbest_file = 'output_nbest_file'\noutput_na_prob_file = 'output_na_prob_file'\nverbose_logging = True\nversion_2_with_negative = True\nnull_score_diff_threshold = 0.0","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.93827Z","iopub.status.idle":"2021-07-26T19:14:10.938942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Генерируем файл с n лучшими ответами `output_nbest_file`\nwrite_predictions(examples, features, all_results, n_best_size,\n                    max_answer_length, do_lower_case, output_prediction_file,\n                    output_nbest_file, output_na_prob_file, verbose_logging,\n                    version_2_with_negative, null_score_diff_threshold)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.94041Z","iopub.status.idle":"2021-07-26T19:14:10.941076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Считаем метрики используя официальный SQuAD script\nevaluate_options = EVAL_OPTS(data_file=PATH_TO_SMALL_DEV_SQUAD,\n                             pred_file=output_prediction_file,\n                             na_prob_file=output_na_prob_file)\nresults = evaluate_on_squad(evaluate_options)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.942721Z","iopub.status.idle":"2021-07-26T19:14:10.943376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Посмотрим глазами на вопросы и предсказанные БЕРТом ответы:**","metadata":{}},{"cell_type":"code","source":"with open('output_nbest_file', 'r') as iofile:\n    predicted_answers = json.load(iofile)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.94484Z","iopub.status.idle":"2021-07-26T19:14:10.9455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = {}\nfor paragraph in small_sample['data'][0]['paragraphs']:\n    for question in paragraph['qas']:\n        questions[question['id']] = {\n            'question': question['question'],\n            'answers': question['answers'],\n            'paragraph': paragraph['context']\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.947088Z","iopub.status.idle":"2021-07-26T19:14:10.947745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for q_num, (key, data) in enumerate(predicted_answers.items()):\n    gt = '' if len(questions[key]['answers']) == 0 else questions[key]['answers'][0]['text']\n    print('Вопрос {0}:'.format(q_num+1), questions[key]['question'])\n    print('-----------------------------------')\n    print('Ground truth:', gt)\n    print('-----------------------------------')   \n    print('Ответы, предсказанные БЕРТом:')\n    preds = ['{0}) '.format(ans_num + 1) + answer['text'] + \\\n             ' (уверенность {0:.2f}%)'.format(answer['probability']*100) \\\n             for ans_num, answer in enumerate(data)]\n    print('\\n'.join(preds))\n#     print('-----------------------------------')   \n#     print('Параграф:', questions[key]['paragraph'])\n    print('\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T19:14:10.949268Z","iopub.status.idle":"2021-07-26T19:14:10.94993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!export SQUAD_DIR=/path/to/SQUAD\n\npython run_squad.py \\\n  --model_type bert \\\n  --model_name_or_path bert-base-cased \\\n  --do_train \\\n  --do_eval \\\n  --do_lower_case \\\n  --train_file $SQUAD_DIR/train-v1.1.json \\\n  --predict_file $SQUAD_DIR/dev-v1.1.json \\\n  --per_gpu_train_batch_size 12 \\\n  --learning_rate 3e-5 \\\n  --num_train_epochs 2.0 \\\n  --max_seq_length 384 \\\n  --doc_stride 128 \\\n  --output_dir /tmp/debug_squad/","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:39:56.942095Z","iopub.status.idle":"2021-07-26T18:39:56.942825Z"},"trusted":true},"execution_count":null,"outputs":[]}]}