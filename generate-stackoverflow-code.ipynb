{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Генерация кода по вопросам со StackOverflow**","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt -q\nimport sys; sys.path.append('./stepik-dl-nlp')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T22:45:32.825241Z","iopub.execute_input":"2021-07-25T22:45:32.826005Z","iopub.status.idle":"2021-07-25T22:48:08.384134Z","shell.execute_reply.started":"2021-07-25T22:45:32.825878Z","shell.execute_reply":"2021-07-25T22:48:08.382576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchtext.datasets import TranslationDataset, Multi30k\nfrom torchtext.data import Field, BucketIterator\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nimport spacy\n\nimport random\nimport math\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:08.386558Z","iopub.execute_input":"2021-07-25T22:48:08.387032Z","iopub.status.idle":"2021-07-25T22:48:20.109012Z","shell.execute_reply.started":"2021-07-25T22:48:08.386992Z","shell.execute_reply":"2021-07-25T22:48:20.107875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 1234\n\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.111212Z","iopub.execute_input":"2021-07-25T22:48:20.111589Z","iopub.status.idle":"2021-07-25T22:48:20.120700Z","shell.execute_reply.started":"2021-07-25T22:48:20.111554Z","shell.execute_reply":"2021-07-25T22:48:20.119432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef tokenize_question(text):\n    \"\"\"\n    Tokenizes question from a string into a list of strings (tokens) and reverses it\n    \"\"\"\n    return list(filter(lambda x: len(x) < 16, re.findall(r\"[\\w']+\", text)[::-1]))\n\ndef tokenize_snippet(text):\n    \"\"\"\n    Tokenizes code snippet into a list of operands\n    \"\"\"\n    return list(filter(lambda x: len(x) < 10, re.findall(r\"[\\w']+|[.,!?;:@~(){}\\[\\]+-/=\\\\\\'\\\"\\`]\", text)))","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.122623Z","iopub.execute_input":"2021-07-25T22:48:20.123084Z","iopub.status.idle":"2021-07-25T22:48:20.135698Z","shell.execute_reply.started":"2021-07-25T22:48:20.123035Z","shell.execute_reply":"2021-07-25T22:48:20.133185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchtext import data, datasets\n\nSRC = data.Field(\n    tokenize = tokenize_question, \n    init_token = '<sos>', \n    eos_token = '<eos>', \n    lower = True,\n    include_lengths = True\n)\n\nTRG = data.Field(\n    tokenize = tokenize_snippet, \n    init_token = '<sos>', \n    eos_token = '<eos>', \n    lower = True\n)\n\nfields = {\n    'intent': ('src', SRC),\n    'snippet': ('trg', TRG)\n}\n\n# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\ntrain_data, valid_data, test_data = data.TabularDataset.splits(\n                            path = './stepik-dl-nlp/datasets/stackoverflow_code_generation/conala/',\n                            train = 'conala-train.csv',\n                            validation = 'conala-valid.csv',\n                            test = 'conala-test.csv',\n                            format = 'csv',\n                            fields = fields\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.137348Z","iopub.execute_input":"2021-07-25T22:48:20.138276Z","iopub.status.idle":"2021-07-25T22:48:20.307537Z","shell.execute_reply.started":"2021-07-25T22:48:20.138234Z","shell.execute_reply":"2021-07-25T22:48:20.306385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SRC.build_vocab([train_data.src], max_size=25000, min_freq=3)\nprint(SRC.vocab.freqs.most_common(20))\n\n\nTRG.build_vocab([train_data.trg], min_freq=5)\nprint(TRG.vocab.freqs.most_common(20))\n\nprint(f\"Уникальные токены в словаре интентов: {len(SRC.vocab)}\")\nprint(f\"Уникальные токены в словаре сниппетов: {len(TRG.vocab)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.309037Z","iopub.execute_input":"2021-07-25T22:48:20.309376Z","iopub.status.idle":"2021-07-25T22:48:20.334765Z","shell.execute_reply.started":"2021-07-25T22:48:20.309343Z","shell.execute_reply":"2021-07-25T22:48:20.333081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Размер обучающей выборки: {len(train_data.examples)}\")\nprint(f\"Размер валидационной выборки: {len(valid_data.examples)}\")\nprint(f\"Размер тестовой выборки: {len(test_data.examples)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.337275Z","iopub.execute_input":"2021-07-25T22:48:20.337703Z","iopub.status.idle":"2021-07-25T22:48:20.351586Z","shell.execute_reply.started":"2021-07-25T22:48:20.337668Z","shell.execute_reply":"2021-07-25T22:48:20.349956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.355517Z","iopub.execute_input":"2021-07-25T22:48:20.355998Z","iopub.status.idle":"2021-07-25T22:48:20.365512Z","shell.execute_reply.started":"2021-07-25T22:48:20.355959Z","shell.execute_reply":"2021-07-25T22:48:20.363915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.367586Z","iopub.execute_input":"2021-07-25T22:48:20.368030Z","iopub.status.idle":"2021-07-25T22:48:20.386148Z","shell.execute_reply.started":"2021-07-25T22:48:20.367993Z","shell.execute_reply":"2021-07-25T22:48:20.385006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2\n\ntrain_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n    (train_data, valid_data, test_data), \n     batch_size = BATCH_SIZE,\n     sort_within_batch = True,\n     sort_key = lambda x : len(x.src),\n     device = device)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.387620Z","iopub.execute_input":"2021-07-25T22:48:20.388016Z","iopub.status.idle":"2021-07-25T22:48:20.403053Z","shell.execute_reply.started":"2021-07-25T22:48:20.387977Z","shell.execute_reply":"2021-07-25T22:48:20.402005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n        super().__init__()\n        \n        self.input_dim = input_dim\n        self.emb_dim = emb_dim\n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n        self.dropout = dropout\n        \n        self.embedding = nn.Embedding(input_dim, emb_dim)\n        \n        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n        \n        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src, src_len):\n        \n        #src = [src sent len, batch size]\n        #src_len = [src sent len]\n        \n        embedded = self.dropout(self.embedding(src))\n        \n        #embedded = [src sent len, batch size, emb dim]\n        \n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n        \n        packed_outputs, hidden = self.rnn(packed_embedded)\n                     \n        #packed_outputs is a packed sequence containing all hidden states\n        #hidden is now from the final non-padded element in the batch\n            \n        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n            \n        #outputs is now a non-packed sequence, all hidden states obtained\n        #  when the input is a pad token are all zeros\n            \n        #outputs = [sent len, batch size, hid dim * num directions]\n        #hidden = [n layers * num directions, batch size, hid dim]\n        \n        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n        #outputs are always from the last layer\n        \n        #hidden [-2, :, : ] is the last of the forwards RNN \n        #hidden [-1, :, : ] is the last of the backwards RNN\n        \n        #initial decoder hidden is final hidden state of the forwards and backwards \n        #  encoder RNNs fed through a linear layer\n        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n        \n        #outputs = [sent len, batch size, enc hid dim * 2]\n        #hidden = [batch size, dec hid dim]\n        \n        return outputs, hidden","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.404223Z","iopub.execute_input":"2021-07-25T22:48:20.404558Z","iopub.status.idle":"2021-07-25T22:48:20.416399Z","shell.execute_reply.started":"2021-07-25T22:48:20.404524Z","shell.execute_reply":"2021-07-25T22:48:20.415076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, enc_hid_dim, dec_hid_dim):\n        super().__init__()\n        \n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n        \n        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n        \n    def forward(self, hidden, encoder_outputs, mask):\n        \n        #hidden = [batch size, dec hid dim]\n        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n        #mask = [batch size, src sent len]\n        \n        batch_size = encoder_outputs.shape[1]\n        src_len = encoder_outputs.shape[0]\n        \n        #repeat encoder hidden state src_len times\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n        \n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        \n        #hidden = [batch size, src sent len, dec hid dim]\n        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n        \n        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n        \n        #energy = [batch size, src sent len, dec hid dim]\n                \n        energy = energy.permute(0, 2, 1)\n        \n        #energy = [batch size, dec hid dim, src sent len]\n        \n        #v = [dec hid dim]\n        \n        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n        \n        #v = [batch size, 1, dec hid dim]\n            \n        attention = torch.bmm(v, energy).squeeze(1)\n        \n        #attention = [batch size, src sent len]\n        \n        attention = attention.masked_fill(mask == 0, -1e10)\n        \n        return F.softmax(attention, dim = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.417851Z","iopub.execute_input":"2021-07-25T22:48:20.418308Z","iopub.status.idle":"2021-07-25T22:48:20.437378Z","shell.execute_reply.started":"2021-07-25T22:48:20.418262Z","shell.execute_reply":"2021-07-25T22:48:20.435796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n        super().__init__()\n\n        self.emb_dim = emb_dim\n        self.enc_hid_dim = enc_hid_dim\n        self.dec_hid_dim = dec_hid_dim\n        self.output_dim = output_dim\n        self.dropout = dropout\n        self.attention = attention\n        \n        self.embedding = nn.Embedding(output_dim, emb_dim)\n        \n        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n        \n        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, input, hidden, encoder_outputs, mask):\n             \n        #input = [batch size]\n        #hidden = [batch size, dec hid dim]\n        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n        #mask = [batch size, src sent len]\n        \n        input = input.unsqueeze(0)\n        \n        #input = [1, batch size]\n        \n        embedded = self.dropout(self.embedding(input))\n        \n        #embedded = [1, batch size, emb dim]\n        \n        a = self.attention(hidden, encoder_outputs, mask)\n                \n        #a = [batch size, src sent len]\n        \n        a = a.unsqueeze(1)\n        \n        #a = [batch size, 1, src sent len]\n        \n        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n        \n        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n        \n        weighted = torch.bmm(a, encoder_outputs)\n        \n        #weighted = [batch size, 1, enc hid dim * 2]\n        \n        weighted = weighted.permute(1, 0, 2)\n        \n        #weighted = [1, batch size, enc hid dim * 2]\n        \n        rnn_input = torch.cat((embedded, weighted), dim = 2)\n        \n        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n            \n        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n        \n        #output = [sent len, batch size, dec hid dim * n directions]\n        #hidden = [n layers * n directions, batch size, dec hid dim]\n        \n        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n        #output = [1, batch size, dec hid dim]\n        #hidden = [1, batch size, dec hid dim]\n        #this also means that output == hidden\n        assert (output == hidden).all()\n        \n        embedded = embedded.squeeze(0)\n        output = output.squeeze(0)\n        weighted = weighted.squeeze(0)\n        \n        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n        \n        #output = [bsz, output dim]\n        \n        return output, hidden.squeeze(0), a.squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.440530Z","iopub.execute_input":"2021-07-25T22:48:20.440958Z","iopub.status.idle":"2021-07-25T22:48:20.460796Z","shell.execute_reply.started":"2021-07-25T22:48:20.440899Z","shell.execute_reply":"2021-07-25T22:48:20.458502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n        super().__init__()\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.pad_idx = pad_idx\n        self.sos_idx = sos_idx\n        self.eos_idx = eos_idx\n        self.device = device\n        \n    def create_mask(self, src):\n        mask = (src != self.pad_idx).permute(1, 0)\n        return mask\n        \n    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n        \n        #src = [src sent len, batch size]\n        #src_len = [batch size]\n        #trg = [trg sent len, batch size]\n        #teacher_forcing_ratio is probability to use teacher forcing\n        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n        \n        if trg is None:\n            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n            inference = True\n            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n        else:\n            inference = False\n            \n        batch_size = src.shape[1]\n        max_len = trg.shape[0]\n        trg_vocab_size = self.decoder.output_dim\n        \n        #tensor to store decoder outputs\n        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n        \n        #tensor to store attention\n        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n        \n        #encoder_outputs is all hidden states of the input sequence, back and forwards\n        #hidden is the final forward and backward hidden states, passed through a linear layer\n        encoder_outputs, hidden = self.encoder(src, src_len)\n                \n        #first input to the decoder is the <sos> tokens\n        output = trg[0,:]\n        \n        mask = self.create_mask(src)\n                \n        #mask = [batch size, src sent len]\n                \n        for t in range(1, max_len):\n            output, hidden, attention = self.decoder(output, hidden, encoder_outputs, mask)\n            outputs[t] = output\n            attentions[t] = attention\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.max(1)[1]\n            output = (trg[t] if teacher_force else top1)\n            if inference and output.item() == self.eos_idx:\n                return outputs[:t], attentions[:t]\n            \n        return outputs, attentions","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.464295Z","iopub.execute_input":"2021-07-25T22:48:20.464776Z","iopub.status.idle":"2021-07-25T22:48:20.487604Z","shell.execute_reply.started":"2021-07-25T22:48:20.464713Z","shell.execute_reply":"2021-07-25T22:48:20.485216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\nENC_EMB_DIM = 128\nDEC_EMB_DIM = 128\nENC_HID_DIM = 100\nDEC_HID_DIM = 100\nENC_DROPOUT = 0.8\nDEC_DROPOUT = 0.8\nPAD_IDX = SRC.vocab.stoi['<pad>']\nSOS_IDX = TRG.vocab.stoi['<sos>']\nEOS_IDX = TRG.vocab.stoi['<eos>']\n\nattn = Attention(ENC_HID_DIM, DEC_HID_DIM)\nenc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\ndec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n\nmodel = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.490067Z","iopub.execute_input":"2021-07-25T22:48:20.490587Z","iopub.status.idle":"2021-07-25T22:48:20.565387Z","shell.execute_reply.started":"2021-07-25T22:48:20.490536Z","shell.execute_reply":"2021-07-25T22:48:20.563038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        if 'weight' in name:\n            nn.init.normal_(param.data, mean=0, std=0.01)\n        else:\n            nn.init.constant_(param.data, 0)\n            \nmodel.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.566805Z","iopub.execute_input":"2021-07-25T22:48:20.567198Z","iopub.status.idle":"2021-07-25T22:48:20.619884Z","shell.execute_reply.started":"2021-07-25T22:48:20.567151Z","shell.execute_reply":"2021-07-25T22:48:20.618292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'Модель содержит {count_parameters(model):,} параметров')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.621784Z","iopub.execute_input":"2021-07-25T22:48:20.622267Z","iopub.status.idle":"2021-07-25T22:48:20.629799Z","shell.execute_reply.started":"2021-07-25T22:48:20.622224Z","shell.execute_reply":"2021-07-25T22:48:20.628532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Then we define our optimizer and criterion. We have already initialized PAD_IDX when initializing the model, so we don't need to do it again.**","metadata":{}},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.631472Z","iopub.execute_input":"2021-07-25T22:48:20.631955Z","iopub.status.idle":"2021-07-25T22:48:20.652891Z","shell.execute_reply.started":"2021-07-25T22:48:20.631888Z","shell.execute_reply":"2021-07-25T22:48:20.651614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.654688Z","iopub.execute_input":"2021-07-25T22:48:20.655140Z","iopub.status.idle":"2021-07-25T22:48:20.668863Z","shell.execute_reply.started":"2021-07-25T22:48:20.655067Z","shell.execute_reply":"2021-07-25T22:48:20.667017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, iterator, optimizer, criterion, clip):\n    \n    model.train()\n    \n    epoch_loss = 0\n    \n    for i, batch in enumerate(iterator):\n        \n        src, src_len = batch.src\n        trg = batch.trg\n        \n        optimizer.zero_grad()\n        \n        output, attetion = model(src, src_len, trg, 0.4)\n        \n        #trg = [trg sent len, batch size]\n        #output = [trg sent len, batch size, output dim]\n        \n        output = output[1:].view(-1, output.shape[-1])\n        trg = trg[1:].view(-1)\n        \n        #trg = [(trg sent len - 1) * batch size]\n        #output = [(trg sent len - 1) * batch size, output dim]\n        \n        loss = criterion(output, trg)\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.670737Z","iopub.execute_input":"2021-07-25T22:48:20.671225Z","iopub.status.idle":"2021-07-25T22:48:20.685887Z","shell.execute_reply.started":"2021-07-25T22:48:20.671187Z","shell.execute_reply":"2021-07-25T22:48:20.684376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    \n    model.eval()\n    \n    epoch_loss = 0\n    \n    with torch.no_grad():\n    \n        for i, batch in enumerate(iterator):\n\n            src, src_len = batch.src\n            trg = batch.trg\n\n            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n\n            #trg = [trg sent len, batch size]\n            #output = [trg sent len, batch size, output dim]\n\n            output = output[1:].view(-1, output.shape[-1])\n            trg = trg[1:].view(-1)\n\n            #trg = [(trg sent len - 1) * batch size]\n            #output = [(trg sent len - 1) * batch size, output dim]\n\n            loss = criterion(output, trg)\n\n            epoch_loss += loss.item()\n        \n    return epoch_loss / len(iterator)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.688010Z","iopub.execute_input":"2021-07-25T22:48:20.688590Z","iopub.status.idle":"2021-07-25T22:48:20.704735Z","shell.execute_reply.started":"2021-07-25T22:48:20.688550Z","shell.execute_reply":"2021-07-25T22:48:20.703088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.706019Z","iopub.execute_input":"2021-07-25T22:48:20.706310Z","iopub.status.idle":"2021-07-25T22:48:20.722725Z","shell.execute_reply.started":"2021-07-25T22:48:20.706284Z","shell.execute_reply":"2021-07-25T22:48:20.721507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 50\nCLIP = 1\n\nbest_valid_loss = float('inf')\n\nfor epoch in range(N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n    valid_loss = evaluate(model, valid_iterator, criterion)\n    \n    end_time = time.time()\n    \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n    \n    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T22:48:20.725988Z","iopub.execute_input":"2021-07-25T22:48:20.726552Z","iopub.status.idle":"2021-07-25T23:25:18.669889Z","shell.execute_reply.started":"2021-07-25T22:48:20.726513Z","shell.execute_reply":"2021-07-25T23:25:18.664595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('conala_model_attention_test.pt'))\n\ntest_loss = evaluate(model, test_iterator, criterion)\n\nprint(f'Перплексия (валидация): {math.exp(test_loss):7.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:26.555739Z","iopub.execute_input":"2021-07-25T23:25:26.556235Z","iopub.status.idle":"2021-07-25T23:25:32.191115Z","shell.execute_reply.started":"2021-07-25T23:25:26.556197Z","shell.execute_reply":"2021-07-25T23:25:32.189608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Предсказание кода по вопросу**","metadata":{}},{"cell_type":"code","source":"def translate_sentence(model, sentence):\n    model.eval()\n    tokenized = tokenize_question(sentence) \n    tokenized = ['<sos>'] + [t.lower() for t in tokenized] + ['<eos>']\n    numericalized = [SRC.vocab.stoi[t] for t in tokenized] \n    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0) \n    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n    translation, attention = translation[1:], attention[1:]\n    return translation, attention","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.193264Z","iopub.execute_input":"2021-07-25T23:25:32.193725Z","iopub.status.idle":"2021-07-25T23:25:32.204555Z","shell.execute_reply.started":"2021-07-25T23:25:32.193677Z","shell.execute_reply":"2021-07-25T23:25:32.203116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_attention(candidate, translation, attention):\n    \n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111)\n    \n    attention = attention.squeeze(1).cpu().detach().numpy()\n    \n    cax = ax.matshow(attention, cmap='bone')\n   \n    ax.tick_params(labelsize=15)\n    ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in tokenize_question(candidate)] + ['<eos>'], \n                       rotation=45)\n    ax.set_yticklabels([''] + translation)\n\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.208185Z","iopub.execute_input":"2021-07-25T23:25:32.208713Z","iopub.status.idle":"2021-07-25T23:25:32.222453Z","shell.execute_reply.started":"2021-07-25T23:25:32.208654Z","shell.execute_reply":"2021-07-25T23:25:32.220748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_idx = 2\nsrc = ' '.join(vars(train_data.examples[example_idx])['src'])\ntrg = ' '.join(vars(train_data.examples[example_idx])['trg'])\nprint(f'src = {src}')\nprint(f'trg = {trg}')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.224985Z","iopub.execute_input":"2021-07-25T23:25:32.225802Z","iopub.status.idle":"2021-07-25T23:25:32.244252Z","shell.execute_reply.started":"2021-07-25T23:25:32.225734Z","shell.execute_reply":"2021-07-25T23:25:32.243121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation, attention = translate_sentence(model, src)\nprint('predicted trg = ', ' '.join(translation))\ndisplay_attention(src, translation, attention)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.245767Z","iopub.execute_input":"2021-07-25T23:25:32.246178Z","iopub.status.idle":"2021-07-25T23:25:32.779371Z","shell.execute_reply.started":"2021-07-25T23:25:32.246131Z","shell.execute_reply":"2021-07-25T23:25:32.777061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_idx = 8\nsrc = ' '.join(vars(valid_data.examples[example_idx])['src'])\ntrg = ' '.join(vars(valid_data.examples[example_idx])['trg'])\nprint(f'src = {src}')\nprint(f'trg = {trg}')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.780841Z","iopub.execute_input":"2021-07-25T23:25:32.781231Z","iopub.status.idle":"2021-07-25T23:25:32.792365Z","shell.execute_reply.started":"2021-07-25T23:25:32.781189Z","shell.execute_reply":"2021-07-25T23:25:32.790639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation, attention = translate_sentence(model, src)\nprint('predicted trg = ', ' '.join(translation))\ndisplay_attention(src, translation, attention)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:32.794108Z","iopub.execute_input":"2021-07-25T23:25:32.794510Z","iopub.status.idle":"2021-07-25T23:25:33.174168Z","shell.execute_reply.started":"2021-07-25T23:25:32.794474Z","shell.execute_reply":"2021-07-25T23:25:33.173028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_idx = 4\nsrc = ' '.join(vars(test_data.examples[example_idx])['src'])\ntrg = ' '.join(vars(test_data.examples[example_idx])['trg'])\nprint(f'src = {src}')\nprint(f'trg = {trg}')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:33.175884Z","iopub.execute_input":"2021-07-25T23:25:33.176255Z","iopub.status.idle":"2021-07-25T23:25:33.184116Z","shell.execute_reply.started":"2021-07-25T23:25:33.176219Z","shell.execute_reply":"2021-07-25T23:25:33.183129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"translation, attention = translate_sentence(model, src)\nprint('predicted trg = ', ''.join(translation))\ndisplay_attention(src, translation, attention)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T23:25:33.186282Z","iopub.execute_input":"2021-07-25T23:25:33.186902Z","iopub.status.idle":"2021-07-25T23:25:33.559806Z","shell.execute_reply.started":"2021-07-25T23:25:33.186845Z","shell.execute_reply":"2021-07-25T23:25:33.558440Z"},"trusted":true},"execution_count":null,"outputs":[]}]}