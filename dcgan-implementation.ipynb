{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-17T14:54:38.211009Z","iopub.execute_input":"2021-07-17T14:54:38.211404Z","iopub.status.idle":"2021-07-17T14:54:39.478533Z","shell.execute_reply.started":"2021-07-17T14:54:38.211303Z","shell.execute_reply":"2021-07-17T14:54:39.477495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:39.481982Z","iopub.execute_input":"2021-07-17T14:54:39.482255Z","iopub.status.idle":"2021-07-17T14:54:41.241886Z","shell.execute_reply.started":"2021-07-17T14:54:39.482227Z","shell.execute_reply":"2021-07-17T14:54:41.240878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:41.245463Z","iopub.execute_input":"2021-07-17T14:54:41.245736Z","iopub.status.idle":"2021-07-17T14:54:42.766816Z","shell.execute_reply.started":"2021-07-17T14:54:41.245706Z","shell.execute_reply":"2021-07-17T14:54:42.765752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nLEARNING_RATE = 3e-4  # could also use two lrs, one for gen and one for disc\nBATCH_SIZE = 512\nIMAGE_SIZE = 64\nCHANNELS_IMG = 1\nNOISE_DIM = 100\nNUM_EPOCHS = 10\nFEATURES_DISC = 64\nFEATURES_GEN = 64","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # input: N x channels_img x 64 x 64\n            self._block(channels_img, features_d, 4, 2, 1),\n            # _block(in_channels, out_channels, kernel_size, stride, padding)\n            self._block(features_d, features_d * 2, 4, 2, 1),\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n            nn.Sigmoid(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:42.771088Z","iopub.execute_input":"2021-07-17T14:54:42.77147Z","iopub.status.idle":"2021-07-17T14:54:42.784782Z","shell.execute_reply.started":"2021-07-17T14:54:42.771425Z","shell.execute_reply":"2021-07-17T14:54:42.783163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, channels_noise, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            # Input: N x channels_noise x 1 x 1\n            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            nn.ConvTranspose2d(\n                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n            ),\n            # Output: N x channels_img x 64 x 64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:42.788215Z","iopub.execute_input":"2021-07-17T14:54:42.790428Z","iopub.status.idle":"2021-07-17T14:54:42.802453Z","shell.execute_reply.started":"2021-07-17T14:54:42.78869Z","shell.execute_reply":"2021-07-17T14:54:42.801601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        tuple([0.5 for _ in range(CHANNELS_IMG)]), tuple([0.5 for _ in range(CHANNELS_IMG)])\n    ),\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:42.89973Z","iopub.execute_input":"2021-07-17T14:54:42.900059Z","iopub.status.idle":"2021-07-17T14:54:42.907312Z","shell.execute_reply.started":"2021-07-17T14:54:42.900029Z","shell.execute_reply":"2021-07-17T14:54:42.906103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you train on MNIST, remember to set channels_img to 1\ndataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms,\n                       download=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:54:42.908648Z","iopub.execute_input":"2021-07-17T14:54:42.909115Z","iopub.status.idle":"2021-07-17T14:59:13.657661Z","shell.execute_reply.started":"2021-07-17T14:54:42.909072Z","shell.execute_reply":"2021-07-17T14:59:13.656688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# comment mnist above and uncomment below if train on CelebA\n#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\ngen = Generator(NOISE_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\ndisc = Discriminator(CHANNELS_IMG, FEATURES_DISC).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:59:13.659148Z","iopub.execute_input":"2021-07-17T14:59:13.659507Z","iopub.status.idle":"2021-07-17T14:59:17.637498Z","shell.execute_reply.started":"2021-07-17T14:59:13.659468Z","shell.execute_reply":"2021-07-17T14:59:17.636622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\nopt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\ncriterion = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:59:17.639237Z","iopub.execute_input":"2021-07-17T14:59:17.639731Z","iopub.status.idle":"2021-07-17T14:59:17.645587Z","shell.execute_reply.started":"2021-07-17T14:59:17.639691Z","shell.execute_reply":"2021-07-17T14:59:17.644842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_noise = torch.randn(32, NOISE_DIM, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:59:17.646645Z","iopub.execute_input":"2021-07-17T14:59:17.647016Z","iopub.status.idle":"2021-07-17T14:59:19.236743Z","shell.execute_reply.started":"2021-07-17T14:59:17.646979Z","shell.execute_reply":"2021-07-17T14:59:19.235882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen.train()\ndisc.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:59:19.238039Z","iopub.execute_input":"2021-07-17T14:59:19.238397Z","iopub.status.idle":"2021-07-17T14:59:19.245937Z","shell.execute_reply.started":"2021-07-17T14:59:19.238338Z","shell.execute_reply":"2021-07-17T14:59:19.245134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    # Target labels not needed! <3 unsupervised\n    for batch_idx, (real, _) in enumerate(dataloader):\n        real = real.to(device)\n        noise = torch.randn(BATCH_SIZE, NOISE_DIM, 1, 1).to(device)\n        fake = gen(noise)\n\n        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n        disc_real = disc(real).reshape(-1)\n        # multiply target by 0.5 is some kind of hacks that helps learning\n        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real)*0.5)\n        disc_fake = disc(fake.detach()).reshape(-1)\n        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake)*0.5)\n        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n        disc.zero_grad()\n        loss_disc.backward()\n        opt_disc.step()\n\n        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n        output = disc(fake).reshape(-1)\n        loss_gen = criterion(output, torch.ones_like(output))\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n\n        # Print losses occasionally and print to tensorboard\n        if batch_idx % 100 == 0:\n            print(\n                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n            )\n\n            with torch.no_grad():\n                fake = gen(fixed_noise)\n                # take out (up to) 32 examples\n                img_grid_real = torchvision.utils.make_grid(\n                    real[:32], normalize=True\n                )\n                img_grid_fake = torchvision.utils.make_grid(\n                    fake[:32], normalize=True\n                )\n\n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n\n            step += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-17T14:59:19.247377Z","iopub.execute_input":"2021-07-17T14:59:19.248108Z","iopub.status.idle":"2021-07-17T15:24:15.4223Z","shell.execute_reply.started":"2021-07-17T14:59:19.248049Z","shell.execute_reply":"2021-07-17T15:24:15.421281Z"},"trusted":true},"execution_count":null,"outputs":[]}]}