{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install boltons -q","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:07.854116Z","iopub.execute_input":"2021-07-23T13:28:07.854445Z","iopub.status.idle":"2021-07-23T13:28:16.088359Z","shell.execute_reply.started":"2021-07-23T13:28:07.854371Z","shell.execute_reply":"2021-07-23T13:28:16.087389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.dataset import random_split\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom boltons.iterutils import windowed\n\nimport string\nfrom pathlib import Path\nfrom textwrap import wrap","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:16.09179Z","iopub.execute_input":"2021-07-23T13:28:16.092074Z","iopub.status.idle":"2021-07-23T13:28:17.341806Z","shell.execute_reply.started":"2021-07-23T13:28:16.092045Z","shell.execute_reply":"2021-07-23T13:28:17.340923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2048\nLEARNING_RATE = 1e-3\nPATIENCE = 5\nNUM_EPOCHS = 50\nBETAS = (0.5, 0.99)\nSEQUENCE_LEN = 64\nEMBEDDING_DIMENSION = 100\nHIDDEN_SIZE = 128\nTEMPERATURE = 0.5\nLEN_GEN_TEXT = 500\nFILE_AMOUNT = 8\nFACTOR = 0.5\nN_LAYERS = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:45:47.558499Z","iopub.execute_input":"2021-07-23T14:45:47.558833Z","iopub.status.idle":"2021-07-23T14:45:47.564726Z","shell.execute_reply.started":"2021-07-23T14:45:47.558801Z","shell.execute_reply":"2021-07-23T14:45:47.562934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"../input/plain-text-wikipedia-202011/enwiki20201020/\"","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:17.355964Z","iopub.execute_input":"2021-07-23T13:28:17.356271Z","iopub.status.idle":"2021-07-23T13:28:17.363066Z","shell.execute_reply.started":"2021-07-23T13:28:17.35624Z","shell.execute_reply":"2021-07-23T13:28:17.362119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:17.364445Z","iopub.execute_input":"2021-07-23T13:28:17.365278Z","iopub.status.idle":"2021-07-23T13:28:17.41512Z","shell.execute_reply.started":"2021-07-23T13:28:17.365247Z","shell.execute_reply":"2021-07-23T13:28:17.414257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(path, sequence_length=SEQUENCE_LEN):\n    texts = []\n    for paths in tqdm(os.listdir(path)[:FILE_AMOUNT]):\n        texts += pd.read_json(os.path.join(path, paths)).text.sample(EMBEDDING_DIMENSION, replace=True).str.lower().tolist()\n    chars_windowed = [list(windowed(text, sequence_length)) for text in texts]\n    all_chars_windowed = [sublst for lst in tqdm(chars_windowed) for sublst in lst]\n    filtered_good_chars = [\n        sequence for sequence in tqdm(all_chars_windowed) \n        if all(char in string.printable for char in sequence)\n    ]\n    return filtered_good_chars\n\n\ndef get_unique_chars(sequences):\n    return {sublst for lst in sequences for sublst in lst}\n\n\ndef create_char2idx(sequences):\n    unique_chars = get_unique_chars(sequences)\n    return {char: idx for idx, char in tqdm(enumerate(sorted(unique_chars)))}\n\n\ndef encode_sequence(sequence, char2idx):\n    return [char2idx[char] for char in sequence]\n\n\ndef encode_sequences(sequences, char2idx):\n    return np.array([\n        encode_sequence(sequence, char2idx) \n        for sequence in tqdm(sequences)\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:17.416494Z","iopub.execute_input":"2021-07-23T13:28:17.417113Z","iopub.status.idle":"2021-07-23T13:28:17.427711Z","shell.execute_reply.started":"2021-07-23T13:28:17.417076Z","shell.execute_reply":"2021-07-23T13:28:17.426875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sequences(Dataset):\n    def __init__(self, path, sequence_length=SEQUENCE_LEN):\n        self.sequences = load_data(DATA_PATH, sequence_length=sequence_length)\n        self.vocab_size = len(get_unique_chars(self.sequences))\n        self.char2idx = create_char2idx(self.sequences)\n        self.idx2char = {idx: char for char, idx in tqdm(self.char2idx.items())}\n        self.encoded = encode_sequences(self.sequences, self.char2idx)\n        \n    def __getitem__(self, i):\n        return self.encoded[i, :-1], self.encoded[i, 1:]\n    \n    def __len__(self):\n        return len(self.encoded)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:17.429025Z","iopub.execute_input":"2021-07-23T13:28:17.429462Z","iopub.status.idle":"2021-07-23T13:28:17.438433Z","shell.execute_reply.started":"2021-07-23T13:28:17.429424Z","shell.execute_reply":"2021-07-23T13:28:17.437632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Sequences(DATA_PATH)\nlen(dataset)\ntrain_loader = DataLoader(dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:28:17.440182Z","iopub.execute_input":"2021-07-23T13:28:17.440491Z","iopub.status.idle":"2021-07-23T13:29:32.886863Z","shell.execute_reply.started":"2021-07-23T13:28:17.440466Z","shell.execute_reply":"2021-07-23T13:29:32.885958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(\n        self,\n        vocab_size,\n        embedding_dimension=EMBEDDING_DIMENSION,\n        hidden_size=HIDDEN_SIZE, \n        n_layers=1,\n        n_layers_2=1,\n        device=device,\n    ):\n        super(RNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.device = device\n        \n        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n        self.rnn = nn.GRU(\n            embedding_dimension,\n            hidden_size,\n            num_layers=n_layers,\n            batch_first=True,\n        )\n        self.decoder = nn.Sequential(\n            *[nn.Linear(hidden_size, vocab_size) for _ in range(n_layers_2)]\n        )\n        \n    def init_hidden(self, batch_size):\n        return torch.randn(self.n_layers, batch_size, self.hidden_size).to(self.device)\n    \n    def forward(self, input_, hidden):\n        encoded = self.encoder(input_)\n        output, hidden = self.rnn(encoded.unsqueeze(1), hidden)\n        output = self.decoder(output.squeeze(1))\n        return output, hidden","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:29:32.889097Z","iopub.execute_input":"2021-07-23T13:29:32.889467Z","iopub.status.idle":"2021-07-23T13:29:32.899671Z","shell.execute_reply.started":"2021-07-23T13:29:32.889427Z","shell.execute_reply":"2021-07-23T13:29:32.89857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN(vocab_size=dataset.vocab_size, device=device, n_layers=N_LAYERS).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=LEARNING_RATE,\n    betas=BETAS\n)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=PATIENCE, min_lr=1e-6, factor=FACTOR)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:29:32.901423Z","iopub.execute_input":"2021-07-23T13:29:32.902087Z","iopub.status.idle":"2021-07-23T13:29:37.659553Z","shell.execute_reply.started":"2021-07-23T13:29:32.902017Z","shell.execute_reply":"2021-07-23T13:29:37.658662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)\nprint()\nprint('Trainable parameters:')\nprint('\\n'.join([' * ' + x[0] for x in model.named_parameters() if x[1].requires_grad]))","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:29:37.660911Z","iopub.execute_input":"2021-07-23T13:29:37.661284Z","iopub.status.idle":"2021-07-23T13:29:37.670377Z","shell.execute_reply.started":"2021-07-23T13:29:37.661245Z","shell.execute_reply":"2021-07-23T13:29:37.667037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\ntrain_losses = []\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    losses = []\n    total = 0\n    for inputs, targets in tqdm(train_loader, leave=False):\n        batch_size = inputs.size(0)\n        hidden = model.init_hidden(batch_size)\n\n        model.zero_grad()\n        \n        loss = 0\n        for char_idx in range(inputs.size(1)):\n            output, hidden = model(inputs[:, char_idx].to(device), hidden)\n            loss += criterion(output, targets[:, char_idx].to(device))\n\n        loss.backward()\n\n        optimizer.step()\n        \n        avg_loss = loss.item() / inputs.size(1)\n        \n        losses.append(avg_loss)\n        total += 1\n    \n    epoch_loss = sum(losses) / total\n    scheduler.step(epoch_loss)\n    train_losses.append(epoch_loss)\n        \n    print(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:30:34.02055Z","iopub.execute_input":"2021-07-23T13:30:34.020905Z","iopub.status.idle":"2021-07-23T14:41:07.598715Z","shell.execute_reply.started":"2021-07-23T13:30:34.020869Z","shell.execute_reply":"2021-07-23T14:41:07.597896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pretty_print(text):\n    \"\"\"Wrap text for nice printing.\"\"\"\n    to_print = ''\n    for paragraph in text.split('\\n'):\n        to_print += '\\n'.join(wrap(paragraph))\n        to_print += '\\n'\n    print(to_print)\n\nmodel.eval()\nseed = 't'\ntext = ''\nwith torch.no_grad():\n    batch_size = 1\n    hidden = model.init_hidden(batch_size)\n    last_char = dataset.char2idx[seed]\n    for _ in range(LEN_GEN_TEXT):\n        output, hidden = model(torch.LongTensor([last_char]).to(device), hidden)\n        \n        distribution = output.squeeze().div(TEMPERATURE).exp()\n        guess = torch.multinomial(distribution, 1).item()\n        \n        last_char = guess\n        text += dataset.idx2char[guess]\n        \npretty_print(text)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T14:46:12.342676Z","iopub.execute_input":"2021-07-23T14:46:12.343029Z","iopub.status.idle":"2021-07-23T14:46:12.949516Z","shell.execute_reply.started":"2021-07-23T14:46:12.342996Z","shell.execute_reply":"2021-07-23T14:46:12.948454Z"},"trusted":true},"execution_count":null,"outputs":[]}]}