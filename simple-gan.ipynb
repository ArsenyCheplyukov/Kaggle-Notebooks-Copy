{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:45.56359Z","iopub.execute_input":"2021-07-17T08:36:45.564045Z","iopub.status.idle":"2021-07-17T08:36:46.926311Z","shell.execute_reply.started":"2021-07-17T08:36:45.563956Z","shell.execute_reply":"2021-07-17T08:36:46.925161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:46.930265Z","iopub.execute_input":"2021-07-17T08:36:46.930579Z","iopub.status.idle":"2021-07-17T08:36:48.753029Z","shell.execute_reply.started":"2021-07-17T08:36:46.930549Z","shell.execute_reply":"2021-07-17T08:36:48.75185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom torch.utils.tensorboard import SummaryWriter  # to print to tensorboard","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:48.756674Z","iopub.execute_input":"2021-07-17T08:36:48.756951Z","iopub.status.idle":"2021-07-17T08:36:50.349014Z","shell.execute_reply.started":"2021-07-17T08:36:48.756924Z","shell.execute_reply":"2021-07-17T08:36:50.347993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_features):\n        super().__init__()\n        self.disc = nn.Sequential(\n            nn.Linear(in_features, 128),\n            nn.LeakyReLU(0.01),\n            nn.Linear(128, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:50.350831Z","iopub.execute_input":"2021-07-17T08:36:50.351504Z","iopub.status.idle":"2021-07-17T08:36:50.359164Z","shell.execute_reply.started":"2021-07-17T08:36:50.351463Z","shell.execute_reply":"2021-07-17T08:36:50.358238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, z_dim, img_dim):\n        super().__init__()\n        self.gen = nn.Sequential(\n            nn.Linear(z_dim, 256),\n            nn.LeakyReLU(0.01),\n            nn.Linear(256, img_dim),\n            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n        )\n\n    def forward(self, x):\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:50.360877Z","iopub.execute_input":"2021-07-17T08:36:50.361595Z","iopub.status.idle":"2021-07-17T08:36:50.369821Z","shell.execute_reply.started":"2021-07-17T08:36:50.361551Z","shell.execute_reply":"2021-07-17T08:36:50.368812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters etc.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nlr = 3e-4\nz_dim = 64\nimage_dim = 28 * 28 * 1  # 784\nbatch_size = 32\nnum_epochs = 50","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:50.371369Z","iopub.execute_input":"2021-07-17T08:36:50.371788Z","iopub.status.idle":"2021-07-17T08:36:50.429733Z","shell.execute_reply.started":"2021-07-17T08:36:50.371747Z","shell.execute_reply":"2021-07-17T08:36:50.428762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc = Discriminator(image_dim).to(device)\ngen = Generator(z_dim, image_dim).to(device)\nfixed_noise = torch.randn((batch_size, z_dim)).to(device)\ntransforms = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:50.433878Z","iopub.execute_input":"2021-07-17T08:36:50.434155Z","iopub.status.idle":"2021-07-17T08:36:55.21193Z","shell.execute_reply.started":"2021-07-17T08:36:50.43412Z","shell.execute_reply":"2021-07-17T08:36:55.210967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\nopt_disc = optim.Adam(disc.parameters(), lr=lr)\nopt_gen = optim.Adam(gen.parameters(), lr=lr)\ncriterion = nn.BCELoss()\nstep = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:36:55.214267Z","iopub.execute_input":"2021-07-17T08:36:55.214679Z","iopub.status.idle":"2021-07-17T08:42:05.719908Z","shell.execute_reply.started":"2021-07-17T08:36:55.214639Z","shell.execute_reply":"2021-07-17T08:42:05.718722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"writer_fake = SummaryWriter(f\"logs/fake\")\nwriter_real = SummaryWriter(f\"logs/real\")","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:42:05.721774Z","iopub.execute_input":"2021-07-17T08:42:05.722428Z","iopub.status.idle":"2021-07-17T08:42:07.609225Z","shell.execute_reply.started":"2021-07-17T08:42:05.72238Z","shell.execute_reply":"2021-07-17T08:42:07.608366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for batch_idx, (real, _) in enumerate(loader):\n        real = real.view(-1, 784).to(device)\n        batch_size = real.shape[0]\n\n        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n        noise = torch.randn(batch_size, z_dim).to(device)\n        fake = gen(noise)\n        disc_real = disc(real).view(-1)\n        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n        disc_fake = disc(fake).view(-1)\n        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n        lossD = (lossD_real + lossD_fake) / 2\n        disc.zero_grad()\n        lossD.backward(retain_graph=True)\n        opt_disc.step()\n\n        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n        # where the second option of maximizing doesn't suffer from\n        # saturating gradients\n        output = disc(fake).view(-1)\n        lossG = criterion(output, torch.ones_like(output))\n        gen.zero_grad()\n        lossG.backward()\n        opt_gen.step()\n\n        if batch_idx == 0:\n            print(\n                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n            )\n\n            with torch.no_grad():\n                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n                data = real.reshape(-1, 1, 28, 28)\n                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n                writer_fake.add_image(\n                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n                )\n                writer_real.add_image(\n                    \"Mnist Real Images\", img_grid_real, global_step=step\n                )\n                step += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-17T08:42:07.610695Z","iopub.execute_input":"2021-07-17T08:42:07.611035Z","iopub.status.idle":"2021-07-17T08:58:02.844838Z","shell.execute_reply.started":"2021-07-17T08:42:07.611Z","shell.execute_reply":"2021-07-17T08:58:02.843947Z"},"trusted":true},"execution_count":null,"outputs":[]}]}