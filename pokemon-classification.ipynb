{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, ConcatDataset, Subset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg  \nfrom matplotlib.image import imread \nimport seaborn as sns\n\nfrom time import time\nfrom tqdm.notebook import tqdm\nfrom copy import deepcopy\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:45.468099Z","iopub.execute_input":"2021-07-10T10:31:45.468462Z","iopub.status.idle":"2021-07-10T10:31:48.256646Z","shell.execute_reply.started":"2021-07-10T10:31:45.468382Z","shell.execute_reply":"2021-07-10T10:31:48.255835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 1337\nbatch_size = 200\nresize = (200, 200)\nrows_num = 10\ntest_split = 0.2\nnum_epoch = 5\nlearning_rate = 0.001\ngamma = 0.1\npatience = 3\nlearning_rate_unfreeze = 0.0001\nsteps_to_checkpoint = 1","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.258057Z","iopub.execute_input":"2021-07-10T10:31:48.258394Z","iopub.status.idle":"2021-07-10T10:31:48.264024Z","shell.execute_reply.started":"2021-07-10T10:31:48.258359Z","shell.execute_reply":"2021-07-10T10:31:48.262737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/pokemonclassification/PokemonData\"\ninfo_dir = \"./\"\nfile_first_name = \"NN_practice_2\"","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.266063Z","iopub.execute_input":"2021-07-10T10:31:48.266483Z","iopub.status.idle":"2021-07-10T10:31:48.272792Z","shell.execute_reply.started":"2021-07-10T10:31:48.266444Z","shell.execute_reply":"2021-07-10T10:31:48.271555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.274720Z","iopub.execute_input":"2021-07-10T10:31:48.275095Z","iopub.status.idle":"2021-07-10T10:31:48.334303Z","shell.execute_reply.started":"2021-07-10T10:31:48.275059Z","shell.execute_reply":"2021-07-10T10:31:48.333316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing dataset for augmentation\n\nfigure_size = plt.rcParams[\"figure.figsize\"]\nfigure_size[0] = 7\nfigure_size[1] = 7\nplt.rcParams[\"figure.figsize\"] = figure_size","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.337451Z","iopub.execute_input":"2021-07-10T10:31:48.337813Z","iopub.status.idle":"2021-07-10T10:31:48.345030Z","shell.execute_reply.started":"2021-07-10T10:31:48.337772Z","shell.execute_reply":"2021-07-10T10:31:48.344054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = mpimg.imread(\"../input/pokemonclassification/PokemonData/Abra/0282b2f3a22745f1a436054ea15a0ae5.jpg\")\nprint(f\"{img.shape}\")\nplt.imshow(img);\n","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.346425Z","iopub.execute_input":"2021-07-10T10:31:48.346792Z","iopub.status.idle":"2021-07-10T10:31:48.647919Z","shell.execute_reply.started":"2021-07-10T10:31:48.346753Z","shell.execute_reply":"2021-07-10T10:31:48.647054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_mean_std(path):\n    dataset = ImageFolder(path, \n                          transform=transforms.Compose([\n                              transforms.ToTensor(), \n                              transforms.Resize(resize)])\n                          )\n    loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    mean = 0.0\n    std = 0.0\n    nb_samples = 0\n    for data, labels in tqdm(loader):\n        data.to(device)\n        batch_samples = len(data)\n        data = data.view(batch_samples, data.size(1), -1)\n        mean += data.mean(2).sum(0)\n        std += data.std(2).sum(0)\n        nb_samples += batch_samples\n\n    mean /= nb_samples\n    std /= nb_samples\n    return mean, std\n","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.649061Z","iopub.execute_input":"2021-07-10T10:31:48.649389Z","iopub.status.idle":"2021-07-10T10:31:48.658544Z","shell.execute_reply.started":"2021-07-10T10:31:48.649356Z","shell.execute_reply":"2021-07-10T10:31:48.657472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = torch.tensor([0.6052, 0.5874, 0.5538])\nstd = torch.tensor([0.2507, 0.2409, 0.2486])","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.661872Z","iopub.execute_input":"2021-07-10T10:31:48.662504Z","iopub.status.idle":"2021-07-10T10:31:48.680217Z","shell.execute_reply.started":"2021-07-10T10:31:48.662463Z","shell.execute_reply":"2021-07-10T10:31:48.679201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(dataset):\n    fig, ax = plt.subplots(figsize=(50, 50))\n    for images, labels in dataset:\n        ax.set_xticks([]), ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=rows_num).permute(1, 2, 0))\n        break;","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.683934Z","iopub.execute_input":"2021-07-10T10:31:48.684217Z","iopub.status.idle":"2021-07-10T10:31:48.691414Z","shell.execute_reply.started":"2021-07-10T10:31:48.684191Z","shell.execute_reply":"2021-07-10T10:31:48.690388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = transforms.Compose([\n    transforms.Resize(resize),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\ntransformer_1 = transforms.Compose([\n    transformer,\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomErasing(scale=(0.01, 0.5)),\n    transforms.ColorJitter(brightness=(0.4, 1), contrast=(0.5, 0.9),\n                           saturation=(0.5, 0.9), hue=(-0.1, 0.1)),\n    transforms.RandomRotation(degrees=(0, 180)),\n])\ntransformer_2 = transforms.Compose([\n    transformer,\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomResizedCrop(size=resize, scale=(0.25, 0.95)),\n    transforms.RandomErasing(scale=(0.01, 0.25)),\n    transforms.RandomAffine(degrees=(0, 75), translate=(0.3,0.3), scale=(0.7,0.7)),\n])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.694302Z","iopub.execute_input":"2021-07-10T10:31:48.694594Z","iopub.status.idle":"2021-07-10T10:31:48.705158Z","shell.execute_reply.started":"2021-07-10T10:31:48.694568Z","shell.execute_reply":"2021-07-10T10:31:48.704068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_set = ImageFolder(data_dir, transform=transformer)\noriginal_dataset = DataLoader(original_set, batch_size=batch_size,\n                              pin_memory=True, shuffle=True)\nshow_batch(original_dataset)\nclasses = original_set.classes\ndel original_set\ndel original_dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:31:48.707816Z","iopub.execute_input":"2021-07-10T10:31:48.708194Z","iopub.status.idle":"2021-07-10T10:32:03.638282Z","shell.execute_reply.started":"2021-07-10T10:31:48.708167Z","shell.execute_reply":"2021-07-10T10:32:03.637478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_1 = ImageFolder(data_dir, transform=transformer_1)\ndataset_1 = DataLoader(set_1, batch_size=batch_size,\n                              pin_memory=True, shuffle=True)\nshow_batch(dataset_1)\ndel dataset_1","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:03.639408Z","iopub.execute_input":"2021-07-10T10:32:03.639843Z","iopub.status.idle":"2021-07-10T10:32:12.984249Z","shell.execute_reply.started":"2021-07-10T10:32:03.639809Z","shell.execute_reply":"2021-07-10T10:32:12.983156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_2 = ImageFolder(data_dir, transform=transformer_2)\ndataset_2 = DataLoader(set_2, batch_size=batch_size,\n                              pin_memory=True, shuffle=True)\nshow_batch(dataset_2)\ndel dataset_2","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:12.985575Z","iopub.execute_input":"2021-07-10T10:32:12.986111Z","iopub.status.idle":"2021-07-10T10:32:20.008814Z","shell.execute_reply.started":"2021-07-10T10:32:12.986063Z","shell.execute_reply":"2021-07-10T10:32:20.007828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_random_indices(dataset_len, persentage):\n    indices = list(range(dataset_len))\n    split = int(np.floor(persentage * dataset_len))\n    np.random.seed(seed)\n    np.random.shuffle(indices)\n    train_idx, test_idx = indices[split:], indices[:split]\n    return train_idx, test_idx","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:20.010406Z","iopub.execute_input":"2021-07-10T10:32:20.010825Z","iopub.status.idle":"2021-07-10T10:32:20.016821Z","shell.execute_reply.started":"2021-07-10T10:32:20.010778Z","shell.execute_reply":"2021-07-10T10:32:20.015959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_test_split(data_dir, valid_persentage):\n    datafolder = ImageFolder(data_dir, transformer)\n    train_val_indexes, test_indexes = gen_random_indices(len(datafolder), valid_persentage)\n    test = Subset(datafolder, indices=test_indexes)\n    train_val = Subset(datafolder, indices=train_val_indexes)\n    dataset = ConcatDataset([\n        train_val,\n        set_1,\n        set_2\n    ])\n    train_indexes, val_indexes = gen_random_indices(len(dataset), valid_persentage)\n    return {\n        \"train\": DataLoader(dataset, batch_size=batch_size, num_workers=4,\n                            pin_memory=True, sampler=SubsetRandomSampler(train_indexes)),\n        \"validation\": DataLoader(dataset, batch_size=batch_size, num_workers=4,\n                            pin_memory=True, sampler=SubsetRandomSampler(val_indexes)),\n        \"test\": DataLoader(test, batch_size=batch_size, num_workers=4,\n                            pin_memory=True, shuffle=True),\n    }","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:20.018322Z","iopub.execute_input":"2021-07-10T10:32:20.018733Z","iopub.status.idle":"2021-07-10T10:32:20.028534Z","shell.execute_reply.started":"2021-07-10T10:32:20.018689Z","shell.execute_reply":"2021-07-10T10:32:20.027569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original = ImageFolder(path, transform=transformer['original'])\n\n#all_set = train_val + test\ntrain_val, test = train_test_split(original, test_size=test_split, shuffle=True, random_state=seed)\n\n#train_val = train + val + dataset1 + dataset2 + dataset3\ntrain_val = ConcatDataset([train_val, \n                           ImageFolder(path, transform=transformer['dataset1']),\n                           ImageFolder(path, transform=transformer['dataset2']),\n                           ImageFolder(path, transform=transformer['dataset3'])]) \n\ntrain, val = train_test_split(train_val, test_size=test_split, shuffle=True, random_state=seed)\n\ndataloaders = {\n    'train': DataLoader(train, batch_size=bs, num_workers=4, pin_memory=True),\n    'val': DataLoader(val, batch_size=bs, num_workers=4, pin_memory=True),\n    'test': DataLoader(test, batch_size=bs, num_workers=4, pin_memory=True)\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sizes","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:20.176169Z","iopub.execute_input":"2021-07-10T10:32:20.176505Z","iopub.status.idle":"2021-07-10T10:32:20.182540Z","shell.execute_reply.started":"2021-07-10T10:32:20.176471Z","shell.execute_reply":"2021-07-10T10:32:20.181685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet101 = models.wide_resnet101_2(pretrained=True, progress=True)\nfor params in resnet101.parameters():\n    params.requires_grad = False \nresnet101.fc = nn.Linear(in_features=resnet101.fc.in_features, out_features=len(classes), bias=True);","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:20.184034Z","iopub.execute_input":"2021-07-10T10:32:20.184715Z","iopub.status.idle":"2021-07-10T10:32:26.457725Z","shell.execute_reply.started":"2021-07-10T10:32:20.184528Z","shell.execute_reply":"2021-07-10T10:32:26.456851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet161 = torchvision.models.densenet161(pretrained=True, progress=True)\nfor params in densenet161.parameters():\n    params.requires_grad=False\ndensenet161.classifier = nn.Linear(in_features=densenet161.classifier.in_features, out_features=len(classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:26.458980Z","iopub.execute_input":"2021-07-10T10:32:26.459491Z","iopub.status.idle":"2021-07-10T10:32:29.041735Z","shell.execute_reply.started":"2021-07-10T10:32:26.459450Z","shell.execute_reply":"2021-07-10T10:32:29.040876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"large_mobilenet = models.mobilenet_v2(pretrained=True, progress=True)\nfor param in large_mobilenet.parameters():\n    param.requires_grad=False\nlarge_mobilenet.classifier[1] = nn.Linear(in_features=large_mobilenet.classifier[1].in_features, out_features=len(classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:29.043050Z","iopub.execute_input":"2021-07-10T10:32:29.043530Z","iopub.status.idle":"2021-07-10T10:32:29.819541Z","shell.execute_reply.started":"2021-07-10T10:32:29.043489Z","shell.execute_reply":"2021-07-10T10:32:29.818654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"googlenet = models.googlenet(pretrained=True, progress=True)\nfor param in googlenet.parameters():\n    param.requires_grad = False\ngooglenet.fc = nn.Linear(in_features=googlenet.fc.in_features, out_features=len(classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:29.820780Z","iopub.execute_input":"2021-07-10T10:32:29.821187Z","iopub.status.idle":"2021-07-10T10:32:31.115605Z","shell.execute_reply.started":"2021-07-10T10:32:29.821149Z","shell.execute_reply":"2021-07-10T10:32:31.114754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19 = models.vgg19_bn(pretrained=True, progress=True)\nfor param in vgg19.parameters():\n    param.required_grad = False\nvgg19.classifier[6] = nn.Linear(in_features=vgg19.classifier[6].in_features, out_features=len(classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:31.116905Z","iopub.execute_input":"2021-07-10T10:32:31.117397Z","iopub.status.idle":"2021-07-10T10:32:40.893642Z","shell.execute_reply.started":"2021-07-10T10:32:31.117357Z","shell.execute_reply":"2021-07-10T10:32:40.892774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mnas = torchvision.models.mnasnet1_0(pretrained=True, progress=True)\nfor param in mnas.parameters():\n    param.required_grad = False\nmnas.classifier[1] = nn.Linear(in_features=mnas.classifier[1].in_features, out_features=len(classes), bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:40.897340Z","iopub.execute_input":"2021-07-10T10:32:40.897602Z","iopub.status.idle":"2021-07-10T10:32:41.708222Z","shell.execute_reply.started":"2021-07-10T10:32:40.897576Z","shell.execute_reply":"2021-07-10T10:32:41.707338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(vgg19.classifier), len(large_mobilenet.classifier), len(mnas.classifier)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:41.709908Z","iopub.execute_input":"2021-07-10T10:32:41.710264Z","iopub.status.idle":"2021-07-10T10:32:42.110583Z","shell.execute_reply.started":"2021-07-10T10:32:41.710228Z","shell.execute_reply":"2021-07-10T10:32:42.109646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = {\n    \"epoch\" : 0,\n    \"name\" : \"\",\n    \"optim_params\" : {},\n    \"criterion_params\" : {},\n    \"model\": {},\n    \"accuracy\": 0.0,\n    \"scheduler\": {}\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.112060Z","iopub.execute_input":"2021-07-10T10:32:42.112436Z","iopub.status.idle":"2021-07-10T10:32:42.118225Z","shell.execute_reply.started":"2021-07-10T10:32:42.112397Z","shell.execute_reply":"2021-07-10T10:32:42.117236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def copy_state(epoch, name, optim, criterion, model, accuracy, scheduler):\n    state = deepcopy(checkpoint)\n    state[\"epoch\"] = epoch\n    state[\"name\"] = name\n    state[\"optim\"] = deepcopy(optim.state_dict())\n    state[\"criterion\"] = deepcopy(criterion.state_dict())\n    state[\"model\"]  = deepcopy(model.state_dict())\n    state[\"scheduler\"] = deepcopy(scheduler.state_dict())\n    state[\"accuracy\"] = accuracy\n    return state","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.119719Z","iopub.execute_input":"2021-07-10T10:32:42.120101Z","iopub.status.idle":"2021-07-10T10:32:42.127678Z","shell.execute_reply.started":"2021-07-10T10:32:42.120062Z","shell.execute_reply":"2021-07-10T10:32:42.126742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_state(checkpoint, map_location=device):\n    optimizer = torch.load(checkpoint[\"optim\"], map_location=map_location)\n    criterion = torch.load(checkpoint[\"criterion\"], map_location=map_location)\n    model = torch.load(checkpoint[\"model\"], map_location=map_location)\n    return optimizer, criterion, model","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.129026Z","iopub.execute_input":"2021-07-10T10:32:42.129705Z","iopub.status.idle":"2021-07-10T10:32:42.140547Z","shell.execute_reply.started":"2021-07-10T10:32:42.129590Z","shell.execute_reply":"2021-07-10T10:32:42.139706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_to_drive(file_name, data_dir, statement):\n    path = f\"{data_dir}/{file_first_name}{file_name}.pth\"\n    torch.save(statement, path)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.141764Z","iopub.execute_input":"2021-07-10T10:32:42.142146Z","iopub.status.idle":"2021-07-10T10:32:42.149385Z","shell.execute_reply.started":"2021-07-10T10:32:42.142099Z","shell.execute_reply":"2021-07-10T10:32:42.148667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_from_drive(file_name, data_dir, map_location=device):\n    path = f\"{data_dir}/{file_first_name}{file_name}.pth\"\n    statement = torch.load(path, map_location=map_location) if open(path) else None\n    return statement","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.150704Z","iopub.execute_input":"2021-07-10T10:32:42.151280Z","iopub.status.idle":"2021-07-10T10:32:42.158177Z","shell.execute_reply.started":"2021-07-10T10:32:42.151246Z","shell.execute_reply":"2021-07-10T10:32:42.157336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, model_name, num_epochs, seed, optimizer):\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=patience, verbose=True)\n    state_history = {\n        \"train\" : {\n            \"loss\": [],\n            \"acc\" : []\n            },\n        \"val\" : {\n            \"loss\": [],\n            \"acc\" : []\n            }\n    }\n    statement = deepcopy(checkpoint)\n    start = time()\n    for epoch in tqdm(range(num_epochs)):\n        for phase in tqdm([\"train\", \"validation\"]):\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n            current_loss = 0.0\n            current_correct = 0\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                with torch.set_grad_enabled(phase==\"train\"):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == \"train\":\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n                current_loss += loss.item() * inputs.size(0)\n                current_correct += torch.sum(preds==labels.data)\n            index = 0 if phase == \"train\" else 1\n            epoch_loss = current_loss / (dataset_sizes[index] * batch_size)\n            epoch_accuracy = current_correct.double() / (dataset_sizes[index] * batch_size)\n            if phase == \"train\":\n                scheduler.step(epoch_accuracy * 100)\n            print(f\"{phase} loss: {epoch_loss:.4f} accuracy: {epoch_accuracy:.4f}\")\n            if phase == \"validation\":\n                state_history[\"val\"][\"loss\"] = epoch_loss\n                state_history[\"val\"][\"acc\"] = epoch_accuracy\n                if epoch_accuracy > statement[\"accuracy\"]:\n                    statement = copy_state(epoch, model_name, optimizer,\n                                           criterion, model, epoch_accuracy, scheduler)\n            else:\n                state_history[\"train\"][\"loss\"] = epoch_loss\n                state_history[\"train\"][\"acc\"] = epoch_accuracy\n            # saving info\n            if (epoch + 1) % steps_to_checkpoint == 0:\n                save_to_drive(model_name, info_dir, statement)\n            torch.cuda.empty_cache()\n    time_passed = time() - start\n    print(f\"Training complete in {time_passed//60}m:{int(time_passed%60)}s\")\n    print(f\"Best accuracy is: {statement['accuracy']}\")\n    model.load_state_dict(statement[\"model\"])\n    return model, state_history","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.159399Z","iopub.execute_input":"2021-07-10T10:32:42.159916Z","iopub.status.idle":"2021-07-10T10:32:42.175056Z","shell.execute_reply.started":"2021-07-10T10:32:42.159868Z","shell.execute_reply":"2021-07-10T10:32:42.174256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_models = [large_mobilenet, resnet101, densenet161, googlenet, vgg19, mnas]\nnames_of_model = [\"mobilenet\", \"resnet\", \"densenet\", \"googlenet\", \"vgg\", \"mnas\"]\nmodels_fc = [\"resnet\", \"googlenet\"]\nstatements_freeze = []\nstatements_unfreeze = []\nfor index in tqdm(range(len(names_of_model))):\n    optimizer= 0\n    if names_of_model[index] in models_fc:\n        optimizer = torch.optim.Adam(list_of_models[index].fc.parameters(), lr=learning_rate)\n    else:\n        optimizer = torch.optim.Adam(list_of_models[index].classifier.parameters(), lr=learning_rate)\n    _, statements = train(list_of_models[index], names_of_model[index], num_epoch, seed, optimizer)\n    statements_freeze.append(statements)\n    ###UNFREZE TECHNIQUE \n    for param in list_of_models[index].parameters():\n        param.requires_grad = True\n    optimizer = torch.optim.Adam(list_of_models[index].parameters(), lr=learning_rate_unfreeze)\n    _, statement = train(list_of_models[index], names_of_model[index], num_epoch, seed, optimizer)\n    statements_unfreeze.append(statement)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:32:42.176255Z","iopub.execute_input":"2021-07-10T10:32:42.176786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Ensemble(nn.Module):\n    def __init__(self, device):\n        super(Ensemble, self).__init__()\n        self.models = nn.ModuleList(list_of_models).to(device)\n    def forward(self, x):\n        output = torch.zeros([x.size(0), len(classes)]).to(device)\n        for model in self.models:\n            output += model(x)\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Ensemble(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef test_prediction(model, test_loader):\n    model.eval()\n    loss = []\n    accuracy = [] \n    predictions = []\n    labels_list = []\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        output = model(images)\n        output.to(\"cpu\")\n        _, preds = torch.max(output, dim=1)\n        acc = torch.tensor(torch.sum(preds==labels).item() / len(preds))\n        loss.append(nn.functional.cross_entropy(output, labels))\n        accuracy.append(acc)\n        predictions.append(preds.tolist())\n        labels_list.append(labels.tolist())\n    loss = torch.stack(loss).mean()\n    accuracy = torch.stack(accuracy).mean()\n    return loss, accuracy, predictions, labels_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy, predicts, labels = test_prediction(model, dataloaders[\"test\"])\nf\"Loss is: {loss} and accuracy is: {accuracy*100} %\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}