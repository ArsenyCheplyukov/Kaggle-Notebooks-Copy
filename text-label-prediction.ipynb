{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LAUNCH TENSORBOARD ON KAGGLE**","metadata":{}},{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:29:03.76886Z","iopub.execute_input":"2021-07-21T15:29:03.769281Z","iopub.status.idle":"2021-07-21T15:29:05.041116Z","shell.execute_reply.started":"2021-07-21T15:29:03.769194Z","shell.execute_reply":"2021-07-21T15:29:05.040062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:29:06.59146Z","iopub.execute_input":"2021-07-21T15:29:06.591819Z","iopub.status.idle":"2021-07-21T15:29:09.299297Z","shell.execute_reply.started":"2021-07-21T15:29:06.591779Z","shell.execute_reply":"2021-07-21T15:29:09.298256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **START WORKING WITH TEXTS**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-21T15:29:22.579484Z","iopub.execute_input":"2021-07-21T15:29:22.579861Z","iopub.status.idle":"2021-07-21T15:29:24.510064Z","shell.execute_reply.started":"2021-07-21T15:29:22.579813Z","shell.execute_reply":"2021-07-21T15:29:24.509134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\nBATCH_SIZE = 4096\nLEARNING_RATE = 1e-3\nNUM_EPOCHS = 25\n# what epochs should go with no improvement to decrease lr\nPATIENCE = NUM_EPOCHS/5","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:29:24.513629Z","iopub.execute_input":"2021-07-21T15:29:24.513921Z","iopub.status.idle":"2021-07-21T15:29:24.520799Z","shell.execute_reply.started":"2021-07-21T15:29:24.513893Z","shell.execute_reply":"2021-07-21T15:29:24.519893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:29:24.52439Z","iopub.execute_input":"2021-07-21T15:29:24.524655Z","iopub.status.idle":"2021-07-21T15:29:24.567723Z","shell.execute_reply.started":"2021-07-21T15:29:24.524631Z","shell.execute_reply":"2021-07-21T15:29:24.566869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(DATA_PATH).sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:29:24.569321Z","iopub.execute_input":"2021-07-21T15:29:24.569664Z","iopub.status.idle":"2021-07-21T15:29:26.224664Z","shell.execute_reply.started":"2021-07-21T15:29:24.569638Z","shell.execute_reply":"2021-07-21T15:29:26.223859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Reviews(Dataset):\n    def __init__(self, path):\n        df = pd.read_csv(path)\n        self.vectorizer = CountVectorizer(stop_words='english', max_df=0.99, min_df=0.005)\n        self.sequences = self.vectorizer.fit_transform(df.review.tolist())\n        self.labels = df.sentiment.replace(['positive', 'negative'], [1, 0]).tolist()\n        self.token2idx = self.vectorizer.vocabulary_\n        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n        \n    def __getitem__(self, i):\n        return self.sequences[i, :].toarray(), self.labels[i]\n    \n    def __len__(self):\n        return self.sequences.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:47:04.314047Z","iopub.execute_input":"2021-07-21T15:47:04.314386Z","iopub.status.idle":"2021-07-21T15:47:04.321877Z","shell.execute_reply.started":"2021-07-21T15:47:04.314355Z","shell.execute_reply":"2021-07-21T15:47:04.321024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Reviews(DATA_PATH)\nloader = DataLoader(dataset, batch_size=BATCH_SIZE)\nprint(dataset[5][0])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T15:47:06.707598Z","iopub.execute_input":"2021-07-21T15:47:06.708158Z","iopub.status.idle":"2021-07-21T15:47:17.301223Z","shell.execute_reply.started":"2021-07-21T15:47:06.708122Z","shell.execute_reply":"2021-07-21T15:47:17.30036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BagOfWordsClassifier(nn.Module):\n    def block(self, in_p, out_p):\n        return nn.Sequential(\n            nn.Linear(hidden[x-1], hidden[x]),\n            nn.ReLU()\n        )\n    \n    def __init__(self, hidden):\n        super(BagOfWordsClassifier, self).__init__()\n        self.len_params = len(hidden)\n        self.model = nn.Sequential(\n            *[nn.Linear(hidden[x-1], hidden[x]) for x in range(1, self.len_params)],\n            nn.Linear(hidden[self.len_params-1], 1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, data):\n        return self.model(data.squeeze(1).float())","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:01:03.391313Z","iopub.execute_input":"2021-07-21T16:01:03.39164Z","iopub.status.idle":"2021-07-21T16:01:03.399586Z","shell.execute_reply.started":"2021-07-21T16:01:03.391608Z","shell.execute_reply":"2021-07-21T16:01:03.398687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BagOfWordsClassifier([len(dataset.token2idx), 128, 64]).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:01:06.187413Z","iopub.execute_input":"2021-07-21T16:01:06.187736Z","iopub.status.idle":"2021-07-21T16:01:06.200408Z","shell.execute_reply.started":"2021-07-21T16:01:06.187707Z","shell.execute_reply":"2021-07-21T16:01:06.199377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCELoss()\noptimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=PATIENCE, min_lr=1e-6, eps=1e-08)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:01:20.214494Z","iopub.execute_input":"2021-07-21T16:01:20.21482Z","iopub.status.idle":"2021-07-21T16:01:20.221647Z","shell.execute_reply.started":"2021-07-21T16:01:20.21479Z","shell.execute_reply":"2021-07-21T16:01:20.219309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"writer_sum = SummaryWriter(\"logs/scratch\")\nwriter = SummaryWriter(\"logs/desc\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:01:23.691139Z","iopub.execute_input":"2021-07-21T16:01:23.691462Z","iopub.status.idle":"2021-07-21T16:01:23.69968Z","shell.execute_reply.started":"2021-07-21T16:01:23.691434Z","shell.execute_reply":"2021-07-21T16:01:23.69885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()\ntrain_losses = []\nfor epochs in tqdm(range(NUM_EPOCHS)):\n    losses = []\n    total = 0\n    for inputs, labels in tqdm(loader, leave=False):\n        model.zero_grad()\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        predicted = model(inputs)\n        loss = criterion(predicted.squeeze(), labels.float())\n        loss.backward()\n        ##########################\n        nn.utils.clip_grad_norm_(model.parameters(), 3)\n        ##########################\n        optimizer.step()\n        losses.append(loss.item())\n        total += 1\n        writer.add_scalar(\"Loss all\", loss.item())\n        \n    current_train_loss = sum(losses)/total\n    scheduler.step(current_train_loss)\n    train_losses.append(current_train_loss)\n    writer_sum.add_scalar(\"Loss summary\", current_train_loss)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:04:19.901812Z","iopub.execute_input":"2021-07-21T16:04:19.902236Z","iopub.status.idle":"2021-07-21T16:07:09.661099Z","shell.execute_reply.started":"2021-07-21T16:04:19.902194Z","shell.execute_reply":"2021-07-21T16:07:09.660242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text):\n    model.eval()\n    with torch.no_grad():\n        test_vector = torch.LongTensor(dataset.vectorizer.transform([text]).toarray()).to(device)\n\n        prediction = model(test_vector).item()\n\n        if prediction > 0.5:\n            print(f'{prediction:0.3}: Positive sentiment')\n        else:\n            print(f'{prediction:0.3}: Negative sentiment')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:09:16.416372Z","iopub.execute_input":"2021-07-21T16:09:16.416692Z","iopub.status.idle":"2021-07-21T16:09:16.42328Z","shell.execute_reply.started":"2021-07-21T16:09:16.416663Z","shell.execute_reply":"2021-07-21T16:09:16.422316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text = \"\"\"\nThis poor excuse for a movie is terrible. It has been 'so good it's bad' for a\nwhile, and the high ratings are a good form of sarcasm, I have to admit. But\nnow it has to stop. Technically inept, spoon-feeding mundane messages with the\nartistic weight of an eighties' commercial, hypocritical to say the least, it\ndeserves to fall into oblivion. Mr. Derek, I hope you realize you are like that\nweird friend that everybody know is lame, but out of kindness and Christian\nduty is treated like he's cool or something. That works if you are a good\ndecent human being, not if you are a horrible arrogant bully like you are. Yes,\nMr. 'Daddy' Derek will end on the history books of the internet for being a\ndelusional sour old man who thinks to be a good example for kids, but actually\nhas a poster of Kim Jong-Un in his closet. Destroy this movie if you all have a\nconscience, as I hope IHE and all other youtube channel force-closed by Derek\nout of SPITE would destroy him in the courts.This poor excuse for a movie is\nterrible. It has been 'so good it's bad' for a while, and the high ratings are\na good form of sarcasm, I have to admit. But now it has to stop. Technically\ninept, spoon-feeding mundane messages with the artistic weight of an eighties'\ncommercial, hypocritical to say the least, it deserves to fall into oblivion.\nMr. Derek, I hope you realize you are like that weird friend that everybody\nknow is lame, but out of kindness and Christian duty is treated like he's cool\nor something. That works if you are a good decent human being, not if you are a\nhorrible arrogant bully like you are. Yes, Mr. 'Daddy' Derek will end on the\nhistory books of the internet for being a delusional sour old man who thinks to\nbe a good example for kids, but actually has a poster of Kim Jong-Un in his\ncloset. Destroy this movie if you all have a conscience, as I hope IHE and all\nother youtube channel force-closed by Derek out of SPITE would destroy him in\nthe courts.\n\"\"\"\npredict_sentiment(test_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T16:09:18.238308Z","iopub.execute_input":"2021-07-21T16:09:18.238633Z","iopub.status.idle":"2021-07-21T16:09:18.249182Z","shell.execute_reply.started":"2021-07-21T16:09:18.238603Z","shell.execute_reply":"2021-07-21T16:09:18.248386Z"},"trusted":true},"execution_count":null,"outputs":[]}]}