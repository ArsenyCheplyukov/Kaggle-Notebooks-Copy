{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Свёрточные нейросети и POS-теггинг**\n### POS-теггинг - определение частей речи (снятие частеречной неоднозначности)","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt -q\nimport sys; \nsys.path.append('./stepik-dl-nlp')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T10:03:45.103192Z","iopub.execute_input":"2021-07-25T10:03:45.104083Z","iopub.status.idle":"2021-07-25T10:06:16.717346Z","shell.execute_reply.started":"2021-07-25T10:03:45.10391Z","shell.execute_reply":"2021-07-25T10:06:16.716288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyconll -q\n!pip install spacy_udpipe -q","metadata":{"execution":{"iopub.status.busy":"2021-07-25T10:06:16.72165Z","iopub.execute_input":"2021-07-25T10:06:16.722022Z","iopub.status.idle":"2021-07-25T10:06:32.230899Z","shell.execute_reply.started":"2021-07-25T10:06:16.721989Z","shell.execute_reply":"2021-07-25T10:06:32.229511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import classification_report\n\nimport numpy as np\n\nimport pyconll\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import TensorDataset\n\nimport dlnlputils\nfrom dlnlputils.data import tokenize_corpus, build_vocabulary, \\\n    character_tokenize, pos_corpus_to_tensor, POSTagger\nfrom dlnlputils.pipeline import train_eval_loop, predict_with_model, init_random_seed\n\ninit_random_seed()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:21:42.295486Z","iopub.execute_input":"2021-07-25T11:21:42.298478Z","iopub.status.idle":"2021-07-25T11:21:53.924131Z","shell.execute_reply.started":"2021-07-25T11:21:42.298342Z","shell.execute_reply":"2021-07-25T11:21:53.922845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Загрузка текстов и разбиение на обучающую и тестовую подвыборки**","metadata":{}},{"cell_type":"code","source":"!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n!wget -O ./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:21:58.107573Z","iopub.execute_input":"2021-07-25T11:21:58.108058Z","iopub.status.idle":"2021-07-25T11:22:09.395944Z","shell.execute_reply.started":"2021-07-25T11:21:58.107998Z","shell.execute_reply":"2021-07-25T11:22:09.394384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_train = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-train.conllu')\nfull_test = pyconll.load_from_file('./stepik-dl-nlp/datasets/ru_syntagrus-ud-dev.conllu')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:09.398482Z","iopub.execute_input":"2021-07-25T11:22:09.398999Z","iopub.status.idle":"2021-07-25T11:22:38.806756Z","shell.execute_reply.started":"2021-07-25T11:22:09.398944Z","shell.execute_reply":"2021-07-25T11:22:38.805621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sent in full_train[:2]:\n    for token in sent:\n        print(token.form, token.upos)\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:38.809207Z","iopub.execute_input":"2021-07-25T11:22:38.809626Z","iopub.status.idle":"2021-07-25T11:22:38.902169Z","shell.execute_reply.started":"2021-07-25T11:22:38.809589Z","shell.execute_reply":"2021-07-25T11:22:38.899554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_SENT_LEN = max(len(sent) for sent in full_train)\nMAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\nprint('Наибольшая длина предложения', MAX_SENT_LEN)\nprint('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:38.904431Z","iopub.execute_input":"2021-07-25T11:22:38.904852Z","iopub.status.idle":"2021-07-25T11:22:39.504813Z","shell.execute_reply.started":"2021-07-25T11:22:38.904812Z","shell.execute_reply":"2021-07-25T11:22:39.503887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_train_texts = [' '.join(token.form for token in sent) for sent in full_train]\nprint('\\n'.join(all_train_texts[:10]))","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:39.508675Z","iopub.execute_input":"2021-07-25T11:22:39.509073Z","iopub.status.idle":"2021-07-25T11:22:40.082775Z","shell.execute_reply.started":"2021-07-25T11:22:39.509018Z","shell.execute_reply":"2021-07-25T11:22:40.081523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_char_tokenized = tokenize_corpus(all_train_texts, tokenizer=character_tokenize)\nchar_vocab, word_doc_freq = build_vocabulary(train_char_tokenized, max_doc_freq=1.0, min_count=5, pad_word='<PAD>')\nprint(\"Количество уникальных символов\", len(char_vocab))\nprint(list(char_vocab.items())[:10])","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:40.085308Z","iopub.execute_input":"2021-07-25T11:22:40.085798Z","iopub.status.idle":"2021-07-25T11:22:41.336966Z","shell.execute_reply.started":"2021-07-25T11:22:40.085751Z","shell.execute_reply":"2021-07-25T11:22:41.335594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNIQUE_TAGS = ['<NOTAG>'] + sorted({token.upos for sent in full_train for token in sent if token.upos})\nlabel2id = {label: i for i, label in enumerate(UNIQUE_TAGS)}\nlabel2id","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:41.339103Z","iopub.execute_input":"2021-07-25T11:22:41.339649Z","iopub.status.idle":"2021-07-25T11:22:41.774162Z","shell.execute_reply.started":"2021-07-25T11:22:41.339596Z","shell.execute_reply":"2021-07-25T11:22:41.77313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs, train_labels = pos_corpus_to_tensor(full_train, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\ntrain_dataset = TensorDataset(train_inputs, train_labels)\n\ntest_inputs, test_labels = pos_corpus_to_tensor(full_test, char_vocab, label2id, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\ntest_dataset = TensorDataset(test_inputs, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:22:41.776457Z","iopub.execute_input":"2021-07-25T11:22:41.776832Z","iopub.status.idle":"2021-07-25T11:23:50.038418Z","shell.execute_reply.started":"2021-07-25T11:22:41.776794Z","shell.execute_reply":"2021-07-25T11:23:50.037289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inputs[1][:5]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:23:50.04007Z","iopub.execute_input":"2021-07-25T11:23:50.04042Z","iopub.status.idle":"2021-07-25T11:23:50.136476Z","shell.execute_reply.started":"2021-07-25T11:23:50.040387Z","shell.execute_reply":"2021-07-25T11:23:50.134926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels[1]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T11:23:50.139149Z","iopub.execute_input":"2021-07-25T11:23:50.139629Z","iopub.status.idle":"2021-07-25T11:23:50.226092Z","shell.execute_reply.started":"2021-07-25T11:23:50.139582Z","shell.execute_reply":"2021-07-25T11:23:50.224652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Вспомогательная свёрточная архитектура**","metadata":{}},{"cell_type":"code","source":"class StackedConv1d(nn.Module):\n    def __init__(self, features_num, layers_n=1, kernel_size=3, conv_layer=nn.Conv1d, dropout=0.0):\n        super().__init__()\n        layers = []\n        for _ in range(layers_n):\n            layers.append(nn.Sequential(\n                conv_layer(features_num, features_num, kernel_size, padding=kernel_size//2),\n                nn.Dropout(dropout),\n                nn.LeakyReLU()))\n        self.layers = nn.ModuleList(layers)\n    \n    def forward(self, x):\n        \"\"\"x - BatchSize x FeaturesNum x SequenceLen\"\"\"\n        for layer in self.layers:\n            x = x + layer(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:58:18.438742Z","iopub.execute_input":"2021-07-24T20:58:18.439274Z","iopub.status.idle":"2021-07-24T20:58:18.51699Z","shell.execute_reply.started":"2021-07-24T20:58:18.439214Z","shell.execute_reply":"2021-07-24T20:58:18.516161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Предсказание частей речи на уровне отдельных токенов**","metadata":{}},{"cell_type":"code","source":"class SingleTokenPOSTagger(nn.Module):\n    def __init__(self, vocab_size, labels_num, embedding_size=32, **kwargs):\n        super().__init__()\n        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n        self.backbone = StackedConv1d(embedding_size, **kwargs)\n        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n        self.out = nn.Linear(embedding_size, labels_num)\n        self.labels_num = labels_num\n    \n    def forward(self, tokens):\n        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n        batch_size, max_sent_len, max_token_len = tokens.shape\n        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n        \n        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n        \n        features = self.backbone(char_embeddings)\n        \n        global_features = self.global_pooling(features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n        \n        logits_flat = self.out(global_features)  # BatchSize*MaxSentenceLen x LabelsNum\n        logits = logits_flat.view(batch_size, max_sent_len, self.labels_num)  # BatchSize x MaxSentenceLen x LabelsNum\n        logits = logits.permute(0, 2, 1)  # BatchSize x LabelsNum x MaxSentenceLen\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:58:54.260177Z","iopub.execute_input":"2021-07-24T20:58:54.260535Z","iopub.status.idle":"2021-07-24T20:58:54.335338Z","shell.execute_reply.started":"2021-07-24T20:58:54.260504Z","shell.execute_reply":"2021-07-24T20:58:54.33449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_token_model = SingleTokenPOSTagger(len(char_vocab), len(label2id), embedding_size=64, layers_n=3, kernel_size=3, dropout=0.3).to(\"cuda\")\nprint('Количество параметров', sum(np.product(t.shape) for t in single_token_model.parameters()))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:59:04.668789Z","iopub.execute_input":"2021-07-24T20:59:04.669164Z","iopub.status.idle":"2021-07-24T20:59:13.583651Z","shell.execute_reply.started":"2021-07-24T20:59:04.669132Z","shell.execute_reply":"2021-07-24T20:59:13.58271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(best_val_loss,\n best_single_token_model) = train_eval_loop(single_token_model,\n                                            train_dataset,\n                                            test_dataset,\n                                            F.cross_entropy,\n                                            lr=5e-3,\n                                            epoch_n=2,\n                                            batch_size=256,\n                                            device='cuda',\n                                            early_stopping_patience=5,\n                                            max_batches_per_epoch_train=500,\n                                            max_batches_per_epoch_val=100,\n                                            lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n                                                                                                                       factor=0.5,\n                                                                                                                       verbose=True))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:00:21.136297Z","iopub.execute_input":"2021-07-24T21:00:21.13702Z","iopub.status.idle":"2021-07-24T21:13:47.544857Z","shell.execute_reply.started":"2021-07-24T21:00:21.136973Z","shell.execute_reply":"2021-07-24T21:13:47.543401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ntorch.save(best_single_token_model.state_dict(), './stepik-dl-nlp/models/single_token_pos.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:13:47.546406Z","iopub.execute_input":"2021-07-24T21:13:47.546758Z","iopub.status.idle":"2021-07-24T21:13:47.62885Z","shell.execute_reply.started":"2021-07-24T21:13:47.54672Z","shell.execute_reply":"2021-07-24T21:13:47.627997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_token_model.load_state_dict(torch.load('./stepik-dl-nlp/models/single_token_pos.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:13:47.632167Z","iopub.execute_input":"2021-07-24T21:13:47.632446Z","iopub.status.idle":"2021-07-24T21:13:47.705813Z","shell.execute_reply.started":"2021-07-24T21:13:47.632416Z","shell.execute_reply":"2021-07-24T21:13:47.704797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = predict_with_model(single_token_model, train_dataset)\ntrain_loss = F.cross_entropy(torch.tensor(train_pred).to(\"cuda\"),\n                             torch.tensor(train_labels).to(\"cuda\"))\nprint('Среднее значение функции потерь на обучении', float(train_loss))\nprint(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\nprint()\n\ntest_pred = predict_with_model(single_token_model, test_dataset)\ntest_loss = F.cross_entropy(torch.tensor(test_pred).to(\"cuda\"),\n                            torch.tensor(test_labels).to(\"cuda\"))\nprint('Среднее значение функции потерь на валидации', float(test_loss))\nprint(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:17:40.974134Z","iopub.execute_input":"2021-07-24T21:17:40.974499Z","iopub.status.idle":"2021-07-24T21:18:32.854992Z","shell.execute_reply.started":"2021-07-24T21:17:40.974468Z","shell.execute_reply":"2021-07-24T21:18:32.853925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Предсказание частей речи на уровне предложений (с учётом контекста)**","metadata":{}},{"cell_type":"code","source":"class SentenceLevelPOSTagger(nn.Module):\n    def __init__(self, vocab_size, labels_num, embedding_size=32, single_backbone_kwargs={}, context_backbone_kwargs={}):\n        super().__init__()\n        self.embedding_size = embedding_size\n        self.char_embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n        self.single_token_backbone = StackedConv1d(embedding_size, **single_backbone_kwargs)\n        self.context_backbone = StackedConv1d(embedding_size, **context_backbone_kwargs)\n        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n        self.out = nn.Conv1d(embedding_size, labels_num, 1)\n        self.labels_num = labels_num\n    \n    def forward(self, tokens):\n        \"\"\"tokens - BatchSize x MaxSentenceLen x MaxTokenLen\"\"\"\n        batch_size, max_sent_len, max_token_len = tokens.shape\n        tokens_flat = tokens.view(batch_size * max_sent_len, max_token_len)\n        \n        char_embeddings = self.char_embeddings(tokens_flat)  # BatchSize*MaxSentenceLen x MaxTokenLen x EmbSize\n        char_embeddings = char_embeddings.permute(0, 2, 1)  # BatchSize*MaxSentenceLen x EmbSize x MaxTokenLen\n        char_features = self.single_token_backbone(char_embeddings)\n        \n        token_features_flat = self.global_pooling(char_features).squeeze(-1)  # BatchSize*MaxSentenceLen x EmbSize\n\n        token_features = token_features_flat.view(batch_size, max_sent_len, self.embedding_size)  # BatchSize x MaxSentenceLen x EmbSize\n        token_features = token_features.permute(0, 2, 1)  # BatchSize x EmbSize x MaxSentenceLen\n        context_features = self.context_backbone(token_features)  # BatchSize x EmbSize x MaxSentenceLen\n\n        logits = self.out(context_features)  # BatchSize x LabelsNum x MaxSentenceLen\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:20:27.642169Z","iopub.execute_input":"2021-07-24T21:20:27.642548Z","iopub.status.idle":"2021-07-24T21:20:28.050518Z","shell.execute_reply.started":"2021-07-24T21:20:27.642512Z","shell.execute_reply":"2021-07-24T21:20:28.049574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_level_model = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n                                              single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3),\n                                              context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3)).to(\"cuda\")\nprint('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model.parameters()))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:20:47.927818Z","iopub.execute_input":"2021-07-24T21:20:47.928147Z","iopub.status.idle":"2021-07-24T21:20:48.007541Z","shell.execute_reply.started":"2021-07-24T21:20:47.928117Z","shell.execute_reply":"2021-07-24T21:20:48.006724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n(best_val_loss,\n best_sentence_level_model) = train_eval_loop(sentence_level_model,\n                                              train_dataset,\n                                              test_dataset,\n                                              F.cross_entropy,\n                                              lr=5e-3,\n                                              epoch_n=2,\n                                              batch_size=256,\n                                              device='cuda',\n                                              early_stopping_patience=5,\n                                              max_batches_per_epoch_train=500,\n                                              max_batches_per_epoch_val=100,\n                                              lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n                                                                                                                         factor=0.5,\n                                                                                                                         verbose=True))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:21:08.82381Z","iopub.execute_input":"2021-07-24T21:21:08.824224Z","iopub.status.idle":"2021-07-24T21:34:43.443352Z","shell.execute_reply.started":"2021-07-24T21:21:08.824183Z","shell.execute_reply":"2021-07-24T21:34:43.442435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(best_sentence_level_model.state_dict(), './stepik-dl-nlp/models/sentence_level_pos.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:50:10.41511Z","iopub.execute_input":"2021-07-24T20:50:10.415495Z","iopub.status.idle":"2021-07-24T20:50:10.500845Z","shell.execute_reply.started":"2021-07-24T20:50:10.415452Z","shell.execute_reply":"2021-07-24T20:50:10.499809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_level_model.load_state_dict(torch.load('./stepik-dl-nlp/models/sentence_level_pos.pth'))\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:50:10.502611Z","iopub.execute_input":"2021-07-24T20:50:10.503047Z","iopub.status.idle":"2021-07-24T20:50:10.591449Z","shell.execute_reply.started":"2021-07-24T20:50:10.503008Z","shell.execute_reply":"2021-07-24T20:50:10.59016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = predict_with_model(sentence_level_model, train_dataset)\ntrain_loss = F.cross_entropy(torch.tensor(train_pred).to(\"cuda\"),\n                             torch.tensor(train_labels).to(\"cuda\"))\nprint('Среднее значение функции потерь на обучении', float(train_loss))\nprint(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\nprint()\n\ntest_pred = predict_with_model(sentence_level_model, test_dataset)\ntest_loss = F.cross_entropy(torch.tensor(test_pred).to(\"cuda\"),\n                            torch.tensor(test_labels).to(\"cuda\"))\nprint('Среднее значение функции потерь на валидации', float(test_loss))\nprint(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T21:37:11.163472Z","iopub.execute_input":"2021-07-24T21:37:11.16382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Применение полученных теггеров и сравнение**","metadata":{}},{"cell_type":"code","source":"single_token_pos_tagger = POSTagger(single_token_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)\nsentence_level_pos_tagger = POSTagger(sentence_level_model, char_vocab, UNIQUE_TAGS, MAX_SENT_LEN, MAX_ORIG_TOKEN_LEN)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T20:38:34.865668Z","iopub.status.idle":"2021-07-24T20:38:34.866246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sentences = [\n    'Мама мыла раму.',\n    'Косил косой косой косой.',\n    'Глокая куздра штеко будланула бокра и куздрячит бокрёнка.',\n    'Сяпала Калуша с Калушатами по напушке.',\n    'Пирожки поставлены в печь, мама любит печь.',\n    'Ведро дало течь, вода стала течь.',\n    'Три да три, будет дырка.',\n    'Три да три, будет шесть.',\n    'Сорок сорок'\n]\ntest_sentences_tokenized = tokenize_corpus(test_sentences, min_token_size=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sent_tokens, sent_tags in zip(test_sentences_tokenized, single_token_pos_tagger(test_sentences)):\n    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sent_tokens, sent_tags in zip(test_sentences_tokenized, sentence_level_pos_tagger(test_sentences)):\n    print(' '.join('{}-{}'.format(tok, tag) for tok, tag in zip(sent_tokens, sent_tags)))\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Свёрточный модуль своими руками**","metadata":{}},{"cell_type":"code","source":"class MyConv1d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding=0):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.weight = nn.Parameter(torch.randn(in_channels * kernel_size, out_channels) / (in_channels * kernel_size),\n                                   requires_grad=True)\n        self.bias = nn.Parameter(torch.zeros(out_channels), requires_grad=True)\n    \n    def forward(self, x):\n        \"\"\"x - BatchSize x InChannels x SequenceLen\"\"\"\n\n        batch_size, src_channels, sequence_len = x.shape        \n        if self.padding > 0:\n            pad = x.new_zeros(batch_size, src_channels, self.padding)\n            x = torch.cat((pad, x, pad), dim=-1)\n            sequence_len = x.shape[-1]\n\n        chunks = []\n        chunk_size = sequence_len - self.kernel_size + 1\n        for offset in range(self.kernel_size):\n            chunks.append(x[:, :, offset:offset + chunk_size])\n\n        in_features = torch.cat(chunks, dim=1)  # BatchSize x InChannels * KernelSize x ChunkSize\n        in_features = in_features.permute(0, 2, 1)  # BatchSize x ChunkSize x InChannels * KernelSize\n        out_features = torch.bmm(in_features, self.weight.unsqueeze(0).expand(batch_size, -1, -1)) + self.bias.unsqueeze(0).unsqueeze(0)\n        out_features = out_features.permute(0, 2, 1)  # BatchSize x OutChannels x ChunkSize\n        return out_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_level_model_my_conv = SentenceLevelPOSTagger(len(char_vocab), len(label2id), embedding_size=64,\n                                                      single_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d),\n                                                      context_backbone_kwargs=dict(layers_n=3, kernel_size=3, dropout=0.3, conv_layer=MyConv1d))\nprint('Количество параметров', sum(np.product(t.shape) for t in sentence_level_model_my_conv.parameters()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(best_val_loss,\n best_sentence_level_model_my_conv) = train_eval_loop(sentence_level_model_my_conv,\n                                                      train_dataset,\n                                                      test_dataset,\n                                                      F.cross_entropy,\n                                                      lr=5e-3,\n                                                      epoch_n=10,\n                                                      batch_size=64,\n                                                      device='cuda',\n                                                      early_stopping_patience=5,\n                                                      max_batches_per_epoch_train=500,\n                                                      max_batches_per_epoch_val=100,\n                                                      lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=2,\n                                                                                                                                 factor=0.5,\n                                                                                                                                 verbose=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pred = predict_with_model(best_sentence_level_model_my_conv, train_dataset)\ntrain_loss = F.cross_entropy(torch.tensor(train_pred),\n                             torch.tensor(train_labels))\nprint('Среднее значение функции потерь на обучении', float(train_loss))\nprint(classification_report(train_labels.view(-1), train_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))\nprint()\n\ntest_pred = predict_with_model(best_sentence_level_model_my_conv, test_dataset)\ntest_loss = F.cross_entropy(torch.tensor(test_pred),\n                            torch.tensor(test_labels))\nprint('Среднее значение функции потерь на валидации', float(test_loss))\nprint(classification_report(test_labels.view(-1), test_pred.argmax(1).reshape(-1), target_names=UNIQUE_TAGS))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}