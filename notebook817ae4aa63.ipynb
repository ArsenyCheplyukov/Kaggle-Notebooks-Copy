{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision.utils import make_grid\nimport torch.nn as nn\nfrom torchvision import transforms, models, datasets\nimport matplotlib.pyplot as plt\nfrom google.colab import drive\nimport torch.optim as optim\nimport numpy as np\nfrom torch.optim import lr_scheduler\nfrom sklearn.model_selection import train_test_split\nfrom time import time\nfrom copy import deepcopy\nfrom tqdm.notebook import tqdm\nimport io\n\n%matplotlib inline\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 5, 5","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T18:39:43.381128Z","iopub.execute_input":"2021-07-04T18:39:43.381458Z","iopub.status.idle":"2021-07-04T18:39:43.400699Z","shell.execute_reply.started":"2021-07-04T18:39:43.381430Z","shell.execute_reply":"2021-07-04T18:39:43.399621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:34:55.508903Z","iopub.execute_input":"2021-07-04T18:34:55.509354Z","iopub.status.idle":"2021-07-04T18:37:25.436190Z","shell.execute_reply.started":"2021-07-04T18:34:55.509265Z","shell.execute_reply":"2021-07-04T18:37:25.435056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install google","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:49:17.682656Z","iopub.execute_input":"2021-07-04T18:49:17.683017Z","iopub.status.idle":"2021-07-04T18:51:10.514087Z","shell.execute_reply.started":"2021-07-04T18:49:17.682987Z","shell.execute_reply":"2021-07-04T18:51:10.512839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:39:30.198578Z","iopub.execute_input":"2021-07-04T18:39:30.198963Z","iopub.status.idle":"2021-07-04T18:39:30.203437Z","shell.execute_reply.started":"2021-07-04T18:39:30.198934Z","shell.execute_reply":"2021-07-04T18:39:30.202595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\nbatch_size = 4\nlearning_rate = 0.001\nseed = 1337\ntest_size = 0.25\nstep_size = 10\ngamma = 0.1\nsteps_to_checkpoint = 1\nbias = True\ntest_num = 4","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:39:33.342948Z","iopub.execute_input":"2021-07-04T18:39:33.343343Z","iopub.status.idle":"2021-07-04T18:39:33.348654Z","shell.execute_reply.started":"2021-07-04T18:39:33.343310Z","shell.execute_reply":"2021-07-04T18:39:33.347728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"/content/gdrive/MyDrive/Colab Notebooks/data/flowers_classification\"\npath_to_load_info = \"/content/gdrive/MyDrive/Colab Notebooks/pretrained_weights\"\ninfo_name = \"NNPractice_1.pth\"\ndrive.mount('/content/gdrive')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:39:36.229166Z","iopub.execute_input":"2021-07-04T18:39:36.229760Z","iopub.status.idle":"2021-07-04T18:39:36.245322Z","shell.execute_reply.started":"2021-07-04T18:39:36.229728Z","shell.execute_reply":"2021-07-04T18:39:36.244173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_valid_loader(data_dir, batch_size, random_seed, valid_size=0.1, \n                       shuffle=True, num_workers=2, mean=[0.5, 0.5, 0.5],\n                       std=[0.25, 0.25, 0.25], normalize=True):\n    normalize = transforms.Normalize(mean=mean, std=std)\n    \n    transform = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize])\n    \n    image_dataset = datasets.ImageFolder(data_dir, transform)\n    \n    len_train = len(image_dataset)\n    indices = list(range(len_train))\n    split = int(np.floor(valid_size * len_train))\n    \n    if shuffle:\n        np.random.seed(random_seed)\n        np.random.shuffle(indices)\n    \n    train_idx, valid_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetRandomSampler(valid_idx)\n    \n    train_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size,\n                                sampler=train_sampler, num_workers=num_workers)\n    valid_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size,\n                                sampler=valid_sampler, num_workers=num_workers)\n    return (train_loader, valid_loader, image_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(input, title, mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25]):\n    inp = input.numpy().transpose(1,2,0)\n    inp = inp * std + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    plt.title(title)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_statement = {\n    \"accuracy\": 0.0,\n    \"epoch\": 0,\n    \"weights\": {},\n    \"criterion\": {},\n    \"optimizer\": {},\n    \"scheduler\": {}\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def copy_info(model, criterion, optimizer, scheduler, accuracy=0.0, epoch=0):\n    state = deepcopy(best_statement)\n    state[\"weights\"] = deepcopy(model.state_dict())\n    state[\"criterion\"] = deepcopy(criterion.state_dict())\n    state[\"optimizer\"] = deepcopy(optimizer.state_dict())\n    state[\"scheduler\"] = deepcopy(scheduler.state_dict())\n    state[\"accuracy\"] = accuracy\n    state[\"epoch\"] = epoch\n    return state","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_to_drive(file_name, data_dir, statement):\n    path = f\"{data_dir}/{file_name}\"\n    torch.save(statement, path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_from_drive(file_name, data_dir, map_location=\"gpu\"):\n    path = f\"{data_dir}/{file_name}\"\n    statement = torch.load(path, map_location=map_location)\n    return statement","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    start = time()\n    best_statement = copy_info(model, criterion, optimizer, scheduler)\n    for epoch in tqdm(range(num_epochs)):\n        for phase in tqdm([\"train\", \"validate\"]):\n            if phase == \"train\":\n                model.train()\n            else:\n                model.eval()\n            current_loss = 0.0\n            current_correct = 0\n            for inputs, labels in tqdm(train_dataset if phase == \"train\" else valid_dataset):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                with torch.set_grad_enabled(phase==\"train\"):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == \"train\":\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n                current_loss += loss.item() * inputs.size(0)\n                current_correct += torch.sum(preds==labels.data)\n            if phase == \"train\":\n                scheduler.step()\n            index = 0 if phase == \"train\" else 1\n            epoch_loss = current_loss / (dataset_sizes[index] * batch_size)\n            epoch_accuracy = current_correct.double() / (dataset_sizes[index] * batch_size)\n            print(f\"{phase} loss: {epoch_loss:.4f} accuracy: {epoch_accuracy:.4f}\")\n            if phase == \"val\" and epoch_accuracy > best_statement[\"accuracy\"]:\n                best_statement = copy_info(model, criterion, optimizer,\n                                           scheduler, epoch_accuracy, epoch)\n            # saving info\n            if (epoch + 1) % steps_to_checkpoint == 0:\n                save_to_drive(info_name, path_to_load_info, best_statement)\n    time_passed = time() - start\n    print(f\"Training complete in {time_passed//60}m:{time_passed%60}\")\n    print(f\"Best accuracy is: {best_statement['accuracy']}\")\n    return best_statement      ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset, valid_dataset, image_dataset = train_valid_loader(data_dir=data_dir,\n    batch_size=batch_size, random_seed=seed)\n\ndataset_sizes = [len(x) for x in [train_dataset, valid_dataset]]\nclass_names = image_dataset.classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sizes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs, classes = next(iter(train_dataset))\nout = make_grid(inputs)\n# what make grid does\nimshow(out, title=[class_names[x] for x in classes])\n# HOW TO INCREASE SIZE OF IMAGES","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.vgg16_bn(pretrained=True, progress=True)\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters of newly constructed modules have requires_grad=True by default\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features=num_features, out_features=len(class_names), bias=bias)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = train_model(model, criterion, optimizer, scheduler, num_epochs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = torch.load(\"/content/gdrive/MyDrive/Colab Notebooks/pretrained_weights/NNPractice_1.pth\", map_location='cpu')[\"weights\"]\n\nmodel.load_state_dict(data)\n\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num in range(test_num):\n    with torch.no_grad():\n        inputs, classes = next(iter(train_dataset))\n        out = make_grid(inputs)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        print([class_names[x] for x in preds])\n        imshow(out, title=[class_names[x] for x in classes])\n        print(torch.sum(preds==classes.data).item() / batch_size)","metadata":{},"execution_count":null,"outputs":[]}]}