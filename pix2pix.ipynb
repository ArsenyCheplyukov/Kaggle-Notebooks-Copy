{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.notebook import tqdm\nfrom torchvision.utils import save_image\nimport numpy as np\nimport os\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-19T20:28:57.585349Z","iopub.execute_input":"2021-07-19T20:28:57.585688Z","iopub.status.idle":"2021-07-19T20:28:57.591385Z","shell.execute_reply.started":"2021-07-19T20:28:57.585658Z","shell.execute_reply":"2021-07-19T20:28:57.590291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:23:50.861609Z","iopub.execute_input":"2021-07-19T20:23:50.861971Z","iopub.status.idle":"2021-07-19T20:23:50.866451Z","shell.execute_reply.started":"2021-07-19T20:23:50.861941Z","shell.execute_reply":"2021-07-19T20:23:50.865166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nTRAIN_DIR = \"../input/pix2pix-dataset/maps/maps/train\"\nVAL_DIR = \"../input/pix2pix-dataset/maps/maps/val/\"\nLEARNING_RATE = 2e-4\nBATCH_SIZE = 16\nNUM_WORKERS = 2\nIMAGE_SIZE = 256\nCHANNELS_IMG = 3\nL1_LAMBDA = 100\nLAMBDA_GP = 10\nNUM_EPOCHS = 64\nLOAD_MODEL = False\nSAVE_MODEL = False\nCHECKPOINT_DISC = \"./disc.pth.tar\"\nCHECKPOINT_GEN = \"./gen.pth.tar\"","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:29:00.19065Z","iopub.execute_input":"2021-07-19T20:29:00.191011Z","iopub.status.idle":"2021-07-19T20:29:00.198641Z","shell.execute_reply.started":"2021-07-19T20:29:00.190981Z","shell.execute_reply":"2021-07-19T20:29:00.197784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"both_transform = A.Compose(\n    [A.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n)\n\ntransform_only_input = A.Compose(\n    [\n        A.HorizontalFlip(p=0.5),\n        A.ColorJitter(p=0.2),\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n        ToTensorV2(),\n    ]\n)\n\ntransform_only_mask = A.Compose(\n    [\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n        ToTensorV2(),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:23:56.754034Z","iopub.execute_input":"2021-07-19T20:23:56.754363Z","iopub.status.idle":"2021-07-19T20:23:56.760433Z","shell.execute_reply.started":"2021-07-19T20:23:56.754333Z","shell.execute_reply":"2021-07-19T20:23:56.759649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n        super(Block, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n            if down\n            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n        )\n\n        self.use_dropout = use_dropout\n        self.dropout = nn.Dropout(0.5)\n        self.down = down\n\n    def forward(self, x):\n        x = self.conv(x)\n        return self.dropout(x) if self.use_dropout else x\n\n\nclass Generator(nn.Module):\n    def __init__(self, in_channels=3, features=64):\n        super().__init__()\n        self.initial_down = nn.Sequential(\n            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n            nn.LeakyReLU(0.2),\n        )\n        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n        self.down2 = Block(\n            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n        )\n        self.down3 = Block(\n            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n        )\n        self.down4 = Block(\n            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n        )\n        self.down5 = Block(\n            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n        )\n        self.down6 = Block(\n            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n        )\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n        )\n\n        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n        self.up2 = Block(\n            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n        )\n        self.up3 = Block(\n            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n        )\n        self.up4 = Block(\n            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n        )\n        self.up5 = Block(\n            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n        )\n        self.up6 = Block(\n            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n        )\n        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n        self.final_up = nn.Sequential(\n            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        d1 = self.initial_down(x)\n        d2 = self.down1(d1)\n        d3 = self.down2(d2)\n        d4 = self.down3(d3)\n        d5 = self.down4(d4)\n        d6 = self.down5(d5)\n        d7 = self.down6(d6)\n        bottleneck = self.bottleneck(d7)\n        up1 = self.up1(bottleneck)\n        up2 = self.up2(torch.cat([up1, d7], 1))\n        up3 = self.up3(torch.cat([up2, d6], 1))\n        up4 = self.up4(torch.cat([up3, d5], 1))\n        up5 = self.up5(torch.cat([up4, d4], 1))\n        up6 = self.up6(torch.cat([up5, d3], 1))\n        up7 = self.up7(torch.cat([up6, d2], 1))\n        return self.final_up(torch.cat([up7, d1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:23:59.229134Z","iopub.execute_input":"2021-07-19T20:23:59.229453Z","iopub.status.idle":"2021-07-19T20:23:59.250271Z","shell.execute_reply.started":"2021-07-19T20:23:59.229426Z","shell.execute_reply":"2021-07-19T20:23:59.249252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super(CNNBlock, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(\n                in_channels * 2,\n                features[0],\n                kernel_size=4,\n                stride=2,\n                padding=1,\n                padding_mode=\"reflect\",\n            ),\n            nn.LeakyReLU(0.2),\n        )\n\n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:\n            layers.append(\n                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n            )\n            in_channels = feature\n\n        layers.append(\n            nn.Conv2d(\n                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n            ),\n        )\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x, y):\n        x = torch.cat([x, y], dim=1)\n        x = self.initial(x)\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.174343Z","iopub.execute_input":"2021-07-19T20:24:06.174674Z","iopub.status.idle":"2021-07-19T20:24:06.186428Z","shell.execute_reply.started":"2021-07-19T20:24:06.174644Z","shell.execute_reply":"2021-07-19T20:24:06.185322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_some_examples(gen, val_loader, epoch, folder):\n    x, y = next(iter(val_loader))\n    x, y = x.to(DEVICE), y.to(DEVICE)\n    gen.eval()\n    with torch.no_grad():\n        y_fake = gen(x)\n        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n        if epoch == 1:\n            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n    gen.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.188151Z","iopub.execute_input":"2021-07-19T20:24:06.18884Z","iopub.status.idle":"2021-07-19T20:24:06.203121Z","shell.execute_reply.started":"2021-07-19T20:24:06.188802Z","shell.execute_reply":"2021-07-19T20:24:06.202286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.204989Z","iopub.execute_input":"2021-07-19T20:24:06.205416Z","iopub.status.idle":"2021-07-19T20:24:06.212386Z","shell.execute_reply.started":"2021-07-19T20:24:06.205379Z","shell.execute_reply":"2021-07-19T20:24:06.211618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(checkpoint_file, model, optimizer, lr):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    # If we don't do this then it will just have learning rate of old checkpoint\n    # and it will lead to many hours of debugging \\:\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.213641Z","iopub.execute_input":"2021-07-19T20:24:06.214862Z","iopub.status.idle":"2021-07-19T20:24:06.226868Z","shell.execute_reply.started":"2021-07-19T20:24:06.214823Z","shell.execute_reply":"2021-07-19T20:24:06.226015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MapDataset(Dataset):\n    def __init__(self, root_dir):\n        self.root_dir = root_dir\n        self.list_files = os.listdir(self.root_dir)\n\n    def __len__(self):\n        return len(self.list_files)\n\n    def __getitem__(self, index):\n        img_file = self.list_files[index]\n        img_path = os.path.join(self.root_dir, img_file)\n        image = np.array(Image.open(img_path))\n        input_image = image[:, :600, :]\n        target_image = image[:, 600:, :]\n\n        augmentations = both_transform(image=input_image, image0=target_image)\n        input_image = augmentations[\"image\"]\n        target_image = augmentations[\"image0\"]\n\n        input_image = transform_only_input(image=input_image)[\"image\"]\n        target_image = transform_only_mask(image=target_image)[\"image\"]\n\n        return input_image, target_image","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.228408Z","iopub.execute_input":"2021-07-19T20:24:06.228683Z","iopub.status.idle":"2021-07-19T20:24:06.24086Z","shell.execute_reply.started":"2021-07-19T20:24:06.228659Z","shell.execute_reply":"2021-07-19T20:24:06.239836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(\n    disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,\n):\n    loop = tqdm(loader, leave=True)\n\n    for idx, (x, y) in enumerate(loop):\n        x = x.to(DEVICE)\n        y = y.to(DEVICE)\n\n        # Train Discriminator\n        with torch.cuda.amp.autocast():\n            y_fake = gen(x)\n            D_real = disc(x, y)\n            D_real_loss = bce(D_real, torch.ones_like(D_real))\n            D_fake = disc(x, y_fake.detach())\n            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n            D_loss = (D_real_loss + D_fake_loss) / 2\n\n        disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n\n        # Train generator\n        with torch.cuda.amp.autocast():\n            D_fake = disc(x, y_fake)\n            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n            L1 = l1_loss(y_fake, y) * L1_LAMBDA\n            G_loss = G_fake_loss + L1\n\n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n\n        if idx % 10 == 0:\n            loop.set_postfix(\n                D_real=torch.sigmoid(D_real).mean().item(),\n                D_fake=torch.sigmoid(D_fake).mean().item(),\n            )\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:24:06.244186Z","iopub.execute_input":"2021-07-19T20:24:06.244458Z","iopub.status.idle":"2021-07-19T20:24:06.258518Z","shell.execute_reply.started":"2021-07-19T20:24:06.244432Z","shell.execute_reply":"2021-07-19T20:24:06.257687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    disc = Discriminator(in_channels=3).to(DEVICE)\n    gen = Generator(in_channels=3, features=64).to(DEVICE)\n    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n    BCE = nn.BCEWithLogitsLoss()\n    L1_LOSS = nn.L1Loss()\n\n    if LOAD_MODEL:\n        load_checkpoint(\n            CHECKPOINT_GEN, gen, opt_gen, LEARNING_RATE,\n        )\n        load_checkpoint(\n            CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n        )\n\n    train_dataset = MapDataset(root_dir=TRAIN_DIR)\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n    )\n    g_scaler = torch.cuda.amp.GradScaler()\n    d_scaler = torch.cuda.amp.GradScaler()\n    val_dataset = MapDataset(root_dir=VAL_DIR)\n    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n\n    for epoch in tqdm(range(NUM_EPOCHS)):\n        train_fn(\n            disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n        )\n\n        if SAVE_MODEL and epoch % 5 == 0:\n            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n\n        save_some_examples(gen, val_loader, epoch, folder=\"./evaluation\")","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:29:15.753075Z","iopub.execute_input":"2021-07-19T20:29:15.753437Z","iopub.status.idle":"2021-07-19T20:29:15.764298Z","shell.execute_reply.started":"2021-07-19T20:29:15.753404Z","shell.execute_reply":"2021-07-19T20:29:15.763372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir evaluation","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:26:18.059489Z","iopub.execute_input":"2021-07-19T20:26:18.059855Z","iopub.status.idle":"2021-07-19T20:26:18.842428Z","shell.execute_reply.started":"2021-07-19T20:26:18.059823Z","shell.execute_reply":"2021-07-19T20:26:18.841231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T20:29:18.156336Z","iopub.execute_input":"2021-07-19T20:29:18.156752Z","iopub.status.idle":"2021-07-19T20:57:00.395526Z","shell.execute_reply.started":"2021-07-19T20:29:18.156698Z","shell.execute_reply":"2021-07-19T20:57:00.394692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip ./evaluation","metadata":{"execution":{"iopub.status.busy":"2021-07-19T21:00:42.924633Z","iopub.execute_input":"2021-07-19T21:00:42.925031Z","iopub.status.idle":"2021-07-19T21:00:44.341146Z","shell.execute_reply.started":"2021-07-19T21:00:42.924992Z","shell.execute_reply":"2021-07-19T21:00:44.339963Z"},"trusted":true},"execution_count":null,"outputs":[]}]}