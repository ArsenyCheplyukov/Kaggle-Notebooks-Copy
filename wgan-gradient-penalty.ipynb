{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:23:01.877594Z","iopub.execute_input":"2021-07-18T13:23:01.878004Z","iopub.status.idle":"2021-07-18T13:23:03.248298Z","shell.execute_reply.started":"2021-07-18T13:23:01.877899Z","shell.execute_reply":"2021-07-18T13:23:03.246921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Github Gist: https://gist.github.com/hantoine/4e7c5bc6748861968e61e60bab89e9b0\nfrom urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef download_and_unzip(url, extract_to='.'):\n    http_response = urlopen(url)\n    zipfile = ZipFile(BytesIO(http_response.read()))\n    zipfile.extractall(path=extract_to)\n\n\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n    \n    # Launch TensorBoard\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # Install ngrok\n    if not isfile('./ngrok'):\n        ngrok_url = 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip'\n        download_and_unzip(ngrok_url)\n        chmod('./ngrok', 0o755)\n\n    # Create ngrok tunnel and print its public URL\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http 6006')\n        time.sleep(1) # Waiting for ngrok to start the tunnel\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\ntb_process, ngrok_process = launch_tensorboard()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:23:08.332377Z","iopub.execute_input":"2021-07-18T13:23:08.332914Z","iopub.status.idle":"2021-07-18T13:23:11.548905Z","shell.execute_reply.started":"2021-07-18T13:23:08.33286Z","shell.execute_reply":"2021-07-18T13:23:11.547711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom torch import multiprocessing as args","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T13:23:51.233609Z","iopub.execute_input":"2021-07-18T13:23:51.233948Z","iopub.status.idle":"2021-07-18T13:23:52.823317Z","shell.execute_reply.started":"2021-07-18T13:23:51.233916Z","shell.execute_reply":"2021-07-18T13:23:52.822453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters etc.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nBATCH_SIZE = 512\nIMAGE_SIZE = 64\nCHANNELS_IMG = 1\nZ_DIM = 100\nNUM_EPOCHS = 5\nFEATURES_CRITIC = 16\nFEATURES_GEN = 16\nCRITIC_ITERATIONS = 5\nLAMBDA_GP = 10","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:23:58.527117Z","iopub.execute_input":"2021-07-18T13:23:58.527484Z","iopub.status.idle":"2021-07-18T13:23:58.578341Z","shell.execute_reply.started":"2021-07-18T13:23:58.527427Z","shell.execute_reply":"2021-07-18T13:23:58.577161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        tuple([0.5 for _ in range(CHANNELS_IMG)]), tuple([0.5 for _ in range(CHANNELS_IMG)])\n    ),\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:38:49.200378Z","iopub.execute_input":"2021-07-18T13:38:49.200798Z","iopub.status.idle":"2021-07-18T13:38:49.206948Z","shell.execute_reply.started":"2021-07-18T13:38:49.20076Z","shell.execute_reply":"2021-07-18T13:38:49.205729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n#comment mnist and uncomment below if you want to train on CelebA dataset\n#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\nloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:38:51.950616Z","iopub.execute_input":"2021-07-18T13:38:51.95101Z","iopub.status.idle":"2021-07-18T13:38:51.987766Z","shell.execute_reply.started":"2021-07-18T13:38:51.950977Z","shell.execute_reply":"2021-07-18T13:38:51.986734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gradient_penalty(critic, real, fake, device=\"cpu\"):\n    BATCH_SIZE, C, H, W = real.shape\n    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    interpolated_images = real * alpha + fake * (1 - alpha)\n\n    # Calculate critic scores\n    mixed_scores = critic(interpolated_images)\n\n    # Take the gradient of the scores with respect to the images\n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.247345Z","iopub.execute_input":"2021-07-18T13:29:31.247765Z","iopub.status.idle":"2021-07-18T13:29:31.258209Z","shell.execute_reply.started":"2021-07-18T13:29:31.24772Z","shell.execute_reply":"2021-07-18T13:29:31.256854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(state, filename=\"celeba_wgan_gp.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.260627Z","iopub.execute_input":"2021-07-18T13:29:31.261023Z","iopub.status.idle":"2021-07-18T13:29:31.26939Z","shell.execute_reply.started":"2021-07-18T13:29:31.260981Z","shell.execute_reply":"2021-07-18T13:29:31.268359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(checkpoint, gen, disc):\n    print(\"=> Loading checkpoint\")\n    gen.load_state_dict(checkpoint['gen'])\n    disc.load_state_dict(checkpoint['disc'])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.271159Z","iopub.execute_input":"2021-07-18T13:29:31.271674Z","iopub.status.idle":"2021-07-18T13:29:31.279923Z","shell.execute_reply.started":"2021-07-18T13:29:31.271586Z","shell.execute_reply":"2021-07-18T13:29:31.278942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # input: N x channels_img x 64 x 64\n            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            # _block(in_channels, out_channels, kernel_size, stride, padding)\n            self._block(features_d, features_d * 2, 4, 2, 1),\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.281707Z","iopub.execute_input":"2021-07-18T13:29:31.282332Z","iopub.status.idle":"2021-07-18T13:29:31.29447Z","shell.execute_reply.started":"2021-07-18T13:29:31.282283Z","shell.execute_reply":"2021-07-18T13:29:31.293293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, channels_noise, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            # Input: N x channels_noise x 1 x 1\n            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            nn.ConvTranspose2d(\n                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n            ),\n            # Output: N x channels_img x 64 x 64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.298912Z","iopub.execute_input":"2021-07-18T13:29:31.299381Z","iopub.status.idle":"2021-07-18T13:29:31.312894Z","shell.execute_reply.started":"2021-07-18T13:29:31.29933Z","shell.execute_reply":"2021-07-18T13:29:31.311666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize gen and disc, note: discriminator should be called critic,\n# according to WGAN paper (since it no longer outputs between [0, 1])\ngen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\ncritic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:31.316236Z","iopub.execute_input":"2021-07-18T13:29:31.316991Z","iopub.status.idle":"2021-07-18T13:29:35.960978Z","shell.execute_reply.started":"2021-07-18T13:29:31.316934Z","shell.execute_reply":"2021-07-18T13:29:35.960021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initializate optimizer\nopt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\nopt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:35.962645Z","iopub.execute_input":"2021-07-18T13:29:35.963008Z","iopub.status.idle":"2021-07-18T13:29:35.972047Z","shell.execute_reply.started":"2021-07-18T13:29:35.962967Z","shell.execute_reply":"2021-07-18T13:29:35.970993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for tensorboard plotting\nfixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/GAN_MNIST/real\")\nwriter_fake = SummaryWriter(f\"logs/GAN_MNIST/fake\")\nstep = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:35.975919Z","iopub.execute_input":"2021-07-18T13:29:35.976236Z","iopub.status.idle":"2021-07-18T13:29:37.759719Z","shell.execute_reply.started":"2021-07-18T13:29:35.976204Z","shell.execute_reply":"2021-07-18T13:29:37.758753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen.train()\ncritic.train()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:29:37.761066Z","iopub.execute_input":"2021-07-18T13:29:37.761419Z","iopub.status.idle":"2021-07-18T13:29:37.769342Z","shell.execute_reply.started":"2021-07-18T13:29:37.761382Z","shell.execute_reply":"2021-07-18T13:29:37.768251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    # Target labels not needed! <3 unsupervised\n    for batch_idx, (real, _) in enumerate(loader):\n        real = real.to(device)\n        cur_batch_size = real.shape[0]\n\n        # Train Critic: max E[critic(real)] - E[critic(fake)]\n        # equivalent to minimizing the negative of that\n        for _ in range(CRITIC_ITERATIONS):\n            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n            fake = gen(noise)\n            critic_real = critic(real).reshape(-1)\n            critic_fake = critic(fake).reshape(-1)\n            gp = gradient_penalty(critic, real, fake, device=device)\n            loss_critic = (\n                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n            )\n            critic.zero_grad()\n            loss_critic.backward(retain_graph=True)\n            opt_critic.step()\n\n        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n        gen_fake = critic(fake).reshape(-1)\n        loss_gen = -torch.mean(gen_fake)\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n\n        # Print losses occasionally and print to tensorboard\n        if batch_idx % 100 == 0 and batch_idx > 0:\n            print(\n                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n            )\n\n            with torch.no_grad():\n                fake = gen(fixed_noise)\n                # take out (up to) 32 examples\n                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n\n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n\n            step += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:39:11.321061Z","iopub.execute_input":"2021-07-18T13:39:11.321515Z","iopub.status.idle":"2021-07-18T14:07:18.941674Z","shell.execute_reply.started":"2021-07-18T13:39:11.321422Z","shell.execute_reply":"2021-07-18T14:07:18.940686Z"},"trusted":true},"execution_count":null,"outputs":[]}]}